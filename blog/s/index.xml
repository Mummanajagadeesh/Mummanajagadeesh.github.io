&lt;?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jagadeesh Mummana | Portfolio</title><link>https://mummanajagadeesh.github.io/</link><description>This is meta description</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://mummanajagadeesh.github.io/blog/s/" rel="self" type="application/rss+xml"/><item><title>The Mathematics Behind the Rubik&amp;#39;s Cube #PID1.3</title><link>https://mummanajagadeesh.github.io/blog/mathematics-behind-rubiks-cube/</link><pubDate>Fri, 14 Feb 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/mathematics-behind-rubiks-cube/</guid><description>&lt;![CDATA[<p>The Rubik‚Äôs Cube is not just a puzzle; it‚Äôs a deep mathematical object grounded in group theory, combinatorics, and geometry. Understanding the math behind it allows us to grasp why it has 43 quintillion possible states, how we categorize moves, and why some solutions are more efficient than others.</p>]]></description><content:encoded>&lt;![CDATA[<p>The Rubik‚Äôs Cube is not just a puzzle; it‚Äôs a deep mathematical object grounded in group theory, combinatorics, and geometry. Understanding the math behind it allows us to grasp why it has 43 quintillion possible states, how we categorize moves, and why some solutions are more efficient than others.</p><h4 id="group-theory-and-the-rubiks-cube"><strong>Group Theory and the Rubik‚Äôs Cube</strong></h4><p>Group theory is a branch of mathematics that studies sets with operations that follow specific rules. The Rubik‚Äôs Cube can be seen as a mathematical group where:</p><ul><li>Each state of the cube is an element of the group.</li><li>Each valid move (rotating a face) is a group operation.</li><li>The identity element is the solved state of the cube.</li><li>Moves have inverses (e.g., turning the right face clockwise can be undone by turning it counterclockwise).</li></ul><p>The Rubik‚Äôs Cube belongs to a finite group since it has a limited number of positions. The set of all possible cube configurations, with the operation of applying a sequence of moves, forms a non-abelian group (meaning that order matters‚Äîdoing move A then B is not the same as doing move B then A).</p><p>Here‚Äôs the updated version incorporating center orientation in the usual order for 3√ó3 scales:</p><h4 id="order-of-an-element-in-the-rubiks-cube-group"><strong>Order of an Element in the Rubik‚Äôs Cube Group</strong></h4><p>In group theory, the order of an element is the number of times it must be applied to return to the identity (solved state). In the Rubik‚Äôs Cube, certain moves or sequences have different orders:</p><ul><li>A single quarter-turn of a face has order 4 (doing it four times returns the cube to the original state).</li><li>A 180-degree turn has order 2.</li><li>Certain complex sequences have higher orders, meaning they take more repetitions to cycle back to the starting position.</li><li>On a standard 3√ó3 Rubik‚Äôs Cube, center pieces do not change position, but their orientation can matter in some cases, such as in supercube variants where sticker orientation is tracked. In such cases, center rotations may introduce elements of order 2 or 4, depending on the move sequence.</li></ul><p>Understanding the order of moves, including center orientation, helps in designing efficient solving algorithms.</p><h4 id="counting-the-43-quintillion-permutations"><strong>Counting the 43 Quintillion Permutations</strong></h4><p>To compute the number of possible Rubik‚Äôs Cube states, we analyze the degrees of freedom:</p><ul><li>There are 8 corner pieces, each of which can be arranged in (8!) ways.</li><li>Each corner has three orientations, giving (3^7) possibilities (the last one is determined by the others).</li><li>There are 12 edge pieces, which can be arranged in (12!) ways.</li><li>Each edge has two orientations, giving (2^{11}) possibilities (the last one is determined by the others).</li><li>However, only even permutations of corners and edges are possible, so we divide by 2.</li></ul><p>Thus, the total number of possible Rubik‚Äôs Cube states is:</p><p>$$
\frac{8! \times 3^7 \times 12! \times 2^{11}}{2} = 43,252,003,274,489,856,000
$$</p><p>which is approximately<strong>43 quintillion</strong>.</p><p>For the<strong>2√ó2√ó2 Rubik‚Äôs Cube</strong>, we use a similar method but without considering edges:</p><ul><li>The 8 corner pieces can be arranged in (8!) ways.</li><li>Each has 3 orientations, giving (3^7) (since the last one is determined).</li><li>Only even permutations are possible, so we divide by 2.</li></ul><p>Thus, the number of possible 2√ó2√ó2 states is:</p><p>$$
\frac{8! \times 3^7}{2} = 3,674,160
$$</p><p>which is significantly smaller than the 3√ó3√ó3 but still quite large.</p><h4 id="gods-number-and-move-metrics"><strong>God‚Äôs Number and Move Metrics</strong></h4><p>God‚Äôs Number is the maximum number of moves required to solve the worst-case scenario of a Rubik‚Äôs Cube optimally. In 2010, researchers proved that God‚Äôs Number for a standard 3√ó3√ó3 Rubik‚Äôs Cube is<strong>20 moves</strong> in the<strong>quarter-turn metric</strong> (where each 90-degree face turn counts as one move).</p><h5 id="move-metrics">Move Metrics</h5><ul><li><strong>Quarter-Turn Metric (QTM)</strong>: Every 90-degree turn is counted as one move. This is the standard used in the 20-move God‚Äôs Number proof.</li><li><strong>Half-Turn Metric (HTM)</strong>: Both 90-degree and 180-degree turns count as one move. In this metric, God‚Äôs Number is<strong>18 moves</strong>.</li><li><strong>Face-Turn Metric (FTM)</strong>: Any rotation of a face, whether 90, 180, or 270 degrees, is counted as one move.</li></ul><p>Different solving methods optimize for different metrics. For example, speedcubers prioritize<strong>fewer moves in practice</strong> rather than the theoretical minimum number of moves.</p><h4 id="euclidean-and-quaternion-mathematics-in-the-rubiks-cube"><strong>Euclidean and Quaternion Mathematics in the Rubik‚Äôs Cube</strong></h4><h5 id="euclidean-geometry-and-the-rubiks-cube"><strong>Euclidean Geometry and the Rubik‚Äôs Cube</strong></h5><p>The Rubik‚Äôs Cube exists in three-dimensional Euclidean space, meaning its transformations can be represented using classical geometric tools such as matrices and vector operations.</p><ul><li><p><strong>Rotation Matrices:</strong> Each face rotation can be described using a 3√ó3 rotation matrix. A 90-degree clockwise rotation about the x, y, or z-axis can be represented as:</p><p>$$
R_x(90^\circ) = \begin{bmatrix} 1 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; -1 \ 0 &amp; 1 &amp; 0 \end{bmatrix},
$$</p><p>$$
R_y(90^\circ) = \begin{bmatrix} 0 &amp; 0 &amp; 1 \ 0 &amp; 1 &amp; 0 \ -1 &amp; 0 &amp; 0 \end{bmatrix},
$$</p><p>$$
R_z(90^\circ) = \begin{bmatrix} 0 &amp; -1 &amp; 0 \ 1 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; 1 \end{bmatrix}.
$$</p></li><li><p><strong>Vector Representation:</strong> Each cubie (small cube piece) has a position vector ( v ), and applying a rotation matrix transforms it to a new position:
$$
v&rsquo; = R v.
$$
Using these transformations, all possible moves on the cube can be described mathematically.</p></li></ul><h5 id="quaternion-representation-and-the-rubiks-cube"><strong>Quaternion Representation and the Rubik‚Äôs Cube</strong></h5><p>Quaternions offer an alternative way to describe rotations in 3D space. A quaternion is defined as:
$$
q = a + bi + cj + dk,
$$
where ( a, b, c, d ) are real numbers, and ( i, j, k ) are imaginary unit vectors satisfying specific multiplication rules.</p><ul><li><p><strong>Rotation Using Quaternions:</strong> Any 3D rotation can be represented as:
$$
q = \cos\left(\frac{\theta}{2}\right) + \sin\left(\frac{\theta}{2}\right)(xi + yj + zk),
$$
where ( \theta ) is the rotation angle, and ( (x, y, z) ) is the rotation axis.</p></li><li><p><strong>Applying a Rotation:</strong> Given a point represented by a quaternion ( p ), the rotated point ( p&rsquo; ) is obtained as:
$$
p&rsquo; = q p q^{-1}.
$$</p></li></ul><p>Using quaternions avoids issues like gimbal lock and allows smooth, efficient calculations, making them useful in robotic cube solvers and computer simulations.</p><h5 id="comparison-of-euclidean-and-quaternion-methods"><strong>Comparison of Euclidean and Quaternion Methods</strong></h5><table><thead><tr><th>Method</th><th>Advantages</th><th>Use Case in Rubik‚Äôs Cube</th></tr></thead><tbody><tr><td><strong>Rotation Matrices</strong></td><td>Simple, easy to compute</td><td>Manual cube manipulation, algebraic solving</td></tr><tr><td><strong>Quaternions</strong></td><td>No gimbal lock, computationally efficient</td><td>Robotics, computer simulations</td></tr></tbody></table><p>While human solvers primarily use group-theoretic approaches, understanding Euclidean and quaternion mathematics is valuable for computational methods and AI-driven solutions.</p><h4 id="advanced-mathematics-behind-the-rubiks-cube">Advanced Mathematics Behind the Rubik‚Äôs Cube</h4><h4 id="graph-theory-and-the-rubiks-cube"><strong>Graph Theory and the Rubik‚Äôs Cube</strong></h4><p>The entire state space of the Rubik‚Äôs Cube can be visualized as a<strong>graph</strong>, where:</p><ul><li>Each<strong>node</strong> represents a unique cube configuration.</li><li>Each<strong>edge</strong> represents a valid move between two configurations.</li></ul><p>This allows us to analyze cube solving as a<strong>shortest path problem</strong> (like in Dijkstra‚Äôs algorithm). The challenge is that this graph is<strong>huge</strong>, containing about<strong>43 quintillion nodes</strong>! Researchers have used<strong>Breadth-First Search (BFS)</strong> to explore how quickly the cube can be solved from any state, leading to the proof of<strong>God‚Äôs Number</strong> (20 in QTM).</p><h4 id="markov-chains-and-random-scrambles"><strong>Markov Chains and Random Scrambles</strong></h4><p>If you randomly twist a Rubik‚Äôs Cube, how many moves does it take before it is &ldquo;fully scrambled&rdquo;? This is a classic<strong>Markov Chain</strong> problem, where each move represents a<strong>random transition</strong> between states. Studies suggest that after about<strong>19-20 random moves</strong>, the cube is statistically close to a uniformly random state. This insight is used in competitive cubing to ensure fairness in official scramble generation.</p><h4 id="group-structure-conjugacy-classes-and-commutators"><strong>Group Structure: Conjugacy Classes and Commutators</strong></h4><p>The Rubik‚Äôs Cube group has special elements called<strong>commutators</strong> and<strong>conjugates</strong>, which are fundamental to advanced solving techniques:</p><ul><li><strong>Commutator</strong>: ([A, B] = A B A^{-1} B^{-1}) ‚Äì used in many algorithms to isolate cube pieces.</li><li><strong>Conjugate</strong>: (X A X^{-1}) ‚Äì applies a transformation in a different context.</li></ul><p>These concepts allow cube solvers to move a small set of pieces without disrupting the rest, forming the basis for algorithms like<strong>CFOP, Roux, and ZZ methods</strong>.</p><h4 id="why-is-solving-the-cube-hard-computational-complexity"><strong>Why Is Solving the Cube Hard? Computational Complexity</strong></h4><p>Solving an<strong>arbitrary</strong> cube position optimally (in the least moves) is an<strong>NP-hard problem</strong>. That means there is no known efficient algorithm that can solve every case optimally in polynomial time. This is why human solvers use heuristic-based approaches like<strong>CFOP, Petrus, and Roux</strong>, rather than brute force computation.</p><h4 id="whats-next-computers-and-efficient-cube-solving"><strong>What‚Äôs Next? Computers and Efficient Cube Solving</strong></h4><p>In our next post, we will explore how<strong>computers</strong> approach solving the Rubik‚Äôs Cube, including AI techniques, heuristics, and optimal solvers like<strong>Kociemba‚Äôs Algorithm and DeepCubeA</strong>.</p>
]]></content:encoded></item><item><title>Solving The Rubiks Cube #PID1.2</title><link>https://mummanajagadeesh.github.io/blog/solving-the-rubiks-cube/</link><pubDate>Fri, 07 Feb 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/solving-the-rubiks-cube/</guid><description>&lt;![CDATA[<p>The Rubik‚Äôs Cube, with its intricate design and colorful chaos, can seem overwhelming at first glance. However, solving it is not just about memorizing algorithms but about understanding the mechanics behind each move. There are several well-known solving methods, each with its own advantages and techniques that cater to different solving styles. Whether you&rsquo;re aiming for speed, efficiency, or ergonomic moves, the CFOP, Roux, and ZZ methods offer distinct paths to mastery. These are all speed-solving methods designed for competitive cubing, but there are also beginner-friendly and alternative approaches like the Layer-by-Layer (LBL) and Petrus methods.</p>]]></description><content:encoded>&lt;![CDATA[<p>The Rubik‚Äôs Cube, with its intricate design and colorful chaos, can seem overwhelming at first glance. However, solving it is not just about memorizing algorithms but about understanding the mechanics behind each move. There are several well-known solving methods, each with its own advantages and techniques that cater to different solving styles. Whether you&rsquo;re aiming for speed, efficiency, or ergonomic moves, the CFOP, Roux, and ZZ methods offer distinct paths to mastery. These are all speed-solving methods designed for competitive cubing, but there are also beginner-friendly and alternative approaches like the Layer-by-Layer (LBL) and Petrus methods.</p><hr><h4 id="cfop-the-classic-speedcubing-approach">CFOP: The Classic Speedcubing Approach</h4><p>CFOP (Cross ‚Äì First Two Layers ‚Äì Orientation of Last Layer ‚Äì Permutation of Last Layer), also known as the Fridrich Method, is the most widely used method among speedcubers. It breaks the solve into four logical steps, enabling high efficiency and minimal pause between sequences.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="360" src="/images/post/solverubcub/cfop_hu7945380640516140194.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/cfop_hu7604892347410183553.jpg'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h5 id="the-cross">The Cross</h5><p>The first step is solving a cross on one face of the cube, typically white. The aim is to position the four edge pieces correctly while minimizing moves. Advanced solvers focus on efficiency, ensuring that each edge is inserted optimally without unnecessary cube rotations. Many speedcubers practice solving the cross in eight moves or fewer to optimize their solving time.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/cross_hu8167784418912384101.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/cross_hu8167784418912384101.webp'"/><h5 id="first-two-layers-f2l">First Two Layers (F2L)</h5><p>Rather than solving corners and edges separately, F2L pairs them up before inserting them into their respective slots. This is a crucial speed improvement over beginner methods, reducing move count significantly. F2L can be learned intuitively, but advanced cubers memorize key cases and algorithms for increased efficiency.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/f2l_hu8826165599237415008.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/f2l_hu8826165599237415008.webp'"/><h5 id="orientation-of-the-last-layer-oll">Orientation of the Last Layer (OLL)</h5><p>Once the first two layers are completed, the next step is orienting all pieces on the top layer so that the face becomes a uniform color. There are 57 possible cases, but beginners can use a two-step OLL approach with just ten algorithms.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/oll_hu17659736153421577177.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/oll_hu17659736153421577177.webp'"/><h5 id="permutation-of-the-last-layer-pll">Permutation of the Last Layer (PLL)</h5><p>The final step is to permute the last layer pieces into their correct positions. This step requires knowledge of 21 algorithms in the full PLL method or just six in the two-look PLL approach. Mastering PLL allows for faster transition times and optimized finger tricks to reduce execution delays.</p><p>CFOP is the go-to method for many speedcubers because of its structured approach and ability to handle high turn-per-second (TPS) solves with ease. Even I use CFOP for solving the cube now‚ÄîI do an intuitive cross and F2L, then use 2-look OLL and 1-look PLL.</p><p>For 2x2, I use the CLL (Corners Last Layer) method. You can check out my times here:<a href="https://events.cubelelo.com/profile/24CLMUM001" target="_blank">Cubelelo Profile</a> (it&rsquo;s unofficial, but yeah!).</p><hr><h4 id="roux-the-efficient-block-building-method">Roux: The Efficient Block-Building Method</h4><p>Roux, developed by Gilles Roux in 2003, takes a vastly different approach from CFOP. It focuses on reducing move count and minimizing cube rotations, making it ideal for one-handed solving. Unlike CFOP, Roux relies heavily on intuitive solving techniques and block-building rather than strict algorithm memorization.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/roux_hu17826746158529360042.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/roux_hu17826746158529360042.webp'"/><h5 id="first-block">First Block</h5><p>The solve begins by constructing a 1x2x3 block on one side of the cube. This is done by strategically placing the edge and corner pieces in the correct positions without disrupting already solved parts.</p><h5 id="second-block">Second Block</h5><p>A second 1x2x3 block is then built on the opposite side of the cube. At this point, the left and right blocks are complete, leaving only the middle slice and top layer unsolved.</p><h5 id="cmll-corner-orientation--permutation">CMLL (Corner Orientation &amp; Permutation)</h5><p>Instead of solving the last layer in steps like OLL and PLL, Roux addresses all four corners at once using CMLL (Corners of the Last Layer). This step requires only 42 algorithms but can be broken into smaller subsets for easier learning.</p><h5 id="lse-last-six-edges">LSE (Last Six Edges)</h5><p>The final stage focuses on solving the remaining six edges using M and U moves exclusively. This step is what makes Roux unique, as it avoids rotations and allows for smooth, fast execution.</p><p>The strength of Roux lies in its efficiency‚Äîsolves often require fewer moves than CFOP, and its reliance on intuitive solving makes it an excellent alternative for those who prefer a different approach.</p><hr><h4 id="zz-the-method-designed-for-ergonomics">ZZ: The Method Designed for Ergonomics</h4><p>The ZZ method, named after its creator Zbigniew Zborowski, aims to balance efficiency and turning ergonomics. It pre-orients edges early in the solve, allowing the rest of the cube to be solved with only R, U, and L moves, eliminating cube rotations and awkward finger placements.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/zz_hu17756769075213033669.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/zz_hu17756769075213033669.webp'"/><h5 id="eoline-edge-orientation--line">EOLine (Edge Orientation &amp; Line)</h5><p>The solve begins by orienting all edges while placing two key edges along the bottom. This setup ensures that later steps can be executed smoothly without disrupting edge orientation.</p><h5 id="first-two-layers-f2l-1">First Two Layers (F2L)</h5><p>Unlike CFOP, which requires cube rotations for F2L, the ZZ method allows for rotationless F2L execution. Because edge orientation was handled in EOLine, all remaining F2L pairs can be inserted using only R, U, and L moves.</p><h5 id="last-layer">Last Layer</h5><p>Since all edges are already oriented, solving the last layer can be approached using CFOP-style algorithms or ZZ-specific techniques. The most advanced ZZ solvers use ZBLL (Zborowski-Bruchem Last Layer), which solves the entire last layer in one step, requiring knowledge of over 400 algorithms.</p><p>ZZ is an excellent choice for solvers who want to improve ergonomics while maintaining low move counts. However, EOLine can be challenging to master, making it slightly more difficult for beginners compared to CFOP.</p><hr><h4 id="layer-by-layer-lbl-the-beginner-friendly-method">Layer-by-Layer (LBL): The Beginner-Friendly Method</h4><p>The Layer-by-Layer (LBL) method is the most common beginner method. It involves solving the cube in three distinct layers:</p><ol><li>Solve the<strong>first layer</strong> by completing a cross and inserting corners.</li><li>Solve the<strong>second layer</strong> by inserting edge pieces into their correct slots.</li><li>Solve the<strong>last layer</strong> using algorithms to orient and permute the pieces.</li></ol><p>This method is easy to learn and provides a solid foundation for more advanced techniques like CFOP.</p><hr><h4 id="petrus-method-the-block-building-alternative">Petrus Method: The Block-Building Alternative</h4><p>The Petrus Method, developed by Lars Petrus, is a block-building approach that reduces move count and improves efficiency:</p><ol><li>Solve a<strong>2x2x2 block</strong> anywhere on the cube.</li><li>Expand it to a<strong>2x2x3 block</strong>.</li><li><strong>Orient the edges</strong> early to make solving easier.</li><li>Solve the<strong>remaining pieces</strong> with minimal moves.</li></ol><p>This method is useful for those who want an alternative to CFOP and prefer a more flexible solving approach.</p><hr><h4 id="choosing-the-right-method">Choosing the Right Method</h4><p>Each method has its strengths, and the best one depends on your goals:</p><ul><li><strong>CFOP</strong> is the best choice for speedcubers aiming for high TPS and efficiency.</li><li><strong>Roux</strong> is ideal for solvers who prefer intuitive solving and minimal rotations.</li><li><strong>ZZ</strong> is suited for those who want ergonomic solves with fewer rotations.</li><li><strong>LBL</strong> is great for beginners starting with the cube.</li><li><strong>Petrus</strong> is perfect for those who enjoy a block-building approach.</li></ul><p>No matter which method you choose, improving your lookahead, finger tricks, and efficiency will always be key to becoming a faster solver. Try out different approaches and see what works best for you!</p><p>Happy cubing!</p>
]]></content:encoded></item><item><title>Mechanics of Rubiks Cube #PID1.1</title><link>https://mummanajagadeesh.github.io/blog/mechanics-of-rubiks-cube/</link><pubDate>Fri, 31 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/mechanics-of-rubiks-cube/</guid><description>&lt;![CDATA[<p>The Rubik‚Äôs Cube is a 3D combination puzzle that has fascinated minds for decades. Invented in<strong>1974 by Ern≈ë Rubik</strong>, a Hungarian architect and professor, it was originally called the &ldquo;Magic Cube.&rdquo; Designed as a teaching tool to explain 3D movement, it quickly became a global sensation. The challenge? Scramble it, then restore each face to a single color‚Äîsounds simple, but millions have struggled (and succeeded) at it since!</p>]]></description><content:encoded>&lt;![CDATA[<p>The Rubik‚Äôs Cube is a 3D combination puzzle that has fascinated minds for decades. Invented in<strong>1974 by Ern≈ë Rubik</strong>, a Hungarian architect and professor, it was originally called the &ldquo;Magic Cube.&rdquo; Designed as a teaching tool to explain 3D movement, it quickly became a global sensation. The challenge? Scramble it, then restore each face to a single color‚Äîsounds simple, but millions have struggled (and succeeded) at it since!</p><h4 id="how-a-rubiks-cube-is-structured"><strong>How a Rubik‚Äôs Cube is Structured</strong></h4><p>At first glance, the Rubik‚Äôs Cube appears to be just 27 smaller cubes arranged in a 3x3 grid, but its internal mechanics are far more sophisticated. The core mechanism allows for smooth rotations, holding everything together while letting the outer pieces move freely.</p><p>The cube consists of three main types of pieces:</p><ul><li><strong>Core:</strong> The core holds the entire structure intact. It consists of six fixed center pieces that never move relative to each other.</li><li><strong>Edges:</strong> The cube has<strong>12 edge pieces</strong>, each with two colors, positioned between the centers.</li><li><strong>Corners:</strong> There are<strong>8 corner pieces</strong>, each with three colors, which determine the cube‚Äôs orientation.</li></ul><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="743" src="/images/post/rubcubemech/image_hu9050823026402286148.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/rubcubemech\/image_hu9077097627081541973.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><p>Each of these pieces interlocks in a way that allows rotation without disassembling the puzzle. When twisted, the cube rearranges itself by moving these smaller components around the core, yet the entire structure remains stable.</p><h4 id="how-it-rotates-and-functions"><strong>How It Rotates and Functions</strong></h4><p>Despite its scrambled look, a Rubik‚Äôs Cube follows a well-structured mechanical system:</p><ul><li><strong>Each face rotates independently</strong>, thanks to the internal core mechanism.</li><li>The<strong>center pieces remain static</strong>, acting as reference points for solving.</li><li><strong>Edge and corner pieces move around freely</strong>, rearranging their positions to create new patterns with every turn.</li></ul><p>Each move you make affects multiple pieces at once, creating complex shifts that can be solved using known algorithms. The key is to understand how these pieces interact with each turn to work towards a solution.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="649" src="/images/post/rubcubemech/moves_hu7891343800563514831.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/rubcubemech\/moves_hu4604621624726201818.jpg'"/><h4 id="rubiks-cube-notation-3x3-standard-moves"><strong>Rubik‚Äôs Cube Notation (3x3 Standard Moves)</strong></h4><p>To communicate Rubik‚Äôs Cube solutions, we use standard notation:</p><ul><li><p><strong>Face Turns:</strong></p><ul><li><strong>R</strong> (Right) ‚Äì Rotate the right face 90¬∞ clockwise</li><li><strong>R&rsquo;</strong> (Right Prime) ‚Äì Rotate the right face 90¬∞ counterclockwise</li><li><strong>L</strong> (Left) ‚Äì Rotate the left face 90¬∞ clockwise</li><li><strong>L&rsquo;</strong> (Left Prime) ‚Äì Rotate the left face 90¬∞ counterclockwise</li><li><strong>U</strong> (Up) ‚Äì Rotate the top face 90¬∞ clockwise</li><li><strong>U&rsquo;</strong> (Up Prime) ‚Äì Rotate the top face 90¬∞ counterclockwise</li><li><strong>D</strong> (Down) ‚Äì Rotate the bottom face 90¬∞ clockwise</li><li><strong>D&rsquo;</strong> (Down Prime) ‚Äì Rotate the bottom face 90¬∞ counterclockwise</li><li><strong>F</strong> (Front) ‚Äì Rotate the front face 90¬∞ clockwise</li><li><strong>F&rsquo;</strong> (Front Prime) ‚Äì Rotate the front face 90¬∞ counterclockwise</li><li><strong>B</strong> (Back) ‚Äì Rotate the back face 90¬∞ clockwise</li><li><strong>B&rsquo;</strong> (Back Prime) ‚Äì Rotate the back face 90¬∞ counterclockwise</li></ul></li><li><p><strong>Double Turns:</strong></p><ul><li>Moves followed by<strong>2</strong> (e.g., R2, U2) indicate a 180¬∞ turn in either direction.</li></ul></li></ul><p>This notation is used universally among cubers, making it easier to follow solving guides and algorithms.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="" src="/images/post/rubcubemech/cube_notation.gif" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src=''"/><h4 id="color-schemes-and-face-orientation"><strong>Color Schemes and Face Orientation</strong></h4><p>Most official Rubik‚Äôs Cubes follow a standardized<strong>color arrangement</strong>, which helps speedcubers recognize patterns quickly. The opposite face pairs are usually:</p><ul><li><strong>White ‚Üî Yellow</strong></li><li><strong>Blue ‚Üî Green</strong></li><li><strong>Red ‚Üî Orange</strong></li></ul><p>This scheme remains consistent across most cubes, ensuring uniformity in solving strategies. Recognizing the relationship between opposite faces is crucial when learning solving techniques, as many algorithms rely on the cube‚Äôs color orientation.</p><h4 id="different-types-of-rubiks-cubes-and-modifications"><strong>Different Types of Rubik‚Äôs Cubes and Modifications</strong></h4><p>The classic 3x3 is just the beginning! There are countless variations, each adding its own twist to the challenge:</p><h5 id="nxn-cubes-larger-and-smaller-variants"><strong>NxN Cubes (Larger and Smaller Variants)</strong></h5><ul><li><strong>2x2 (Mini Cube)</strong> ‚Äì A simpler version, great for beginners.</li><li><strong>3x3 (Standard Cube)</strong> ‚Äì The original and most popular.</li><li><strong>4x4 (Rubik‚Äôs Revenge)</strong> ‚Äì Extra layers mean extra complexity.</li><li><strong>5x5 (Professor‚Äôs Cube)</strong> ‚Äì More layers, more challenge.</li><li>Even larger cubes like<strong>6x6, 7x7, and beyond</strong> exist for advanced solvers.</li></ul><h5 id="shape-modifications"><strong>Shape Modifications</strong></h5><ul><li><strong>Fisher Cube</strong> ‚Äì A 3x3 shape mod that appears to shift its center axis, making it visually deceptive.</li><li><strong>Windmill Cube</strong> ‚Äì Features diagonal cuts, making rotations feel unpredictable.</li><li><strong>Axis Cube</strong> ‚Äì Turns into a bizarre, asymmetric mess when scrambled.</li><li><strong>Mirror Cube</strong> ‚Äì Solved by shape instead of color, adding an extra challenge.</li></ul><h5 id="other-unique-cubes"><strong>Other Unique Cubes</strong></h5><ul><li><strong>Pyraminx</strong> ‚Äì A triangular-based twisty puzzle with simpler movement mechanics.</li><li><strong>Megaminx</strong> ‚Äì A 12-sided dodecahedron cube with an extra layer of complexity.</li><li><strong>Ghost Cube</strong> ‚Äì A shape-shifting cube that must be solved by aligning irregularly shaped pieces rather than colors.</li></ul><p>Each of these variations presents a unique solving challenge, keeping cubers engaged for years!</p><h4 id="final-thoughts"><strong>Final Thoughts</strong></h4><p>The Rubik‚Äôs Cube is more than just a toy‚Äîit‚Äôs a<strong>mechanical marvel, a brain workout, and an endless source of fun</strong>. Whether you‚Äôre solving a classic 3x3 or diving into the wild world of modded cubes, the principles remain the same:<strong>patterns, patience, and persistence</strong>. Solving a Rubik‚Äôs Cube can enhance cognitive skills like problem-solving, pattern recognition, and spatial awareness, making it a fantastic hobby for all ages.</p><p>So, grab a cube, start twisting, and embrace the puzzle madness! üîÑ‚ú®</p>
]]></content:encoded></item><item><title>Why Should You Start Solving Puzzles? #PID1.0</title><link>https://mummanajagadeesh.github.io/blog/why-should-you-start-solving-puzzles/</link><pubDate>Fri, 24 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/why-should-you-start-solving-puzzles/</guid><description>&lt;![CDATA[<p>Puzzles. Whether it‚Äôs a crossword, Sudoku, or that infuriating jigsaw piece that just won‚Äôt fit, puzzles have a unique way of grabbing our attention and holding it hostage. But have you ever wondered why solving puzzles feels so satisfying? Beyond the fun, puzzles sharpen your mind, boost your problem-solving skills, and, let‚Äôs be honest, give you bragging rights.</p>]]></description><content:encoded>&lt;![CDATA[<p>Puzzles. Whether it‚Äôs a crossword, Sudoku, or that infuriating jigsaw piece that just won‚Äôt fit, puzzles have a unique way of grabbing our attention and holding it hostage. But have you ever wondered why solving puzzles feels so satisfying? Beyond the fun, puzzles sharpen your mind, boost your problem-solving skills, and, let‚Äôs be honest, give you bragging rights.</p><p>At their core, puzzles are challenges‚Äîa structured way to ask, ‚ÄúHow do I figure this out?‚Äù And that question is more important than you might think. Life, in many ways, is a giant puzzle: decisions, strategies, unexpected twists. The better we get at solving little puzzles, the more equipped we are for the big ones.</p><h4 id="why-solve-puzzles">Why Solve Puzzles?</h4><p>Solving puzzles is like a gym session for your brain. They improve cognitive functions, boost memory, and enhance focus. But beyond brainpower, puzzles teach patience, perseverance, and the art of thinking outside the box‚Äîskills that are valuable in any field, from coding to cooking to simply navigating life.</p><p>And let‚Äôs not forget the dopamine rush! Every solved puzzle is a small victory, and our brains love rewarding us for it. Who doesn‚Äôt like a mental high five?</p><hr><h4 id="coding-the-ultimate-mental-puzzle">Coding: The Ultimate Mental Puzzle</h4><p>Now, let‚Äôs talk about coding‚Äîarguably one of the most satisfying puzzles you can tackle. Writing code is essentially solving a problem using logic, creativity, and a touch of wizardry. Each bug is a mini-puzzle, each feature a challenge to implement. And with coding puzzles, you‚Äôre not just solving; you‚Äôre building.</p><p>For those who‚Äôve wrestled with algorithms, debugging, or optimizing code, you‚Äôll agree: coding is a puzzle that never gets old. The beauty lies in its versatility. Problems evolve, solutions change, and the learning never stops.</p><hr><h4 id="two-hands-one-brain-the-magic-of-physical-puzzles">Two Hands, One Brain: The Magic of Physical Puzzles</h4><p>Now, let‚Äôs take this a step further: puzzles that involve not just your mind but your hands too. Think about the Rubik‚Äôs Cube, where both hemispheres of your brain are engaged. The left brain loves the logical sequences and patterns, while the right brain enjoys the spatial awareness and creativity. It‚Äôs like a full-brain workout.</p><p>Physical puzzles improve hand-eye coordination, dexterity, and your ability to multitask. Plus, there‚Äôs something incredibly satisfying about manipulating an object and watching it transform under your hands. For me, working with physical puzzles has always been a humbling experience‚Äîyou can‚Äôt brute force them; they demand focus and finesse.</p><hr><h4 id="the-rubiks-cube-a-personal-journey">The Rubik‚Äôs Cube: A Personal Journey</h4><p>Ah, the Rubik‚Äôs Cube‚Äîa classic that‚Äôs equal parts intriguing and intimidating. My first encounter with it was‚Ä¶ chaotic, to say the least. Scrambling it was easy, but solving it? Let‚Äôs just say it took me more than a few attempts (and some YouTube tutorials) to get it right.</p><p>But once I did, it was magical. Solving a Rubik‚Äôs Cube is a dance of logic and intuition. It teaches you to think in layers, anticipate moves, and stay calm under pressure. And honestly, it‚Äôs just plain cool to whip one out and solve it in front of friends.</p><hr><h4 id="puzzles-meet-tech-the-rubiks-cube-solver">Puzzles Meet Tech: The Rubik‚Äôs Cube Solver</h4><p>Now imagine combining the worlds of physical and digital puzzles. That‚Äôs exactly what we‚Äôll be doing in the<strong>Rubik‚Äôs Cube Solver</strong> series. This project is a blend of hardware and software challenges‚Äîa perfect playground for anyone who loves puzzles.</p><p>The idea is to build a system that can solve a Rubik‚Äôs Cube autonomously. From understanding the cube‚Äôs mechanics to writing algorithms that optimize solutions, this project is as rewarding as it is complex. And here‚Äôs the best part: you‚Äôll get to learn and build alongside me.</p><p><em>Note</em>: This project is still in its simulation phase. There are optimizations to be made, and the hardware implementation is yet to be completed. But that‚Äôs the beauty of this series‚Äîwe‚Äôll question every step, learn from every mistake, and inch closer to the solution together.</p><hr><h4 id="introducing-the-pid-series">Introducing the PID Series</h4><p>The Rubik‚Äôs Cube Solver is just the beginning. The<strong>PID: Project IN Detail</strong> series is a deep dive into my projects, where I share insights, challenges, and breakthroughs. There‚Äôs a lot more to come, and I‚Äôm thrilled to have you along for the ride.</p><p>In the next few posts, we‚Äôll start with the basics of solving a Rubik‚Äôs Cube‚Äîthe foundational techniques that will help you tackle the puzzle manually. From there, we‚Äôll explore how computers can do it better, faster, and with optimizations we can only dream of.</p><hr><h4 id="why-wait-lets-get-started">Why Wait? Let‚Äôs Get Started!</h4><p>Puzzles are more than a pastime; they‚Äôre a way of thinking, learning, and growing. Whether you‚Äôre a coding enthusiast, a Rubik‚Äôs Cube aficionado, or just someone who loves a good challenge, this series has something for you.</p><p>So grab a cube, roll up your sleeves, and let‚Äôs dive into the fascinating world of puzzles‚Äîone twist at a time.</p>
]]></content:encoded></item><item><title>My RosConIN&amp;#39;24 Experience</title><link>https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/</link><pubDate>Fri, 17 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/</guid><description>&lt;![CDATA[<p>Last year, I missed ROSCon India due to exams and, honestly, had no idea what I was missing out on. This year, though, I made it, and it turned out to be more than I ever imagined. The two days I spent at ROSConIN'24 were nothing short of transformative, and this blog itself is a result of the inspiration I drew from the event.</p>]]></description><content:encoded>&lt;![CDATA[<p>Last year, I missed ROSCon India due to exams and, honestly, had no idea what I was missing out on. This year, though, I made it, and it turned out to be more than I ever imagined. The two days I spent at ROSConIN'24 were nothing short of transformative, and this blog itself is a result of the inspiration I drew from the event.</p><h3 id="setting-the-stage">Setting the Stage</h3><p>The second edition of ROSCon India, following the overwhelming success of last year‚Äôs event with 750+ attendees, was hosted by ARTPARK at the Indian Institute of Science (IISc), Bangalore. This event brought together developers, hobbyists, researchers, and industry professionals to share, learn, and network over all things ROS (Robot Operating System).</p><p>What makes ROSCon India special is its resemblance to the international ROSCon, with a local flavor that emphasizes India‚Äôs growing influence in robotics and automation. It was heartwarming to see support from Open Robotics and the enthusiastic efforts of Acceleration Robotics, RigBetel Labs, and ARTPARK in organizing such an impactful gathering.</p><h3 id="day-0-workshops-galore">Day 0: Workshops Galore</h3><p>The event kicked off with Workshop Day on December 4th. We could choose one out of three workshops, and I opted for the third one:</p><ol><li><p><strong>Workshop 1: Next-Gen Robotics Development with NVIDIA ISAAC, GenAI, and ROS</strong> ‚Äì Organized by NVIDIA, this workshop offered a comprehensive dive into cutting-edge robotics development. Though I couldn‚Äôt attend it, the buzz from the attendees made it clear how enriching it was.</p></li><li><p><strong>Workshop 2: Leveraging Zenoh as a ROS 2 Middleware Layer</strong> ‚Äì Conducted by Zettascale Technology, this session explored Zenoh as an innovative middleware layer for ROS 2. It intrigued many participants and opened up discussions on its potential.</p></li><li><p><strong>Workshop 3: ROS 2 Controls, Navigation, and Advanced Communication Study</strong> ‚Äì Organized by ARTPARK, this was my pick! A deep dive into ROS 2 controls, navigation, and communication felt perfectly aligned with my interests. The hands-on experience and insights I gained were invaluable.</p></li></ol><h3 id="day-1-a-conference-to-remember">Day 1: A Conference to Remember</h3><p>December 5th began with registrations and a warm welcome address by the organizers, setting an enthusiastic tone. Some highlights from the day included:</p><ul><li><strong>Keynotes</strong>: Geoffrey Biggs (CTO, Open Robotics) and Yadunund Vijay (Intrinsic) discussed the state of Open Robotics in 2024, followed by Jigar Halani from NVIDIA sharing insights on robotics development.</li><li><strong>Inspiring Talks</strong>: From Yuvraj Mehta‚Äôs session on RoboGPT to Sarvesh Kumar Malladi‚Äôs insights on Universal Robots‚Äô ROS2 features, each talk added depth to the learning experience.</li><li><strong>Industry Focus</strong>: Anish Dalvi from TCS delved into automotive protocols, while Somdeb Saha highlighted retail automation with ROS. Both sessions demonstrated the vast industrial applications of ROS.</li><li><strong>Panel Discussion</strong>: The day ended with an engaging panel on cracking the product-market fit in robotics, featuring founders and investors sharing valuable insights.</li></ul><h3 id="day-2-deep-dives-and-future-directions">Day 2: Deep Dives and Future Directions</h3><p>December 6th brought more enlightening sessions, including:</p><ul><li><strong>Keynote by Angelo Corsaro (ZettaScale Technology)</strong>: An in-depth look at Zenoh as an alternative middleware layer for ROS 2.</li><li><strong>Technical Sessions</strong>: From Ajay Sethi and Prateek Nagras introducing the Robotics Application Stack to Nidhi Choudhary‚Äôs integration of physics-based neural networks with Gazebo, the variety of topics covered was astounding.</li><li><strong>Fireside Chat</strong>: The event concluded with a thought-provoking discussion on the future of ROS, featuring Geoffrey Biggs, Yadunund Vijay, and Angelo Corsaro.</li></ul><h3 id="networking-and-personal-highlights">Networking and Personal Highlights</h3><p>One of the most fulfilling aspects of ROSConIN‚Äô24 was the chance to meet incredible people. I connected with alumni from my college, including Aryan Jaguste and Jatin Vera, whose experience in robotics left me inspired. I also met many other professionals who have been in this field for years, generously sharing their knowledge and encouraging me to keep learning and experimenting.</p><p>It was this vibrant exchange of ideas and stories that inspired me to start this blog. ROSConIN‚Äô24 wasn‚Äôt just a conference; it was a catalyst for my growth in the robotics domain.</p><h3 id="a-big-shoutout">A Big Shoutout</h3><p>A massive thanks to all the companies and individuals who made this event possible, including Acceleration Robotics, RigBetel Labs, ARTPARK, NVIDIA, Zettascale Technology, Tata Consultancy Services, Universal Robots, and many others like Autodiscovery, Botsoverkill, Bullwork, Golain, I-Hub Jodhpur, IISc, Kikobot, Nawe, Neuralzome, Thundroids, Vicharak, Virya, and xTerra.</p><h3 id="closing-thoughts">Closing Thoughts</h3><p>As I reflect on my experience, I can‚Äôt help but marvel at how much this event has broadened my horizons. It‚Äôs not just about the technical knowledge but also the sense of community and the shared passion for innovation. If you‚Äôre even remotely interested in robotics or automation, attending ROSConIN should be a no-brainer. Who knows? You might walk away with a new project idea, a mentor, or even the inspiration to start a blog, just like I did!</p><p>As if ROSConIN‚Äô24 wasn‚Äôt enough to fill my plate with excitement, the very next day, I found myself at the GNOME Asia Summit in Bangalore. It was an incredible opportunity to connect with open-source contributors and Linux enthusiasts. The vibe there was equally inspiring, and I came away with even more appreciation for the open-source community.</p><p>Speaking of Bangalore, let‚Äôs not forget the city&rsquo;s legendary traffic. I‚Äôll admit, navigating those jam-packed streets tested my patience (and Google Maps‚Äô sanity), but the morning chill and the sheer energy of being in India‚Äôs tech hub more than made up for it. If you‚Äôve never tried squeezing in two major conferences in one trip, let me tell you‚Äîit‚Äôs like a crash course in networking and caffeine dependency.</p><p>Meeting passionate individuals at both events has only fueled my curiosity to dive deeper into robotics and open source. In fact, it was during ROSConIN‚Äô24 that I felt inspired to start this tech blog, channeling my excitement and insights into something more tangible. And hey, if I can navigate Bangalore traffic and two back-to-back conferences, I‚Äôm pretty sure I can handle just about anything life throws my way!</p>
]]></content:encoded></item><item><title>Why Blog in 2025? (And How to Get Started)</title><link>https://mummanajagadeesh.github.io/blog/why-blog-in-2025/</link><pubDate>Fri, 10 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/why-blog-in-2025/</guid><description>&lt;![CDATA[<p>In 2025, with the internet brimming with TikToks, reels, and AI-generated articles, you might wonder‚Äî<strong>is blogging still worth it?</strong><br>
The answer is a resounding<strong>YES</strong>, and here‚Äôs why.</p>]]></description><content:encoded>&lt;![CDATA[<p>In 2025, with the internet brimming with TikToks, reels, and AI-generated articles, you might wonder‚Äî<strong>is blogging still worth it?</strong><br>
The answer is a resounding<strong>YES</strong>, and here‚Äôs why.</p><hr><h5 id="why-blog-in-2025"><strong>Why Blog in 2025?</strong></h5><h6 id="1-share-your-unique-perspective"><strong>1. Share Your Unique Perspective</strong></h6><p>In a world of AI-generated content,<strong>your personal voice matters more than ever</strong>. AI might generate the basics, but<strong>stories, experiences, and personal insights</strong> are uniquely human. Whether you‚Äôre building your first robot, sharing parenting tips, or learning a new language, your journey can inspire others.</p><blockquote><p>Think about it: How many times have you Googled a problem, stumbled upon a blog, and found exactly what you needed? That could be you helping someone else.</p></blockquote><hr><h6 id="2-build-your-digital-legacy"><strong>2. Build Your Digital Legacy</strong></h6><p>Your blog is<strong>your corner of the internet</strong>‚Äîa space to leave your mark. Unlike fleeting social media posts, blogs are evergreen, searchable, and<strong>build a record of your growth</strong>. For developers, it can be a portfolio of your work; for creatives, it‚Äôs a gallery of your creations.</p><blockquote><p>I started my blog to document my tech projects, but I realized it‚Äôs also helping me keep track of my ideas, progress, and experiments. Plus, I‚Äôve already met people who share the same passions‚Äîthanks to this little space!</p></blockquote><hr><h6 id="3-learn-as-you-share"><strong>3. Learn as You Share</strong></h6><p>Writing is an incredible teacher. To explain something clearly, you need to truly understand it yourself.</p><ul><li>Developers often blog about solutions to bugs or coding techniques, which not only helps others but reinforces their own knowledge.</li><li>For non-tech folks, writing about personal projects‚Äîwhether it‚Äôs DIY, cooking, or fitness‚Äîgives clarity and keeps you motivated.</li></ul><blockquote><p><strong>Pro Tip:</strong> Blogging can make you a better problem-solver. Breaking down problems into digestible steps is the essence of both writing and coding.</p></blockquote><hr><h6 id="4-build-connections-and-opportunities"><strong>4. Build Connections and Opportunities</strong></h6><p>Blogging isn‚Äôt just about putting your thoughts into words; it‚Äôs about<strong>starting conversations</strong>. Your blog can:</p><ul><li>Attract collaborators who resonate with your ideas.</li><li>Impress potential employers or clients by showcasing your expertise.</li><li>Connect you with a like-minded community.</li></ul><blockquote><p>Think of it as networking without the awkward handshakes.</p></blockquote><hr><h6 id="5-stay-relevant-in-the-ai-era"><strong>5. Stay Relevant in the AI Era</strong></h6><p>AI is great for automating tasks, but<strong>creativity, originality, and storytelling</strong>? That‚Äôs all you. A blog lets you flex those creative muscles and prove you‚Äôre not just keeping up with the times‚Äîyou‚Äôre shaping them.</p><hr><h6 id="why-students-should-start-blogging-"><strong>Why Students Should Start Blogging</strong> üéì</h6><p>As a student, blogging can be a game-changer for your personal and professional growth. Here‚Äôs why:</p><ol><li><p><strong>Showcase Your Skills</strong>:<br>
Your blog can act as a dynamic portfolio. Whether it‚Äôs coding projects, research papers, or even creative writing, it‚Äôs a platform to demonstrate your expertise and passion. Employers and professors love seeing initiative.</p></li><li><p><strong>Document Your Learning</strong>:<br>
Writing about what you‚Äôre learning‚Äîwhether it‚Äôs a tough algorithm, a robotics project, or study hacks‚Äîhelps reinforce your understanding and creates a resource for others.</p></li><li><p><strong>Stand Out</strong>:<br>
In a competitive world, a well-maintained blog sets you apart. It shows that you‚Äôre not just a passive learner but someone who actively contributes to the community.</p></li><li><p><strong>Build Connections</strong>:<br>
Blogging opens doors to collaborations, internships, and mentorships. Sharing your work publicly can attract like-minded peers, professors, or even recruiters.</p></li></ol><blockquote><p><strong>Pro Tip for Students</strong>: Start small. Write about a project or concept you recently worked on in class‚Äîit‚Äôs a great way to begin!</p></blockquote><hr><h5 id="how-to-start-blogging-in-2025"><strong>How to Start Blogging in 2025</strong></h5><p>If all this has convinced you, let‚Äôs talk about how to get started! Whether you‚Äôre a dev documenting code or someone sharing life hacks, blogging has never been easier.</p><hr><h6 id="1-choose-your-purpose"><strong>1. Choose Your Purpose</strong></h6><p>Ask yourself:<strong>Why do I want to blog?</strong></p><ul><li>Is it to document your journey (like me)?</li><li>Share your expertise?</li><li>Build a personal brand?</li><li>Just for fun?</li></ul><blockquote><p>Defining your purpose will help you stay motivated and give your blog a clear focus.</p></blockquote><hr><h6 id="2-pick-the-right-platform"><strong>2. Pick the Right Platform</strong></h6><p>Here are a few options to suit different needs:</p><ul><li><strong>Techies</strong>: Use GitHub Pages for free hosting or platforms like Jekyll/Hugo for custom setups.</li><li><strong>Beginners</strong>: Try WordPress or Ghost‚Äîthey‚Äôre user-friendly and have tons of templates.</li><li><strong>Minimalists</strong>: Substack or Medium are great for simple, distraction-free writing.</li></ul><blockquote><p><strong>What I Use</strong>: I opted for GitHub Pages because I love having full control over my blog‚Äôs look and feel.</p></blockquote><hr><h6 id="3-write-what-you-know-and-love"><strong>3. Write What You Know (And Love)</strong></h6><p>Find your niche. You don‚Äôt need to be an expert‚Äîjust share your journey as you learn.</p><ul><li>Devs: Write about side projects, tutorials, or debugging solutions.</li><li>Non-devs: Document hobbies, productivity hacks, or personal experiences.</li></ul><blockquote><p>Remember: What‚Äôs obvious to you might be groundbreaking to someone else.</p></blockquote><hr><h6 id="4-keep-it-simple-at-first"><strong>4. Keep It Simple (At First)</strong></h6><p>Don‚Äôt overcomplicate it. Your first post can be:</p><ul><li>An introduction to who you are.</li><li>A story about a project you worked on.</li><li>A simple ‚Äúlesson learned‚Äù post.</li></ul><blockquote><p>It‚Äôs okay if your first post isn‚Äôt perfect‚Äîit‚Äôs better to start and improve as you go.</p></blockquote><hr><h6 id="5-leverage-ai-to-help-you"><strong>5. Leverage AI to Help You</strong></h6><p>In 2025, AI tools can make blogging easier:</p><ul><li>Use<strong>ChatGPT</strong> for brainstorming post ideas.</li><li><strong>Grammarly</strong> can polish your grammar.</li><li>Tools like<strong>Jasper AI</strong> can even generate draft content.</li></ul><p>But remember:<strong>your voice is the star.</strong> AI can assist, but authenticity is irreplaceable.</p><hr><h6 id="6-promote-your-blog"><strong>6. Promote Your Blog</strong></h6><p>Once your blog is live, share it!</p><ul><li>Post about it on LinkedIn, Instagram, or Twitter.</li><li>Join communities (Reddit, Discord, forums) related to your niche.</li><li>Collaborate with others by guest-posting or linking to their work.</li></ul><blockquote><p>If you‚Äôre consistent, people will notice.</p></blockquote><hr><h6 id="7-embrace-the-process"><strong>7. Embrace the Process</strong></h6><p>Blogging is a journey. Don‚Äôt stress about being perfect‚Äîjust keep writing, experimenting, and learning. Tools like<strong>Google Analytics</strong> can show you what‚Äôs working and help you refine your style.</p><hr><h5 id="final-thoughts"><strong>Final Thoughts</strong></h5><p>Blogging in 2025 is about more than just writing‚Äîit‚Äôs about<strong>sharing your voice, building connections, and leaving a legacy</strong>. Whether you‚Äôre a coder, a hobbyist, or someone with a passion to share, there‚Äôs never been a better time to start.</p><blockquote><p><strong>Your Blog, Your Rules:</strong> It doesn‚Äôt have to be fancy. It just has to be<strong>you.</strong></p></blockquote><hr><h5 id="whats-next"><strong>What‚Äôs Next?</strong></h5><p>If you‚Äôre thinking of starting a blog, go for it! Your ideas are worth sharing. Feel free to reach out if you need help setting things up or brainstorming ideas‚ÄîI‚Äôd love to hear from you.</p><p>Ready to take the plunge? Hit that<strong>&ldquo;New Blog&rdquo;</strong> button and let the world hear your voice!</p><hr>
]]></content:encoded></item><item><title>Hello World!!</title><link>https://mummanajagadeesh.github.io/blog/hello-world/</link><pubDate>Fri, 03 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/hello-world/</guid><description>&lt;![CDATA[<p>Hello World! I‚Äôm<strong><em>Jagadeesh Mummana</em></strong>, and welcome to my blog dedicated to the fields of robotics, artificial intelligence, and various technological experiments I am engaged in.</p>]]></description><content:encoded>&lt;![CDATA[<p>Hello World! I‚Äôm<strong><em>Jagadeesh Mummana</em></strong>, and welcome to my blog dedicated to the fields of robotics, artificial intelligence, and various technological experiments I am engaged in.</p><p>If you have an interest in electronics, microcontrollers, or understanding technology, you may find the content here to be beneficial. My journey in this area has provided me with significant insights, and I believe it is time to document my experiences.</p><hr><h5 id="purpose-of-this-blog">Purpose of This Blog ¬†</h5><p>I started this blog mainly to organize and document what I‚Äôve learned from various projects. A lot of my work tends to get buried in random folders on my laptop, and I figured sharing it here might make it more useful‚Äînot just for me, but maybe for others too.</p><p>This blog allows me to organize my thoughts, share what I have learned, and connect with others who share similar interests in technology. Additionally, I plan to commit to a weekly post every<strong><em>random</em></strong> day to maintain consistency in my exploration and reflection. If you&rsquo;re interested in staying updated, consider subscribing to my newsletter on the right!.</p><blockquote><p><strong>Motto:</strong> &ldquo;Knowledge grows best when shared.&rdquo; ¬†</p></blockquote><hr><h5 id="about-me">About Me ¬†</h5><p>I am currently a sophomore at<strong>NIT Calicut</strong>, pursuing a degree in<strong>Electronics and Communication Engineering</strong> with a minor in<strong>Robotics and Automation</strong>.</p><p>I have a passion for constructing and deconstructing various systems to understand their functionality. My primary focus lies at the intersection of software and hardware, where innovative solutions often emerge.</p><p>It is important to note that I tend to have many ongoing projects simultaneously, which can sometimes hinder completion. I hope this blog serves as a motivation to follow through on more of these endeavors.</p><hr><h5 id="current-projects-">Current Projects üîç ¬†</h5><p>I work on a lot of different projects, some finished, some still in progress. Here are just a few that reflect my interests‚Äîfind all on my Projects Page.</p><ol><li><strong><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM</a></strong> ‚Äì<em>Prosthetic Arm</em> ¬†
This project involves creating a prosthetic arm that mimics finger movements using servos to create tension similar to biological tendons. ¬†</li></ol><figure class="img-center" role="group" aria-describedby="caption-Prosthetic Arm Prototype"><img title="" loading="lazy" decoding="async" class="img " width="900" height="503" src="/images/post/hw/prosarm_hu4681128037264936396.webp" alt="alter-text" onerror="this.onerror='null';this.src='\/images\/post\/hw\/prosarm_hu11497401644345071069.png'"/><figcaption id="caption-Prosthetic Arm Prototype" class="caption-Prosthetic-Arm-Prototype">
Prosthetic Arm Prototype</figcaption></figure><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><ol start="2"><li><strong><a href="https://github.com/Mummanajagadeesh/V-RU81K5CU83" target="_blank">V-RU81K5CU83</a></strong> (<em>part of<a href="https://github.com/Mummanajagadeesh/RU83C" target="_blank">RU83C</a></em>) ‚Äì<em>Virtual Rubik&rsquo;s Cube Simulator</em> ¬†
This is a 3D Rubik‚Äôs Cube simulator designed in Unity, utilizing the Kociemba Solver to provide solutions based on the cube‚Äôs current configuration. ¬†</li></ol><figure class="img-center" role="group" aria-describedby="caption-Virtual Rubik&rsquo;s Cube Simulator"><img title="" loading="lazy" decoding="async" class="img " width="900" height="510" src="/images/post/hw/vrubikscube_hu15748914767339416372.webp" alt="alter-text" onerror="this.onerror='null';this.src='\/images\/post\/hw\/vrubikscube_hu5853377216002858037.png'"/><figcaption id="caption-Virtual Rubik&rsquo;s Cube Simulator" class="caption-Virtual-Rubiks-Cube-Simulator">
Virtual Rubik&rsquo;s Cube Simulator</figcaption></figure><ol start="3"><li><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe</a></strong> ‚Äì<em>Image Processing Using Verilog</em> ¬†
This project focuses on applying Verilog for image processing techniques such as edge detection and geometric transformations. Here are two spin-offs from this work:</li></ol><figure class="img-center" role="group" aria-describedby="caption-Label Detection Using Prewitt Operator"><img title="" loading="lazy" decoding="async" class="img " width="900" height="639" src="/images/post/hw/label-detec_hu14937165004100200016.webp" alt="alter-text" onerror="this.onerror='null';this.src='\/images\/post\/hw\/label-detec_hu13542012983157751631.png'"/><figcaption id="caption-Label Detection Using Prewitt Operator" class="caption-Label-Detection-Using-Prewitt-Operator">
Label Detection Using Prewitt Operator</figcaption></figure><p>¬† ¬†-<strong>Label Detection</strong>: ¬†
This involves utilizing the Prewitt and Canny edge detectors to identify label boundaries based on sudden intensity changes. Python is used to compile the results. ¬†</p><p>¬† ¬†-<strong>Document Scanner</strong> (<em>In Progress</em>): ¬†
Building off the label detection principles, this project aims to identify the corners of a document and map these onto a rectangular frame. I aspire to incorporate Optical Character Recognition (OCR) for text extraction as well.</p><hr><blockquote><p><strong>Note:</strong> Some repositories are currently private due to various constraints. Should you have an inquiry about any of these projects, please feel free to reach out, and I will do my best to share what I can.</p></blockquote><hr><h5 id="future-directions">Future Directions ¬†</h5><p>In the near future, I aim to delve deeper into these projects by providing tutorials, lessons, and sharing insights from the challenges I encounter along the way.</p><p>If you have any suggestions for topics or projects that you would like to see discussed, please do not hesitate to contact me.</p><hr><h5 id="lets-collaborate-">Let‚Äôs Collaborate ü§ù ¬†</h5><p>If anything here caught your eye, or if you‚Äôve got a project in mind you‚Äôd like to team up on, hit me up. Collaboration is one of the best ways to learn, and I‚Äôd love to hear what you‚Äôre working on too.</p><hr><h5 id="connect-with-me-">Connect With Me üåê ¬†</h5><p>Here‚Äôs where you can find me: ¬†</p><ul><li>üåå<strong>Portfolio</strong>:<a href="https://mummanajagadeesh.github.io" target="_blank">mummanajagadeesh.github.io</a> ¬†</li><li>üíº<strong>LinkedIn</strong>:<a href="https://www.linkedin.com/in/jagadeeeshmummana" target="_blank">Jagadeesh Mummana</a> ¬†</li><li>üîß<strong>GitHub</strong>:<a href="https://github.com/Mummanajagadeesh" target="_blank">Mummanajagadeesh</a> ¬†</li><li>üì∏<strong>Instagram</strong>:<a href="https://www.instagram.com/jagadeesh__97__" target="_blank">@jagadeesh__97__</a> ¬†</li></ul><hr><p>If any of this interests you, stick around! I‚Äôm always learning and trying new things, and I‚Äôd love to share that journey with you. Looking forward to exploring more together!</p>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/diffdrive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/diffdrive/</guid><description>&lt;![CDATA[<h2 id="differential-drive-robot-simulationhttpsgithubcommummanajagadeeshdifferential-drive-robot-w"><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">Differential Drive Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Differential Drive Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A custom-built robot featuring a differential drive system that calculates its position and movement based on wheel rotations</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">DDRüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This repository contains the simulation of a<strong>Differential Drive Robot</strong>, built from scratch, which uses basic odometry to track its position. The robot is equipped with motors and position sensors to calculate its movement and orientation while navigating the environment.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="differential-drive-robot-simulationhttpsgithubcommummanajagadeeshdifferential-drive-robot-w"><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">Differential Drive Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Differential Drive Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A custom-built robot featuring a differential drive system that calculates its position and movement based on wheel rotations</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">DDRüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This repository contains the simulation of a<strong>Differential Drive Robot</strong>, built from scratch, which uses basic odometry to track its position. The robot is equipped with motors and position sensors to calculate its movement and orientation while navigating the environment.</p><h4 id="demo-video"><strong>Demo Video</strong></h4><p>Click the image below to watch a demo of the robot in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/FwafE7gGxxY" frameborder="0" allowfullscreen=/></div></div><hr><h4 id="how-it-works"><strong>How It Works</strong></h4><h5 id="robot-design"><strong>Robot Design</strong></h5><p>The robot moves using<strong>two independent motors</strong> and tracks its position using<strong>two position sensors</strong>.</p><ul><li><strong>Motors</strong>: The left and right wheels have separate motors, allowing the robot to move forward, turn, or rotate in place.</li><li><strong>Position Sensors</strong>: These track how much each wheel has moved, which is used for odometry (position tracking).</li></ul><h5 id="odometry-calculation"><strong>Odometry Calculation</strong></h5><p>The robot calculates its position based on:</p><ul><li><strong>Wheel Movement</strong>: It reads the sensor values to determine how far each wheel has traveled.</li><li><strong>Position Updates</strong>: Using this data, the robot calculates its new<code>(x, y, Œ∏)</code> coordinates.</li><li><strong>Velocity Computation</strong>: The robot computes both<strong>linear speed (v)</strong> and<strong>angular speed (w)</strong> to track its movement.</li></ul><p>The position updates continuously as the robot moves in the simulation.</p><hr><h4 id="code-explanation"><strong>Code Explanation</strong></h4><h5 id="1-odometry-calculation-tracking-the-robots-position"><strong>1. Odometry Calculation (Tracking the Robot‚Äôs Position)</strong></h5><ul><li>Reads values from the<strong>position sensors</strong> to determine how far the wheels have moved.</li><li>Converts sensor readings into<strong>distance traveled</strong>.</li><li>Updates the<strong>robot‚Äôs position and orientation</strong> using trigonometric calculations.</li><li>Continuously prints the<strong>current position (x, y, Œ∏)</strong> of the robot.</li></ul><h5 id="2-robot-motion-control-making-the-robot-move"><strong>2. Robot Motion Control (Making the Robot Move)</strong></h5><ul><li>Sets<strong>both wheels at full speed</strong> to move forward.</li><li>Adjusts<strong>wheel speeds differently</strong> to turn:<ul><li>Turns<strong>right</strong> when needed.</li><li>Moves<strong>straight</strong> otherwise.</li></ul></li></ul><h5 id="3-square-path-movement"><strong>3. Square Path Movement</strong></h5><ul><li>The robot moves in a<strong>square pattern</strong> by following a sequence:<ul><li><strong>Moves forward for a fixed distance</strong>.</li><li><strong>Rotates 90 degrees</strong>.</li><li><strong>Repeats</strong> until a full square is completed.</li></ul></li><li>The<strong>timing of movements and turns</strong> is pre-calculated to ensure accuracy.</li></ul><hr><h4 id="installation-and-usage"><strong>Installation and Usage</strong></h4><h5 id="requirements"><strong>Requirements</strong></h5><ul><li><strong>Webots</strong>: Download and install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure Python is installed for running the controller code.</li></ul><h5 id="steps-to-run"><strong>Steps to Run</strong></h5><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/differential-drive-robot-w.git</span></span><span style="display:flex;"><span>cd differential-drive-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>differential_drive_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation to observe the robot‚Äôs movement and odometry in action.</li></ol><hr><h4 id="future-enhancements"><strong>Future Enhancements</strong></h4><ul><li><strong>Path Following</strong>: Implement algorithms for following predefined paths.</li><li><strong>Advanced Sensors</strong>: Add ultrasonic sensors for obstacle detection.</li><li><strong>Improved Control</strong>: Implement PID controllers for smoother movement.</li></ul><hr>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/gpbot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/</guid><description>&lt;![CDATA[<h2 id="gpbot---basic-sensor-based-general-purpose-amrhttpsgithubcommummanajagadeeshgpbot-w"><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOT - Basic Sensor based General Purpose AMR</a></h2><table><thead><tr><th><strong>Name</strong></th><th>GPBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This 4-wheeled robot is equipped with GPS, IMU, LiDAR, Distance Sensors, and a 2-DOF camera (using linear and rotary actuators). It detects objects using computer vision, avoids obstacles, and navigates autonomously.</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOTüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><h3 id="overview">Overview</h3><p>The robot is equipped with<strong>GPS, IMU, LiDAR, and a 2-DOF camera</strong>, enabling it to detect objects using computer vision, avoid obstacles, and navigate autonomously.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="gpbot---basic-sensor-based-general-purpose-amrhttpsgithubcommummanajagadeeshgpbot-w"><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOT - Basic Sensor based General Purpose AMR</a></h2><table><thead><tr><th><strong>Name</strong></th><th>GPBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This 4-wheeled robot is equipped with GPS, IMU, LiDAR, Distance Sensors, and a 2-DOF camera (using linear and rotary actuators). It detects objects using computer vision, avoids obstacles, and navigates autonomously.</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOTüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><h3 id="overview">Overview</h3><p>The robot is equipped with<strong>GPS, IMU, LiDAR, and a 2-DOF camera</strong>, enabling it to detect objects using computer vision, avoid obstacles, and navigate autonomously.</p><h4 id="live-interaction">Live Interaction</h4><p>Interact with the robot in real-time via the following link:</p><p><a href="https://webots.cloud/ScKiz83?upload=webots" target="_blank">CLOUD INTERACTION_WEBOTS</a></p><h3 id="demo-videos">Demo Videos</h3><p>Explore the robot‚Äôs functionalities through these demo videos:</p><table><thead><tr><th>Camera Test</th><th>Object Detection</th><th>LiDAR in Action</th></tr></thead><tbody><tr><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/rqTKV85uOz4" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/wl0mYWiO184" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/9qBLSOo2feE" frameborder="0" allowfullscreen=/></div></div></td></tr></tbody></table><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="576" src="/images/projects/gpbot/gpbot_hu16267225310171384651.webp" alt="GPBOT" onerror="this.onerror='null';this.src='\/images\/projects\/gpbot\/gpbot_hu17654837491023740790.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h3 id="robot-overview">Robot Overview</h3><h4 id="features">Features:</h4><ul><li><strong>4-Wheeled Mobility:</strong> Designed for efficient movement in diverse environments.</li><li><strong>Sensor Suite:</strong><ul><li><strong>GPS:</strong> Provides global positioning and navigation.</li><li><strong>IMU:</strong> Tracks orientation and movement.</li><li><strong>LiDAR:</strong> Maps the surroundings and detects obstacles.</li><li><strong>2-DOF Camera:</strong> Offers flexible vision capabilities with linear and rotary actuation.</li></ul></li><li><strong>Autonomous Operation:</strong> The robot navigates without relying on complex algorithms, utilizing basic control mechanisms.</li></ul><h3 id="controls">Controls</h3><p>The following key mappings define the robot‚Äôs movement and camera operations:</p><h4 id="movement-controls">Movement Controls</h4><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>‚Üë</td><td>Move forward</td></tr><tr><td>‚Üì</td><td>Move backward</td></tr><tr><td>‚Üê</td><td>Turn left</td></tr><tr><td>‚Üí</td><td>Turn right</td></tr></tbody></table><h4 id="camera-controls">Camera Controls</h4><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>W</td><td>Move camera up</td></tr><tr><td>S</td><td>Move camera down</td></tr><tr><td>A</td><td>Rotate camera left (ACW)</td></tr><tr><td>D</td><td>Rotate camera right (CW)</td></tr></tbody></table><h4 id="control-visualization">Control Visualization</h4><h5 id="movement">Movement</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span> ‚îå‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îê</span></span><span style="display:flex;"><span> ‚îÇ ‚Üê ‚îÇ‚îÇ ‚Üë ‚îÇ‚îÇ ‚Üí ‚îÇ</span></span><span style="display:flex;"><span> ‚îÇ ‚Üê ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚Üí ‚îÇ</span></span><span style="display:flex;"><span> ‚îÇ ‚Üê ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚Üí ‚îÇ</span></span><span style="display:flex;"><span> ‚îÇ ‚Üê ‚îÇ‚îÇ ‚Üì ‚îÇ‚îÇ ‚Üí ‚îÇ</span></span><span style="display:flex;"><span> ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îò</span></span></code></pre></div><h5 id="camera">Camera</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span> ‚îå‚îÄ‚îÄ‚îÄ‚îê</span></span><span style="display:flex;"><span> ‚îÇ W ‚îÇ</span></span><span style="display:flex;"><span> ‚îî‚îÄ‚îÄ‚îÄ‚îò</span></span><span style="display:flex;"><span> ‚îå‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îê</span></span><span style="display:flex;"><span> ‚îÇ A ‚îÇ‚îÇ S ‚îÇ‚îÇ D ‚îÇ</span></span><span style="display:flex;"><span> ‚îî‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îò</span></span></code></pre></div><h3 id="implementation-details">Implementation Details</h3><p>The robot has been built from scratch, integrating multiple sensors to enhance its navigation and detection abilities.</p><ul><li><strong>Camera Functionality:</strong> The 2-DOF camera captures images and analyzes the environment for object recognition.</li><li><strong>Object Detection:</strong> Using computer vision, the robot identifies and reacts to obstacles in its path.</li></ul><h3 id="installation-and-usage">Installation and Usage</h3><h4 id="requirements">Requirements</h4><ul><li><strong>Webots:</strong> Download and install Webots from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li></ul><h4 id="setup-instructions">Setup Instructions</h4><ol><li>Clone the repository:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/gpbot-w.git</span></span><span style="display:flex;"><span>cd gpbot-w</span></span></code></pre></div></li><li>Open Webots and load the robot‚Äôs world file.</li><li>Start the simulation to test the robot‚Äôs capabilities.</li></ol><h3 id="future-enhancements">Future Enhancements</h3><ul><li><strong>Algorithm Integration:</strong> Implement advanced path planning and control algorithms.</li><li><strong>Enhanced Object Recognition:</strong> Utilize AI-based models for improved object detection.</li><li><strong>Multi-Robot Coordination:</strong> Develop cooperative strategies for multiple robots in a shared space.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/i2cv/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/i2cv/</guid><description>&lt;![CDATA[<h2 id="i2c-protocol-verilog-implementation-using-fsmhttpsgithubcommummanajagadeeshi2c-protocol-verilog"><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2C Protocol Verilog Implementation using FSM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>I2C Protocol</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of I2C Protocol using Finite State Machine (FSM) design</td></tr><tr><td><strong>Start</strong></td><td>06 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2CVüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Protocols, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project implements the I2C protocol in Verilog with various versions and configurations. Below is a summary of each version:</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="i2c-protocol-verilog-implementation-using-fsmhttpsgithubcommummanajagadeeshi2c-protocol-verilog"><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2C Protocol Verilog Implementation using FSM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>I2C Protocol</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of I2C Protocol using Finite State Machine (FSM) design</td></tr><tr><td><strong>Start</strong></td><td>06 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2CVüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Protocols, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project implements the I2C protocol in Verilog with various versions and configurations. Below is a summary of each version:</p><h4 id="v102---simple-master-slave-no-clock-stretching">v1.0.2 - Simple Master-Slave (No Clock Stretching)</h4><ul><li><strong>Description</strong>: This version implements a simple I2C protocol with one master and one slave device. It does not support clock stretching.</li><li><strong>Features</strong>:<ul><li>Basic I2C communication between a single master and slave.</li><li>No handling of clock stretching; both master and slave devices operate with the same clock frequency.</li><li>NACK will be raised indicating that the given address for slave is wrong.</li></ul></li></ul><h4 id="v203---clock-stretching-with-fixed-master-delay">v2.0.3 - Clock Stretching with Fixed Master Delay</h4><ul><li><strong>Description</strong>: This version adds support for clock stretching. The master introduces a fixed delay after sending each data frame, and the SCL line will be held low (clock stretching) while waiting for the slave.</li><li><strong>Features</strong>:<ul><li>Clock stretching is supported for managing communication timing.</li><li>The master introduces a fixed delay to simulate real-world clock stretching scenarios.</li></ul></li></ul><h4 id="v204---clock-stretching-with-configurable-master-delay">v2.0.4 - Clock Stretching with Configurable Master Delay</h4><ul><li><strong>Description</strong>: This version builds on v2.0.3 by adding a configurable delay from the testbench. The delay allows adjusting the time period that the SCL line waits, providing greater flexibility.</li><li><strong>Features</strong>:<ul><li>Configurable master delay, adjustable from the testbench.</li><li>SCL waiting period comparison between the master and slave devices.</li><li>Enhanced clock stretching handling with configurable delays.</li></ul></li></ul><h4 id="v301---multi-slave-single-master-configuration">v3.0.1 - Multi-Slave Single Master Configuration</h4><ul><li><strong>Description</strong>: This version introduces a configuration with a single master and multiple slave devices. The master can communicate with any of the slaves, supporting multi-slave communication.</li><li><strong>Features</strong>:<ul><li>One master can communicate with multiple slaves.</li><li>The master can address and select any slave for communication.</li><li>Basic multi-slave handling without clock stretching.</li></ul></li></ul><h4 id="v311---multi-slave-multi-master-configuration">v3.1.1 - Multi-Slave Multi-Master Configuration</h4><ul><li><strong>Description</strong>: The latest version supports a multi-master, multi-slave configuration, where both the master and slaves can initiate communication. It adds complexity to handle multiple devices that can take control of the bus.</li><li><strong>Features</strong>:<ul><li>Multiple masters can communicate with multiple slaves.</li><li>Advanced bus arbitration is implemented to handle multiple masters trying to access the bus at the same time.</li><li>Suitable for complex systems requiring both multiple masters and multiple slaves.</li></ul></li></ul><p>I2C combines the strengths of both UART and
SPI. It operates using just two wires, like asynchronous serial, yet
supports communication with up to 1,008 peripheral devices. Unlike SPI,
I2C accommodates multi-controller systems, allowing more than one
controller to communicate with all peripheral devices on the bus
(although the controllers must take turns using the bus lines).</p><p>I2C data rates fall between those of asynchronous serial and SPI, with
most devices communicating at 100 kHz or 400 kHz. While there is some
overhead&mdash;requiring one additional acknowledgment (ACK/NACK) bit for
every 8 bits of data transmitted&mdash;I2C remains efficient. Although
implementing I2C requires more complex hardware than SPI, it is still
simpler than asynchronous serial and can be easily realized in software.</p><figure id="fig:i2c_block_diagram"><span class="image placeholder" data-original-image-src="i2c_block_diagram.png" data-original-image-title="" width="80%"/><figcaption>Block Diagram of an I2C System</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="600" src="/images/projects/i2cv/i2c_block_diagram_hu9724975040744162600.webp" alt="Block Diagram of an I2C System" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/i2c_block_diagram_hu8969938300534542992.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="physical-layer">Physical layer</h4><h5 id="two-wire-communication">Two-Wire Communication</h5><p>An I2C system utilizes<strong>two shared communication lines</strong> for all
devices on the bus. These two lines facilitate<strong>bidirectional,
half-duplex communication</strong>. I2C supports multiple controllers and
multiple target devices, making it a flexible choice for various
applications. It is essential to use<strong>pull-up resistors</strong> on both of
these lines to ensure proper operation. Fig<a href="#fig:i2c_implementation">2.4</a>{reference-type=&ldquo;ref&rdquo;
reference=&ldquo;fig:i2c_implementation&rdquo;} shows a typical implementation of
the I2C physical layer.</p><figure id="fig:i2c_implementation"><span class="image placeholder" data-original-image-src="i2c_physical_layer.png" data-original-image-title="" width="80%"/><figcaption>Typical I2C Implementation</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="377" src="/images/projects/i2cv/i2c_physical_layer_hu5001890849971727351.webp" alt="Typical I2C Implementation" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/i2c_physical_layer_hu5413651912767855860.png'"/><p>One of the main reasons that I2C is a widely adopted protocol is due to
its requirement of only<strong>two lines</strong> for communication. The first line,<strong>SCL</strong>, is the serial clock line, primarily controlled by the
controller device. SCL is responsible for synchronously clocking data in
or out of the target device. The second line,<strong>SDA</strong>, is the serial
data line, used to transmit data to or from the target devices. For
instance, a controller device can send configuration data and output
codes to a target<strong>digital-to-analog converter (DAC)</strong>, or a target<strong>analog-to-digital converter (ADC)</strong> can send conversion data back to
the controller device.</p><p>I2C operates as a<strong>half-duplex communication</strong> protocol, meaning that
only one controller or target device can send data on the bus at any
given time. In contrast, the<strong>Serial Peripheral Interface (SPI)</strong> is a<strong>full-duplex protocol</strong> that allows data to be sent and received
simultaneously, requiring four lines for communication: two data lines
for sending and receiving data, along with a serial clock and a unique
SPI chip select line to select the device for communication.</p><p>An I2C controller device initiates and terminates communication, which
eliminates potential issues related to<strong>bus contention</strong>. Communication
with a target device is established through a<strong>unique address</strong> on the
bus, allowing multiple controllers and multiple target devices to
coexist on the I2C bus.</p><p>The SDA and SCL lines have an<strong>open-drain connection</strong> to all devices
on the bus, necessitating a pull-up resistor connected to a common
voltage supply.</p><h5 id="open-drain-connection">Open-Drain Connection</h5><p>The<strong>open-drain connections</strong> are employed on both the SDA and SCL
lines and are linked to an NMOS transistor. This open-drain
configuration manages the I2C communication line by either pulling the
line low or allowing it to rise to a high state. The term "open-drain"
refers to the NMOS bus connection when the NMOS is turned<strong>OFF</strong>.
Figure<a href="#fig:open_drain_connection">2.5</a>{reference-type=&ldquo;ref&rdquo;
reference=&ldquo;fig:open_drain_connection&rdquo;} illustrates the open-drain
connection when the NMOS is turned<strong>ON</strong>.</p><figure id="fig:open_drain_connection"><span class="image placeholder" data-original-image-src="open_drain_connection.png" data-original-image-title="" width="80%"/><figcaption>Open-Drain Connection Pulls Line Low When NMOS is Turned
On</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="408" src="/images/projects/i2cv/open_drain_connection_hu11847467768529842632.webp" alt="Open-Drain Connection Pulls Line Low When NMOS is Turned On" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/open_drain_connection_hu6074012038034762589.png'"/><p>To establish the voltage level of the SDA or SCL line, the NMOS
transistor is either switched<strong>ON</strong> or<strong>OFF</strong>. When the NMOS is<strong>ON</strong>, it allows current to flow through the resistor to ground,
effectively pulling the open-drain line low. This transition from high
to low is typically rapid, as the NMOS quickly discharges any
capacitance on the SDA or SCL lines.</p><p>When the NMOS turns<strong>OFF</strong>, the device ceases to pull current, and the
pull-up resistor subsequently raises the SDA or SCL line back to<strong>VDD</strong>. Figure<a href="#fig:open_drain_off">2.6</a>{reference-type=&ldquo;ref&rdquo;
reference=&ldquo;fig:open_drain_off&rdquo;} shows the open-drain line when the NMOS
is turned<strong>OFF</strong>, illustrating how the pull-up resistor brings the line
high.</p><figure id="fig:open_drain_off"><span class="image placeholder" data-original-image-src="open_drain_off.png" data-original-image-title="" width="80%"/><figcaption>Open-Drain Line with NMOS Turned Off</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="469" src="/images/projects/i2cv/open_drain_off_hu4560108909222930383.webp" alt="Open-Drain Line with NMOS Turned Off" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/open_drain_off_hu5878766402834574374.png'"/><p>The transition of the open-drain line to a high state is slower because
the line is pulled up against the bus capacitance, rather than being
actively driven high.</p><h4 id="i2c-protocol">I2C Protocol</h4><p>Communication over<strong>I2C</strong> requires a specific signaling protocol to
ensure that devices on the bus recognize valid I2C transmissions. While
this process is more intricate than<strong>UART</strong> or<strong>SPI</strong>, most
I2C-compatible devices handle the finer protocol details internally,
allowing developers to focus primarily on data exchange.</p><p><strong>SDA and SCL Lines:</strong> The I2C bus operates with two main lines:<strong>SDA</strong>
(Serial Data Line) and<strong>SCL</strong> (Serial Clock Line). Data is transmitted
over the<strong>SDA</strong> line in sync with clock pulses on the<strong>SCL</strong> line.
Generally, data is placed on<strong>SDA</strong> when<strong>SCL</strong> is low, and devices
sample this data when<strong>SCL</strong> goes high. If needed, multiple internal<strong>registers</strong> may control data handling, especially in complex devices.</p><p><strong>Protocol Components:</strong></p><p>1.<strong>Start Condition:</strong> To initiate communication, the controller sets<strong>SCL</strong> high and then pulls<strong>SDA</strong> low. This signals all peripheral
devices on the bus that a transmission is starting. In cases where
multiple controllers attempt to start communication simultaneously, the
first device to pull<strong>SDA</strong> low gains control. If necessary, the
controller can issue repeated start conditions to maintain bus control
without releasing it.</p><p>2.<strong>Address Frame:</strong> Every I2C transmission begins with an<strong>address
frame</strong> to specify the target peripheral. This frame consists of a 7-bit
address, sent<strong>MSB</strong> (most significant bit) first, followed by a<strong>R/W
bit</strong> indicating the operation type (read or write).</p><p>After this, the 9th bit, known as the<strong>ACK/NACK bit</strong>, is used by the
receiving device to confirm reception. If the device pulls<strong>SDA</strong> low
before the 9th clock pulse (<strong>ACK</strong>), communication continues. If not
(<strong>NACK</strong>), it indicates either unrecognized data or an issue in
reception, prompting the controller to decide the next steps.</p><p>3.<strong>Data Frames:</strong> Following the address frame, one or more<strong>data
frames</strong> are sent over the<strong>SDA</strong> line. Each data frame is 8 bits, and
data is transferred from the controller to the peripheral or vice versa,
based on the<strong>R/W bit</strong> in the address frame.</p><p>Many peripheral devices have auto-incrementing<strong>internal registers</strong>,
enabling data to continue from consecutive registers without the need to
re-specify the register address.</p><p>4.<strong>Stop Condition:</strong> The controller ends communication by generating
a<strong>stop condition</strong>. This is done by transitioning<strong>SDA</strong> from low to
high after a high-to-low transition on<strong>SCL</strong>, with<strong>SCL</strong> held high
during the stop sequence. To avoid false stop conditions, the value on<strong>SDA</strong> should not change while<strong>SCL</strong> is high during regular data
transmission.</p><p>The<strong>I2C protocol</strong> divides communication into structured<strong>frames</strong>.
Each communication sequence begins with a<strong>START</strong> condition, initiated
by the controller, followed by an<strong>address frame</strong> and then one or more<strong>data frames</strong>. Every frame also includes an acknowledgment (ACK) bit,
signaling that the frame has been received successfully by the intended
device.<strong>Figure 3-3</strong> illustrates the structure of two I2C
communication frames, showing both address and data frames in detail.</p><figure id="fig:i2c_frames"><span class="image placeholder" data-original-image-src="i2c_frames.png" data-original-image-title="" width="80%"/><figcaption>I2C Address and Data Frames</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="214" src="/images/projects/i2cv/i2c_frames_hu8079952379911720152.webp" alt="I2C Address and Data Frames" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/i2c_frames_hu17776359726810003991.png'"/><p>In an I2C transaction, the controller first sends a<strong>START condition</strong>
by pulling the<strong>SDA</strong> line low, followed by the<strong>SCL</strong> line. This
sequence asserts control over the bus, preventing other devices from
interfering. Each target device on the I2C bus has a unique<strong>7-bit
address</strong>, allowing the controller to specify which target device it
intends to communicate with.</p><p>Once the address is set on<strong>SDA</strong> while<strong>SCL</strong> acts as the clock, the<strong>8th bit</strong> (R/W bit) indicates the intended operation type:<strong>read
(1)</strong> or<strong>write (0)</strong>. This initial address and R/W bit are followed by
an<strong>ACK bit</strong>, sent by the target device to confirm receipt. If the
target device receives the address successfully, it pulls<strong>SDA</strong> low
during the next<strong>SCL</strong> pulse, signaling an ACK. If no device
acknowledges, the line remains high, signaling a<strong>NACK</strong>.</p><p>After the address frame, one or more<strong>data frames</strong> follow. Each data
frame contains 8 bits of data, which are acknowledged (ACK) in the 9th
bit. If the data frame is a<strong>write</strong> operation, the target device pulls<strong>SDA</strong> low to confirm data receipt. For<strong>read</strong> operations, the
controller pulls<strong>SDA</strong> low to acknowledge receipt of the data. The
presence or absence of the ACK is essential for troubleshooting, as a
missing ACK may indicate an addressing error or transmission failure.</p><p>Finally, the communication ends with a<strong>STOP condition</strong>, where the
controller releases<strong>SCL</strong> first, followed by<strong>SDA</strong>. This action
releases the I2C bus for other devices to use, completing the
communication cycle.</p><p>This structured protocol allows for the transmission of multiple bytes
within one communication sequence. In cases where a target device has
multiple internal<strong>registers</strong>, a write operation can specify the
register to read or write data to, enhancing flexibility and enabling
complex data transactions.</p><h1 id="module-specifications">Module Specifications</h1><h4 id="master-module">MASTER MODULE</h4><h5 id="c0d3">C0d3</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Main module declaration</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">module</span> i2c_master(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> clk,<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rst,<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr,<span style="color:#75715e">// 7-bit I2C slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in,<span style="color:#75715e">// Data to send to slave in write mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> enable,<span style="color:#75715e">// Start signal for I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rw,<span style="color:#75715e">// Read/Write control (0 for write, 1 for read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out,<span style="color:#75715e">// Data received from slave in read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> ready,<span style="color:#75715e">// Indicates when the master is ready for a new transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> i2c_sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_scl<span style="color:#75715e">// I2C clock line (SCL) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Define states for I2C master FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> IDLE<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> START<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> ADDRESS<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> WRITE_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> WRITE_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_ACK2<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> STOP<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> DIVIDE_BY<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;<span style="color:#75715e">// Clock divider to generate I2C clock from system clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state;<span style="color:#75715e">// Current state of the FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] saved_addr;<span style="color:#75715e">// Stores the 7-bit address and RW bit for the current transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] saved_data;<span style="color:#75715e">// Data to be sent in write transactions</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter;<span style="color:#75715e">// Bit counter for data/address transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter2<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Divider counter for generating i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> write_enable;<span style="color:#75715e">// Controls whether the master drives SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_out;<span style="color:#75715e">// Data to output on SDA line when write_enable is 1</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> i2c_scl_enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Controls the state of the i2c_scl line (enabled or high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> i2c_clk<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Internal I2C clock signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Ready signal is high when the master is idle and not in reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> ready<span style="color:#f92672">=</span> ((rst<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (state<span style="color:#f92672">==</span> IDLE))<span style="color:#f92672">?</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// I2C SCL signal: High when i2c_scl_enable is low; otherwise, driven by i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> i2c_scl<span style="color:#f92672">=</span> (i2c_scl_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">?</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> i2c_clk;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// SDA line is driven by sda_out when write_enable is high; otherwise, it's in high-impedance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> i2c_sda<span style="color:#f92672">=</span> (write_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">?</span> sda_out<span style="color:#f92672">:</span> 'bz;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// I2C clock divider: Divides system clock to generate i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter2<span style="color:#f92672">==</span> (DIVIDE_BY<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_clk<span style="color:#f92672">&lt;=</span><span style="color:#f92672">~</span>i2c_clk;<span style="color:#75715e">// Toggle i2c_clk when half period is reached</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter2<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Reset the divider counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter2<span style="color:#f92672">&lt;=</span> counter2<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Increment the divider counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Enable/disable I2C clock based on current state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Disable SCL on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((state<span style="color:#f92672">==</span> IDLE)<span style="color:#f92672">||</span> (state<span style="color:#f92672">==</span> START)<span style="color:#f92672">||</span> (state<span style="color:#f92672">==</span> STOP))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// SCL is disabled in IDLE, START, and STOP states</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SCL in other states</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// State machine for controlling the I2C master operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Reset state to IDLE on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span> (state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> IDLE:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (enable)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> START;<span style="color:#75715e">// Start I2C transaction when enable is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> saved_addr<span style="color:#f92672">&lt;=</span> {addr, rw};<span style="color:#75715e">// Save the 7-bit address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> saved_data<span style="color:#f92672">&lt;=</span> data_in;<span style="color:#75715e">// Save the data to be sent (in write mode)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> START:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Initialize bit counter to 7 for 8-bit transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> state<span style="color:#f92672">&lt;=</span> ADDRESS;<span style="color:#75715e">// Move to ADDRESS state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> ADDRESS:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ACK;<span style="color:#75715e">// Move to ACK check after sending address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Transmit address bits, count down</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (i2c_sda<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span><span style="color:#75715e">// ACK received (SDA pulled low by slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Reset bit counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span> (saved_addr[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>) state<span style="color:#f92672">&lt;=</span> WRITE_DATA;<span style="color:#75715e">// If RW=0, go to write mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> state<span style="color:#f92672">&lt;=</span> READ_DATA;<span style="color:#75715e">// If RW=1, go to read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// NACK received, move to STOP state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ACK2;<span style="color:#75715e">// Move to second ACK check after data transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Transmit data bits, count down</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((i2c_sda<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)) state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Return to IDLE on ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// If NACK received or enable low, go to STOP</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> data_out[counter]<span style="color:#f92672">&lt;=</span> i2c_sda;<span style="color:#75715e">// Capture data bit from SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>) state<span style="color:#f92672">&lt;=</span> WRITE_ACK;<span style="color:#75715e">// After last bit, go to WRITE_ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down for each bit received</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// Go to STOP after sending ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> STOP:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Go back to IDLE after STOP condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// SDA output logic based on the current state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Drive SDA high on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span> (state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> START:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for start condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Pull SDA low for start condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> ADDRESS:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> saved_addr[counter];<span style="color:#75715e">// Send each bit of the address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA to allow slave to drive ACK/NACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for data transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span> saved_data[counter];<span style="color:#75715e">// Output each bit of data to SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for ACK transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Send ACK by pulling SDA low</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA to read data from slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> STOP:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for stop condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Release SDA to indicate stop</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation">Explanation</h5><p>The provided code is a Verilog implementation of an I2C Master Module.
This module enables communication with I2C-compatible devices through
the I2C protocol by implementing the necessary operations to generate
I2C signals and manage data transfer. Let&rsquo;s break down each section of
the code:</p><h6 id="module-declaration">Module Declaration</h6><p>The code begins with the module declaration:</p><blockquote><pre><code>module i2c_master(
input wire clk, // System clock
input wire rst, // Synchronous reset
input wire [6:0] addr, // 7-bit I2C address
input wire [7:0] data_in, // Data to be transmitted
input wire enable, // Enable signal to start I2C transaction
input wire rw, // Read/Write control (0 = Write, 1 = Read)
output reg [7:0] data_out, // Data received from I2C
output wire ready, // Ready signal when module is idle
inout i2c_sda, // I2C data line (SDA)
inout wire i2c_scl // I2C clock line (SCL)
);</code></pre></blockquote><p>This module contains inputs for the system clock (<code>clk</code>), reset (<code>rst</code>),
I2C address (<code>addr</code>), data to be sent (<code>data_in</code>), an enable signal
(<code>enable</code>), and a Read/Write control (<code>rw</code>). It also provides outputs
for data received (<code>data_out</code>), a ready status signal (<code>ready</code>), and
bidirectional I2C lines,<code>i2c_sda</code> and<code>i2c_scl</code>.</p><h6 id="state-machine-definition">State Machine Definition</h6><p>The code defines several states representing stages in the I2C
transaction:</p><blockquote><pre><code>localparam IDLE = 0;
localparam START = 1;
localparam ADDRESS = 2;
localparam READ_ACK = 3;
localparam WRITE_DATA = 4;
localparam WRITE_ACK = 5;
localparam READ_DATA = 6;
localparam READ_ACK2 = 7;
localparam STOP = 8;</code></pre></blockquote><p>Each<code>localparam</code> corresponds to a state in the Finite State Machine
(FSM), controlling the I2C protocol flow, including start, address
transmission, acknowledgment (ACK) reception, data transfer, and stop
condition generation.</p><h6 id="clock-divider">Clock Divider</h6><p>To generate a slower clock for the I2C operations, a clock divider is
implemented:</p><blockquote><pre><code>always @(posedge clk) begin
if (counter2 == (DIVIDE_BY / 2) - 1) begin
i2c_clk &lt;= ~i2c_clk;
counter2 &lt;= 0;
end else counter2 &lt;= counter2 + 1;
end</code></pre></blockquote><p>This block toggles<code>i2c_clk</code> at a lower frequency than the system clock,<code>clk</code>, using a counter<code>counter2</code> with a division factor defined by<code>DIVIDE_BY</code>.</p><h6 id="sda-and-scl-control">SDA and SCL Control</h6><p>To control the<code>i2c_sda</code> and<code>i2c_scl</code> lines based on the module&rsquo;s
state:</p><blockquote><pre><code>assign ready = ((rst == 0) &amp;&amp; (state == IDLE)) ? 1 : 0;
assign i2c_scl = (i2c_scl_enable == 0) ? 1 : i2c_clk;
assign i2c_sda = (write_enable == 1) ? sda_out : 'bz;</code></pre></blockquote><ul><li><p><code>ready</code> is high when the reset is inactive and the state is<code>IDLE</code>.</p></li><li><p><code>i2c_scl</code> is either high (idle state) or follows the divided<code>i2c_clk</code> signal.</p></li><li><p><code>i2c_sda</code> outputs the value of<code>sda_out</code> when<code>write_enable</code> is
active. When<code>write_enable</code> is inactive,<code>i2c_sda</code> goes to
high-impedance (<code>‚Äôbz</code>) for reading data.</p></li></ul><h6 id="finite-state-machine-fsm">Finite State Machine (FSM)</h6><p>The FSM controls the I2C communication process, progressing through
states based on the I2C protocol requirements:</p><blockquote><pre><code>always @(posedge i2c_clk or posedge rst) begin
if (rst == 1) begin
state &lt;= IDLE;
end else begin
case (state)
IDLE: begin
if (enable) begin
state &lt;= START;
saved_addr &lt;= {addr, rw};
saved_data &lt;= data_in;
end
end
START: begin
counter &lt;= 7;
state &lt;= ADDRESS;
end
...
STOP: begin
state &lt;= IDLE;
end
endcase
end
end</code></pre></blockquote><p>Each state corresponds to an I2C operation:</p><ul><li><p><code>IDLE</code>: Waits for<code>enable</code> signal to initiate communication.</p></li><li><p><code>START</code>: Prepares a start condition by asserting<code>sda_out</code> low.</p></li><li><p><code>ADDRESS</code>: Sends the address and R/W bit.</p></li><li><p><code>READ_ACK</code> and<code>READ_ACK2</code>: Verifies acknowledgment (ACK) from the
slave.</p></li><li><p><code>WRITE_DATA</code> and<code>WRITE_ACK</code>: Transfers data to the slave and waits
for ACK.</p></li><li><p><code>READ_DATA</code>: Receives data from the slave.</p></li><li><p><code>STOP</code>: Generates a stop condition and returns to<code>IDLE</code>.</p></li></ul><h6 id="sda-output-logic">SDA Output Logic</h6><p>The logic for controlling the<code>i2c_sda</code> line, depending on the FSM
state, is implemented as follows:</p><blockquote><pre><code>always @(negedge i2c_clk or posedge rst) begin
if (rst == 1) begin
write_enable &lt;= 1;
sda_out &lt;= 1;
end else begin
case (state)
START: begin
write_enable &lt;= 1;
sda_out &lt;= 0;
end
ADDRESS: begin
sda_out &lt;= saved_addr[counter];
end
...
STOP: begin
write_enable &lt;= 1;
sda_out &lt;= 1;
end
endcase
end
end</code></pre></blockquote><ul><li><p>In the<code>START</code> state,<code>sda_out</code> goes low to generate a start
condition.</p></li><li><p>In the<code>ADDRESS</code> and<code>WRITE_DATA</code> states,<code>sda_out</code> sends the bits
of<code>saved_addr</code> or<code>saved_data</code>.</p></li><li><p>In<code>STOP</code>,<code>sda_out</code> goes high to signify the end of the
transmission.</p></li></ul><p>This Verilog module effectively implements an I2C Master communication
sequence by controlling the<code>i2c_sda</code> and<code>i2c_scl</code> lines according to
the I2C protocol.</p><h4 id="slave-module">SLAVE MODULE</h4><h5 id="c0d3-1">C0d3</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">module</span> i2c_slave(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr_in,<span style="color:#75715e">// Slave address to respond to (dynamic address input)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> scl<span style="color:#75715e">// I2C clock line (SCL)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Define states for the I2C slave FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> READ_ADDR<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// State for reading the address from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> SEND_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// State for sending ACK after receiving a matching address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> READ_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>;<span style="color:#75715e">// State for reading data from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> WRITE_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>;<span style="color:#75715e">// State for sending data to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> SEND_ACK2<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;<span style="color:#75715e">// State for sending ACK after receiving data from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr;<span style="color:#75715e">// Register to store the address received from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter;<span style="color:#75715e">// Bit counter for data/address transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Current state of the FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Register to store data received from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b11001100</span>;<span style="color:#75715e">// Data to be sent to the master in read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_out<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Data to drive onto SDA when write_enable is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_in<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Register to capture SDA input data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> start<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Flag to indicate the start condition (SDA goes low while SCL is high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> write_enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Controls whether the slave drives the SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Tri-state SDA line: driven by sda_out when write_enable is high, otherwise high-impedance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> sda<span style="color:#f92672">=</span> (write_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">?</span> sda_out<span style="color:#f92672">:</span> 'bz;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Detect start condition on SDA falling edge when SCL is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> sda)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((start<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (scl<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> start<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Set start flag</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Initialize counter to read 8 bits (address or data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Detect stop condition on SDA rising edge when SCL is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> sda)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((start<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">&amp;&amp;</span> (scl<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Go to READ_ADDR state to read the address from master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> start<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Clear start flag</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// State machine for I2C slave behavior, triggered on rising edge of SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> scl)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (start<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span><span style="color:#75715e">// Only proceed if start condition was detected</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">case</span>(state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ADDR:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> addr[counter]<span style="color:#f92672">&lt;=</span> sda;<span style="color:#75715e">// Capture address bit from SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> SEND_ACK;<span style="color:#75715e">// Move to SEND_ACK after receiving full address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down to receive 8 bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Check if received address matches slave address (addr_in)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(addr[<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> addr_in)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Reset bit counter for next data frame</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// Determine next state based on R/W bit (addr[0])</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(addr[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_DATA;<span style="color:#75715e">// If R/W=0, master wants to write, go to READ_DATA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> WRITE_DATA;<span style="color:#75715e">// If R/W=1, master wants to read, go to WRITE_DATA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Address mismatch, go back to READ_ADDR</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> data_in[counter]<span style="color:#f92672">&lt;=</span> sda;<span style="color:#75715e">// Capture data bit from SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> SEND_ACK2;<span style="color:#75715e">// Move to SEND_ACK2 after receiving full byte</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down to receive 8 bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Go back to READ_ADDR to listen for next address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Transmit data_out to master one bit at a time</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// After last bit, go back to READ_ADDR</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down for each bit sent</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Control SDA output behavior on falling edge of SCL, depending on the state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> scl)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span>(state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ADDR:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA while reading address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> (addr[<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> addr_in)<span style="color:#f92672">?</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Send ACK (low) if address matches, else NACK (high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive ACK/NACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA while reading data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> data_out[counter];<span style="color:#75715e">// Send each bit of data_out on SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Send ACK (low) after receiving data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation-1">Explanation</h5><p>The Verilog code presented is for an I2C Slave Module that implements
the core logic for an I2C slave device capable of receiving and
transmitting data over the I2C protocol. Let&rsquo;s break down the components
of the code and their functionality:</p><h6 id="module-declaration-1">Module Declaration</h6><p>The module begins with the declaration of inputs and outputs:</p><blockquote><pre><code>module i2c_slave(
input [6:0] addr_in, // Dynamic address input for I2C slave
inout sda, // I2C data line (SDA)
inout scl // I2C clock line (SCL)
);</code></pre></blockquote><p>The inputs include a 7-bit address (<code>addr_in</code>) for the slave device,
along with the bidirectional<code>sda</code> and<code>scl</code> lines for data and clock
signals respectively.</p><h6 id="state-machine-definition-1">State Machine Definition</h6><p>The I2C protocol relies on a finite state machine (FSM) to control the
data transfer sequence. The FSM is represented by five states:</p><blockquote><pre><code>localparam READ_ADDR = 0;
localparam SEND_ACK = 1;
localparam READ_DATA = 2;
localparam WRITE_DATA = 3;
localparam SEND_ACK2 = 4;</code></pre></blockquote><p>Each state corresponds to a particular phase of the I2C communication: -<code>READ_ADDR</code>: Reads the I2C address and R/W bit. -<code>SEND_ACK</code>: Sends
acknowledgment (ACK) if the address matches. -<code>READ_DATA</code>: Receives
data from the master. -<code>WRITE_DATA</code>: Sends data to the master. -<code>SEND_ACK2</code>: Sends a second ACK after data reception.</p><h6 id="internal-registers-and-signals">Internal Registers and Signals</h6><p>Several internal registers and signals are declared to support the
functionality of the I2C slave: -<code>addr</code> holds the slave address and R/W
bit. -<code>counter</code> is used to count bits during transmission. -<code>state</code>
holds the current FSM state. -<code>data_in</code> and<code>data_out</code> store the
incoming and outgoing data, respectively. -<code>sda_out</code> and<code>sda_in</code>
control the data line (SDA). -<code>start</code> flags the detection of the I2C
start condition. -<code>write_enable</code> controls whether the slave can drive
the SDA line.</p><h6 id="sda-line-control">SDA Line Control</h6><p>The assignment of the<code>sda</code> line is conditional on the<code>write_enable</code>
signal:</p><blockquote><pre><code>assign sda = (write_enable == 1) ? sda_out : 'bz;</code></pre></blockquote><p>This means that the slave drives the<code>sda</code> line when<code>write_enable</code> is
active, otherwise, the line is in high-impedance state (&lsquo;bz).</p><h6 id="start-and-stop-condition-detection">Start and Stop Condition Detection</h6><p>The start condition is detected when there is a falling edge on the<code>sda</code> line while the<code>scl</code> line is high, and the stop condition is
detected when there is a rising edge on the<code>sda</code> line while<code>scl</code> is
high. These conditions trigger transitions in the FSM.</p><blockquote><pre><code>always @(negedge sda) begin
if ((start == 0) &amp;&amp; (scl == 1)) begin
start &lt;= 1; // Set start flag
counter &lt;= 7; // Initialize bit counter
end
end
always @(posedge sda) begin
if ((start == 1) &amp;&amp; (scl == 1)) begin
state &lt;= READ_ADDR; // Transition to READ_ADDR state
start &lt;= 0; // Reset start flag
write_enable &lt;= 0; // Disable write
end
end</code></pre></blockquote><p>These blocks capture the start and stop conditions and manage the FSM
transitions accordingly.</p><h6 id="fsm-logic-for-data-transfer">FSM Logic for Data Transfer</h6><p>The FSM operates on the rising edge of the<code>scl</code> signal, progressing
through various states based on the detected conditions:</p><blockquote><pre><code>always @(posedge scl) begin
if (start == 1) begin
case(state)
READ_ADDR: begin
addr[counter] &lt;= sda;
if(counter == 0) state &lt;= SEND_ACK;
else counter &lt;= counter - 1;
end
SEND_ACK: begin
if(addr[7:1] == addr_in) begin
counter &lt;= 7;
if(addr[0] == 0) begin
state &lt;= READ_DATA; // If write mode, move to READ_DATA
end else state &lt;= WRITE_DATA; // Else move to WRITE_DATA
end else state &lt;= READ_ADDR;
end
...
endcase
end
end</code></pre></blockquote><p>The state transitions depend on whether the address matches, the R/W
bit, and whether data is being read or written. The<code>SEND_ACK</code> state
sends an acknowledgment if the address is correct, while the<code>READ_DATA</code>
and<code>WRITE_DATA</code> states handle data reception and transmission
respectively.</p><h6 id="sda-output-logic-1">SDA Output Logic</h6><p>The logic for controlling the<code>sda</code> output during the FSM states is
defined in the following block:</p><blockquote><pre><code>always @(negedge scl) begin
case(state)
READ_ADDR: begin
write_enable &lt;= 0; // Disable writing during address read
end
SEND_ACK: begin
sda_out &lt;= (addr[7:1] == addr_in) ? 0 : 1; // Send ACK (0) or NACK (1)
write_enable &lt;= 1;
end
READ_DATA: begin
write_enable &lt;= 0; // Disable writing during data read
end
WRITE_DATA: begin
sda_out &lt;= data_out[counter]; // Output data bit by bit
write_enable &lt;= 1;
end
SEND_ACK2: begin
sda_out &lt;= 0; // Send ACK (0) after data reception
write_enable &lt;= 1;
end
endcase
end</code></pre></blockquote><p>Each state manipulates the<code>sda_out</code> signal to either send an
acknowledgment (ACK) or transmit the data bit by bit. The<code>SEND_ACK</code>
state checks the address match and sends either an ACK or NACK. The<code>WRITE_DATA</code> state sends the data, while the<code>SEND_ACK2</code> state sends an
ACK after data reception.</p><h6 id="summary">Summary</h6><p>This Verilog code implements a simple I2C Slave module that can handle
basic I2C communication. It includes start/stop condition detection,
address matching, data reception, and data transmission using an FSM.
The module can receive data from the I2C master, send data to it, and
properly acknowledge the master at each step in the communication
process.</p><h4 id="top-level-module">TOP-LEVEL MODULE</h4><h5 id="c0d3-2">C0d3</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Top module to integrate i2c_master and i2c_slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Top module to integrate i2c_master and i2c_slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">module</span> top(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> clk,<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rst,<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr,<span style="color:#75715e">// 7-bit I2C address for the master to communicate with</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in,<span style="color:#75715e">// Data to be sent from the master to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> enable,<span style="color:#75715e">// Enable signal to initiate I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rw,<span style="color:#75715e">// Read/Write signal (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out,<span style="color:#75715e">// Data received by the master from the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> ready,<span style="color:#75715e">// Signal indicating the master is ready for a new operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_scl<span style="color:#75715e">// I2C clock line (SCL)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Internal register to store the address the slave will respond to.</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// This is the fixed address of the slave in this example.</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] slave_address<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0101010</span>;<span style="color:#75715e">// Example default slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the I2C slave module</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> i2c_slave slave_inst (</span></span><span style="display:flex;"><span> .addr_in(slave_address),<span style="color:#75715e">// Provide the fixed slave address to the slave instance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .sda(i2c_sda),<span style="color:#75715e">// Connect the slave's SDA line to the top-level SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .scl(i2c_scl)<span style="color:#75715e">// Connect the slave's SCL line to the top-level SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> );</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the I2C master module</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> i2c_master master_inst (</span></span><span style="display:flex;"><span> .clk(clk),<span style="color:#75715e">// Connect the system clock to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rst(rst),<span style="color:#75715e">// Connect the reset signal to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .addr(addr),<span style="color:#75715e">// Provide the I2C address the master should communicate with</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_in(data_in),<span style="color:#75715e">// Data to be sent to the slave (if writing)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .enable(enable),<span style="color:#75715e">// Enable signal to start the I2C transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rw(rw),<span style="color:#75715e">// Read/Write signal (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_out(data_out),<span style="color:#75715e">// Data received from the slave (if reading)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .ready(ready),<span style="color:#75715e">// Master ready signal indicating it's idle or ready for a new transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_sda(i2c_sda),<span style="color:#75715e">// Connect the master's SDA line to the top-level SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_scl(i2c_scl)<span style="color:#75715e">// Connect the master's SCL line to the top-level SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> );</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation-2">Explanation</h5><ul><li><p>The<code>top</code> module connects an I2C master and slave module on shared<code>i2c_sda</code> and<code>i2c_scl</code> lines.</p></li><li><p>The<code>slave_address</code> register holds a predefined address used by the
slave.</p></li><li><p>The<code>i2c_slave</code> and<code>i2c_master</code> modules are instantiated and
connected to share the I2C lines and control signals.</p></li></ul><h4 id="testbench-module">TESTBENCH MODULE</h4><h5 id="c0d3-3">C0d3</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">module</span> i2c_controller_tb();</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Inputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> clk;<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> rst;<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr;<span style="color:#75715e">// Address for the master to communicate with</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in;<span style="color:#75715e">// Data to be sent from the master to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> enable;<span style="color:#75715e">// Enable signal to start communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> rw;<span style="color:#75715e">// Read/Write control (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Outputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out;<span style="color:#75715e">// Data received by the master from the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> ready;<span style="color:#75715e">// Ready signal indicating the master is ready for a new operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Bidirectional wires</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> i2c_sda;<span style="color:#75715e">// I2C data line (SDA) - shared between master and slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> i2c_scl;<span style="color:#75715e">// I2C clock line (SCL) - shared between master and slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the Top Module (Device Under Test - DUT)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> top uut (</span></span><span style="display:flex;"><span> .clk(clk),<span style="color:#75715e">// Connect system clock to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rst(rst),<span style="color:#75715e">// Connect reset signal to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .addr(addr),<span style="color:#75715e">// Connect address input to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_in(data_in),<span style="color:#75715e">// Connect data to be sent by master to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .enable(enable),<span style="color:#75715e">// Connect enable signal to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rw(rw),<span style="color:#75715e">// Connect read/write control to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_out(data_out),<span style="color:#75715e">// Receive data read by master from DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .ready(ready),<span style="color:#75715e">// Receive ready signal from DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_sda(i2c_sda),<span style="color:#75715e">// Connect bidirectional SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_scl(i2c_scl)<span style="color:#75715e">// Connect bidirectional SCL line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> );</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Clock generation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">initial</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> clk<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">forever</span> #<span style="color:#ae81ff">1</span> clk<span style="color:#f92672">=</span><span style="color:#f92672">~</span>clk;<span style="color:#75715e">// Toggle clock every 1 ns to generate a 2 ns period clock (500 MHz)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Test sequence to simulate I2C operations</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">initial</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Set up VCD file for waveform dumping</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> $dumpfile(<span style="color:#e6db74">"i2c_controller_tb.vcd"</span>);<span style="color:#75715e">// Name of the VCD file for waveform output</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> $dumpvars(<span style="color:#ae81ff">0</span>, i2c_controller_tb);<span style="color:#75715e">// Dump all variables in this module for waveform analysis</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Initialize Inputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rst<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert reset to initialize the system</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Initially disable communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0000000</span>;<span style="color:#75715e">// Set an initial address (not used immediately)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b0</span>;<span style="color:#75715e">// Set initial data (not used immediately)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Set initial operation to write (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait for reset to complete</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">10</span>;</span></span><span style="display:flex;"><span> rst<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert reset after 10 ns to start normal operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Test Case 1: Write operation with matching address (Expect ACK from slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0101010</span>;<span style="color:#75715e">// Set address to match the slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b10101010</span>;<span style="color:#75715e">// Data to be sent to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Set operation to write</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert enable to start the I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">20</span> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert enable after 20 ns to complete the command</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait and observe response (slave should ACK the address and receive data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">100</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Test Case 2: Write operation with non-matching address (Expect NACK from slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b1111111</span>;<span style="color:#75715e">// Set address to a non-matching address for the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b11001100</span>;<span style="color:#75715e">// Different data to be sent to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Set operation to write</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert enable to start the I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">20</span> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert enable after 20 ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait and observe response (slave should NACK the address since it does not match)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">100</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Test Case 3: Read operation with matching address (Expect ACK from slave and read data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0101010</span>;<span style="color:#75715e">// Set address to match the slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Set operation to read</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert enable to start the I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">20</span> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert enable after 20 ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait and observe response (slave should ACK the address and send data to master)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">100</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> #<span style="color:#ae81ff">200</span></span></span><span style="display:flex;"><span> $finish;<span style="color:#75715e">// End the simulation after 200 ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation-3">Explanation</h5><ul><li><p><code>i2c_controller_tb</code>: Testbench module for the<code>top</code> module
integrating the master-slave I2C communication.</p></li><li><p>A clock signal is generated using a continuous<code>initial</code> block.</p></li><li><p>Test cases:</p><ul><li><p><strong>Test Case 1</strong>: Matches the slave address, expecting an ACK.</p></li><li><p><strong>Test Case 2</strong>: Uses a non-matching address, expecting a NACK.</p></li><li><p><strong>Test Case 3</strong>: Matches the address and tests a read operation.</p></li></ul></li><li><p>At the end of the test cases, the simulation finishes with<code>$finish</code>.</p></li></ul><h1 id="results">Results</h1><h4 id="test-case-1-address-match-with-write-operation">Test Case 1: Address Match with Write Operation</h4><figure><span class="image placeholder" data-original-image-src="TEST-CASE-1.jpg" data-original-image-title="" width="\textwidth"/><figcaption>Test Case 1</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/i2cv/TEST-CASE-2_hu6405931946634379952.webp" alt="Test Case 2" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/TEST-CASE-2_hu12279029995292422776.jpg'"/><p>The waveform in this test shows the master sending an address 7&rsquo;b0101010, which matches the slave‚Äôs configured address. Since the address matches, the slave acknowledges the communication by sending an ACK (acknowledgment) signal. After receiving the ACK, the master initiates a write operation, transmitting the data 8&rsquo;b10101010 to the slave. The enable signal is set to initiate communication and deasserted after a delay, allowing the transmission to complete. The presence of the ACK in this waveform confirms that the address was successfully matched, allowing data transfer.</p><figure><span class="image placeholder" data-original-image-src="TEST-CASE-2.jpg" data-original-image-title="" width="\textwidth"/><figcaption>Test Case 2</figcaption></figure><h4 id="test-case-2-address-mismatch-with-write-operation-expect-nack">Test Case 2: Address Mismatch with Write Operation (Expect NACK)</h4><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/i2cv/TEST-CASE-2_hu6405931946634379952.webp" alt="Test Case 3" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/TEST-CASE-2_hu12279029995292422776.jpg'"/><p>In this test case, the master sends a non-matching address 7&rsquo;b1111111, which does not correspond to the slave‚Äôs preset address. The waveform shows the absence of an acknowledgment signal (NACK) from the slave, indicating that the address verification failed and the data transfer cannot proceed. This NACK response is expected behavior when the slave does not recognize the transmitted address. The enable signal initiates the communication, but with no matching address and no ACK received, data transfer is not established.</p><figure><span class="image placeholder" data-original-image-src="TEST-CASE-3.jpg" data-original-image-title="" width="\textwidth"/><figcaption>Test Case 3</figcaption></figure><h4 id="test-case-3-address-match-with-read-operation">Test Case 3: Address Match with Read Operation</h4><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/i2cv/TEST-CASE-3_hu5097597462133817533.webp" alt="Test Case 3" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/TEST-CASE-3_hu16799201968338071699.jpg'"/><p>The final waveform demonstrates a read operation with the master sending a matching address 7&rsquo;b0101010. Upon recognizing the address, the slave responds with an ACK signal, confirming the communication link. Following the acknowledgment, the master initiates a read operation, and the slave provides the preloaded data 8&rsquo;b11001100 to the master. The enable signal triggers the start of communication and is deasserted after a delay, allowing the master to read the data. This successful transmission and receipt of data verify correct read functionality with an address match.</p><h3 id="challenges-and-risk-analysis">Challenges and Risk Analysis</h3><h4 id="potential-issues-and-solutions">Potential Issues and Solutions</h4><p>In the development of the I2C communication project, I encountered several challenges, starting with the design of basic Verilog modules for both master and slave entities capable of fundamental read and write operations. After an initial review of the I2C protocol from various online resources and Verilog syntax, I designed a preliminary testbench module to simulate and validate the basic functionality.</p><p>As the project progressed, I introduced additional functionality, including ACK and NACK flags, to handle incorrect slave addresses and refined the finite state machine (FSM) logic for more reliable state transitions. To make the slave module independent of global configurations, I designed a top-level module that instantiated both the master and slave modules and added an extra layer of address validation.</p><p>For synchronization, I implemented clock stretching between address and data frames. This addition worked effectively during address transmission but revealed timing issues during data frame read operations. After extensive troubleshooting, I identified limitations in the initial approach and modified the design accordingly.</p><p>I also explored a multi-master, multi-slave configuration, assigning slave addresses in the format<code>10101XY</code> (with<code>XY</code> values as 00, 01, 10, and 11 for slaves 1 through 4) and a master select line in the testbench to choose the active master. Preloaded data in each slave was structured as<code>110011XY</code> to streamline read operations. However, unresolved synchronization issues in the multi-master setup led me to scale back to a single-master, single-slave model, excluding clock stretching and multiple nodes. The final design focuses on single-point communication, with code attempts for the multi-master setup included in the project appendix on GitHub.</p><h4 id="risk-management">Risk Management</h4><p>Several potential risks emerged during the design and integration phases:</p><ul><li><p><strong>Design Complexity</strong>: The complexity of the I2C protocol and multi-node configuration posed unforeseen design challenges. A modular testing approach mitigated these risks by allowing iterative refinements.</p></li><li><p><strong>Timing Issues</strong>: Timing mismatches, particularly in multi-master configurations, impacted protocol accuracy. While resolved in the single-master model, this remains an area for future improvement.</p></li><li><p><strong>FSM Complexity</strong>: Introducing ACK/NACK handling increased the complexity of the FSM, raising the potential for state transition errors. Comprehensive simulation and debugging minimized these risks.</p></li></ul><p>In this project, I implemented the clock stretching functionality and addressed timing issues in data frame read operations. Starting with basic I2C modules, I managed the synchronization aspect by incorporating clock stretching between address and data frames, a mechanism crucial for addressing timing issues in the protocol. Despite progress, some discrepancies remain in the data frame during read operations, which are planned for future enhancements.</p><p>Additionally, I expanded the basic modules by introducing acknowledgment (ACK) and negative acknowledgment (NACK) flags to handle erroneous addresses. I refined the FSM logic to improve state transitions, address handling, and protocol management complexities. While the initial goal was a multi-master configuration with selectable slave nodes, unresolved timing issues led to a focus on a single-master, single-slave model, effectively capturing the core aspects of I2C communication in the final implementation.</p><h3 id="future-work-and-improvements">Future Work and Improvements</h3><h4 id="suggested-enhancements">Suggested Enhancements</h4><p>Future enhancements to this project could include adding more registers
to each slave, allowing for more sophisticated data handling. Additional
registers would enable more extensive data storage and retrieval options
in each slave device, making the project closer to real-world I2C
applications.</p><h4 id="alternative-designs">Alternative Designs</h4><p>Exploring alternative FSM architectures could improve the efficiency and
stability of the I2C protocol, especially for multi-master
configurations. Further, advanced data synchronization techniques,
possibly through modified clock stretching or data frame timing
adjustments, could address the current timing issues. Replacing the
current point-to-point master-slave setup with a robust multi-node
configuration, if resolved, could significantly enhance the protocol&rsquo;s
scalability.</p><h3 id="appendices">Appendices</h3><h4 id="verilog-code-listings">Verilog Code Listings</h4><p>The complete Verilog code for the I2C Master module, including support
for multi-master/slave configuration and clock stretching, is available
in the following GitHub repository:</p><p><strong>Repository:</strong><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">https://github.com/Mummanajagadeesh/I2C-protocol-verilog</a></p><h4 id="references">References</h4><ol><li><p>Texas Instruments,<em>A Basic Guide to I2C</em>, Available at:<a href="https://www.ti.com/lit/pdf/sbaa565" target="_blank">https://www.ti.com/lit/pdf/sbaa565</a></p></li><li><p>Prodigy Technoinnovations,<em>I2C Protocol</em>, Available at:<a href="https://www.prodigytechno.com/i2c-protocol" target="_blank">https://www.prodigytechno.com/i2c-protocol</a></p></li><li><p>SparkFun,<em>I2C Tutorial</em>, Available at:<a href="https://learn.sparkfun.com/tutorials/i2c/all" target="_blank">https://learn.sparkfun.com/tutorials/i2c/all</a></p></li><li><p>Class Lectures,<em>Verilog Code Syntax</em></p></li></ol><blockquote><p>Most images in this document are adapted from the above
resources. All images are copyrighted by their respective owners; no
ownership rights are claimed.</p></blockquote>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/improve/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/improve/</guid><description>&lt;![CDATA[<h2 id="improve-image-processing-using-veriloghttpsgithubcommummanajagadeeshimprove"><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe: Image Processing using Verilog</a></h2><table><thead><tr><th><strong>Name</strong></th><th>ImProVe</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>ImProVe (Image Processing using Verilog) is a project focused on implementing image processing techniques using Verilog. It involves building image processing logic from the ground up, exploring various algorithms and approaches within HDL</td></tr><tr><td><strong>Start</strong></td><td>27 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVeüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Image Processing, HDL, Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, SystemVerilog, Icarus, Xilinx, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Active)</td></tr><tr><td><strong>Progress</strong></td><td>- Implemented edge detection algorithms: Prewitt, Sobel, Canny, Moravec corner detection, and Emboss.<br> - Applied blurring filters: Gaussian, Median, Box, and Bilateral.<br> - Completed geometric operations: Rotation, Translation, Shearing, Cropping, Reflection, and Perspective Transform.<br> - Integrated thresholding techniques: Global Thresholding, Adaptive Thresholding, Otsu&rsquo;s Method, and Color Thresholding.<br> - Color effects: Grayscale, Sepia, Contrast, Brightness, Invert, Negative, Saturation, Gamma correction, and Sharpening.<br> - Developed subprojects: Label detection (Done), Document scanner (Ongoing), Stereo camera matching (Almost done), MNIST Digit Recognition and OCR [EMNIST] (In Working Condition).</td></tr><tr><td><strong>Next Steps</strong></td><td>- Develop a synthesizable module as a proof of concept (Almost Done)<br> - Implement morphological operations: Dilation, Closing, Opening.</td></tr></tbody></table><hr><table><thead><tr><th><strong>ImProVe Project Versions</strong></th><th><strong>Linked Projects</strong></th></tr></thead><tbody><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeR" target="_blank">ImProVeR: ImProVe Revised Version</a></strong><br> Revised version with improved documentation and structure for better clarity and usability</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">CoVer: CORDIC math modules in VERilog</a></strong><br> Replaces non-synthesizable math constructs by utilizing the CORDIC algorithm for more efficient hardware implementation</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeS" target="_blank">ImProVeS: ImProVe with Synthesizable Modules</a></strong><br> Focuses on making all modules synthesizable and aims for simulation on Xilinx Vivado</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">NeVer: NEural NEtwork in VERilog</a></strong><br> Implements a neural network in Verilog for better hardware acceleration of image processing tasks</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeD" target="_blank">ImProVeD: ImProVe with Deep Learning</a></strong><br> Adds deep learning techniques to enhance image processing capabilities</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ProtoN: PROTOcol comparison in verilog</a></strong><br> Compares different communication protocols in Verilog for efficient high-speed data transfer, focusing on synthesizability and module communication</td></tr></tbody></table><hr><h4 id="project-overview"><strong>Project Overview</strong></h4><p>ImProVe is an initiative to implement core image processing algorithms using Verilog. It aims to achieve real-time performance for advanced applications in fields like robotics, medical imaging, and computer vision.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="improve-image-processing-using-veriloghttpsgithubcommummanajagadeeshimprove"><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe: Image Processing using Verilog</a></h2><table><thead><tr><th><strong>Name</strong></th><th>ImProVe</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>ImProVe (Image Processing using Verilog) is a project focused on implementing image processing techniques using Verilog. It involves building image processing logic from the ground up, exploring various algorithms and approaches within HDL</td></tr><tr><td><strong>Start</strong></td><td>27 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVeüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Image Processing, HDL, Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, SystemVerilog, Icarus, Xilinx, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Active)</td></tr><tr><td><strong>Progress</strong></td><td>- Implemented edge detection algorithms: Prewitt, Sobel, Canny, Moravec corner detection, and Emboss.<br> - Applied blurring filters: Gaussian, Median, Box, and Bilateral.<br> - Completed geometric operations: Rotation, Translation, Shearing, Cropping, Reflection, and Perspective Transform.<br> - Integrated thresholding techniques: Global Thresholding, Adaptive Thresholding, Otsu&rsquo;s Method, and Color Thresholding.<br> - Color effects: Grayscale, Sepia, Contrast, Brightness, Invert, Negative, Saturation, Gamma correction, and Sharpening.<br> - Developed subprojects: Label detection (Done), Document scanner (Ongoing), Stereo camera matching (Almost done), MNIST Digit Recognition and OCR [EMNIST] (In Working Condition).</td></tr><tr><td><strong>Next Steps</strong></td><td>- Develop a synthesizable module as a proof of concept (Almost Done)<br> - Implement morphological operations: Dilation, Closing, Opening.</td></tr></tbody></table><hr><table><thead><tr><th><strong>ImProVe Project Versions</strong></th><th><strong>Linked Projects</strong></th></tr></thead><tbody><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeR" target="_blank">ImProVeR: ImProVe Revised Version</a></strong><br> Revised version with improved documentation and structure for better clarity and usability</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">CoVer: CORDIC math modules in VERilog</a></strong><br> Replaces non-synthesizable math constructs by utilizing the CORDIC algorithm for more efficient hardware implementation</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeS" target="_blank">ImProVeS: ImProVe with Synthesizable Modules</a></strong><br> Focuses on making all modules synthesizable and aims for simulation on Xilinx Vivado</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">NeVer: NEural NEtwork in VERilog</a></strong><br> Implements a neural network in Verilog for better hardware acceleration of image processing tasks</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeD" target="_blank">ImProVeD: ImProVe with Deep Learning</a></strong><br> Adds deep learning techniques to enhance image processing capabilities</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ProtoN: PROTOcol comparison in verilog</a></strong><br> Compares different communication protocols in Verilog for efficient high-speed data transfer, focusing on synthesizability and module communication</td></tr></tbody></table><hr><h4 id="project-overview"><strong>Project Overview</strong></h4><p>ImProVe is an initiative to implement core image processing algorithms using Verilog. It aims to achieve real-time performance for advanced applications in fields like robotics, medical imaging, and computer vision.</p><hr><h4 id="motivation">Motivation</h4><blockquote><p>On November 26, 2024, while preparing for my Verilog elective exam, I needed to scan and rotate images of handwritten notes. That&rsquo;s when I thought:</p></blockquote><blockquote><p>&ldquo;Can image rotation be implemented using Verilog?&rdquo;</p></blockquote><p>This led me to experiment with basic transformations like rotation, cropping, translation, and shearing. As I explored further, I expanded the scope to include edge detection methods (Prewitt, Sobel, Kirsch Compass, Robinson Compass, and Canny) and noise reduction techniques (median, Gaussian, and box filters).</p><p>Initially, I wasn&rsquo;t familiar with the mathematical foundations of these techniques, so I learned them as I implemented each one. The project started as<strong>RoVer ‚Äì Rotation using Verilog</strong>, focusing solely on image rotation. Over time, it evolved beyond simple transformations, leading to the creation of<strong>ImProVe ‚Äì Image Processing Using Verilog</strong>.</p><h4 id="aim"><strong>Aim</strong></h4><p>The goal of this project is simple yet ambitious:<em>Build a set of foundational image processing blocks using Verilog that can be deployed on hardware for real-world applications.</em></p><p>These blocks will enable practical applications such as label detection, document scanning, object recognition, and more, making real-life automation and AI-driven vision tasks possible.</p><h6 id="the-challenge"><strong>THE Challenge</strong></h6><p><em>The project isn&rsquo;t just about implementing these techniques‚Äîit&rsquo;s about making them synthesizable for hardware. Currently, there are many simulation constructs that aren&rsquo;t FPGA-friendly. Fixing this is a big part of the journey.</em></p><hr><h4 id="features"><strong>Features</strong></h4><p>ImProVe supports a wide array of image processing functionalities categorized into multiple domains:</p><h6 id="01--edge-detection-and-feature-extractionhttpsgithubcommummanajagadeeshimprovetreemain1"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/1" target="_blank">01 Edge Detection and Feature Extraction</a></strong></h6><ul><li>‚úÖ<strong>Sobel Operator</strong>: Detects edges by computing gradients in horizontal and vertical directions</li><li>‚úÖ<strong>Prewitt Operator</strong>: Similar to Sobel but uses different kernel values</li><li>‚úÖ<strong>Roberts Cross Operator</strong>: Uses a 2x2 kernel for edge detection</li><li>‚úÖ<strong>Robinson Compass Operator</strong>: Uses eight directional masks to detect edges with specific orientation sensitivity</li><li>‚úÖ<strong>Kirsch Compass Operator</strong>: Detects edges by applying a set of 3x3 masks to enhance edges in various directions</li><li>‚úÖ<strong>Laplacian Operator</strong>: Captures edges by computing the second derivative of the image, highlighting regions of rapid intensity change</li><li>‚úÖ<strong>Laplacian of Gaussian (LoG)</strong>: Combines edge detection with noise reduction</li><li>‚úÖ<strong>Canny Edge Detection</strong>: Advanced edge detection using gradients, non-maximum suppression, and thresholding</li><li>‚úÖ<strong>Emboss Filter</strong>: Applies a convolution kernel to highlight edges and create a 3D relief effect</li><li>‚úÖ<strong>Moravec Corner Detection</strong>: Detects corners by evaluating changes in intensity in various directions using a 3x3 window</li><li>üî≤<strong>Harris Corner Detection</strong>: Identifies corners by analyzing intensity gradients</li></ul><h6 id="02--noise-reduction-and-smoothinghttpsgithubcommummanajagadeeshimprovetreemain2"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/2" target="_blank">02 Noise Reduction and Smoothing</a></strong></h6><ul><li>‚úÖ<strong>Gaussian Blur</strong>: Smoothens and reduces noise using a Gaussian kernel</li><li>‚úÖ<strong>Median Filter</strong>: Replaces each pixel with the median of its neighborhood to remove Noise</li><li>‚úÖ<strong>Box Filter (Mean Filter)</strong>: Averages pixel values within a window for Smoothing</li><li>‚úÖ<strong>Bilateral Filter</strong>: Preserves edges while reducing noise by combining spatial and intensity information</li></ul><h6 id="03--thresholding-and-binarizationhttpsgithubcommummanajagadeeshimprovetreemain3"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/3" target="_blank">03 Thresholding and Binarization</a></strong></h6><ul><li>‚úÖ<strong>Global Thresholding</strong>: Converts grayscale images to binary using a fixed thresholding</li><li>‚úÖ<strong>Adaptive Thresholding</strong>: Dynamically computes thresholds based on local Intensity</li><li>‚úÖ<strong>Otsu&rsquo;s Method</strong>: Automatically finds the optimal threshold for binarization</li><li>‚úÖ<strong>Color Thresholding</strong>: Applies thresholding on color spaces (e g , RGB, HSV, LAB) to segment specific color ranges</li></ul><h6 id="04--morphological-operationshttpsgithubcommummanajagadeeshimprovetreemain4"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/4" target="_blank">04 Morphological Operations</a></strong></h6><ul><li>üî≤<strong>Erosion</strong>: Shrinks objects by removing pixels on boundaries</li><li>üî≤<strong>Dilation</strong>: Grows objects by adding pixels to boundaries</li><li>üî≤<strong>Opening</strong>: Removes noise using erosion followed by dilation</li><li>üî≤<strong>Closing</strong>: Fills small holes using dilation followed by erosion</li><li>üî≤<strong>Boundary Extraction</strong>: Extracts object boundaries from binary images</li></ul><h6 id="05--filtering-and-transformationshttpsgithubcommummanajagadeeshimprovetreemain5"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/5" target="_blank">05 Filtering and Transformations</a></strong></h6><ul><li>üî≤<strong>Convolution Filtering</strong>: Applies custom kernels for sharpening, blurring, and edge enhancement</li><li>üî≤<strong>High-Pass Filtering</strong>: Enhances edges and fine details</li><li>üî≤<strong>Low-Pass Filtering</strong>: Removes high-frequency noise for smoother images</li><li>üî≤<strong>Fourier Transform</strong>: Converts spatial data to frequency domain for filtering</li><li>üî≤<strong>Discrete Cosine Transform (DCT)</strong>: Used for image compression (e g , JPEG)</li><li>üî≤<strong>Wavelet Transform</strong>: Decomposes images for multiscale analysis</li></ul><h6 id="06--geometric-transformationshttpsgithubcommummanajagadeeshimprovetreemain6"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/6" target="_blank">06 Geometric Transformations</a></strong></h6><ul><li>‚úÖ<strong>Rotation</strong>: Rotates the image by a given angle</li><li>‚úÖ<strong>Scaling</strong>: Resizes the image while preserving aspect ratio</li><li>‚úÖ<strong>Translation</strong>: Shifts the image position</li><li>‚úÖ<strong>Shearing</strong>: Distorts the image by shifting rows or columns</li><li>‚úÖ<strong>Cropping</strong>: Extracts a rectangular region from the image</li><li>‚úÖ<strong>Reflection</strong>: Flips the image across a specified axis (horizontal, vertical, or diagonal)</li><li>‚úÖ<strong>3D Perspective Transformation</strong>: Applies a projective transformation that distorts the image to simulate depth</li><li>üî≤<strong>Affine Transformations</strong>: Combines translation, scaling, rotation, and shearing</li></ul><h6 id="07--histogram-based-processinghttpsgithubcommummanajagadeeshimprovetreemain7"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/7" target="_blank">07 Histogram-Based Processing</a></strong></h6><ul><li>üî≤<strong>Histogram Equalization</strong>: Enhances image contrast by redistributing pixel intensity</li><li>üî≤<strong>CLAHE</strong>: Locally enhances contrast in small regions</li><li>üî≤<strong>Histogram Matching</strong>: Matches the histogram of one image to another</li></ul><h6 id="08--texture-analysishttpsgithubcommummanajagadeeshimprovetreemain8"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/8" target="_blank">08 Texture Analysis</a></strong></h6><ul><li>üî≤<strong>Gabor Filters</strong>: Extracts texture features using orientation-sensitive filters</li><li>üî≤<strong>Local Binary Patterns (LBP)</strong>: Captures texture by comparing neighboring pixel intensities</li><li>üî≤<strong>Haralick Features</strong>: Computes texture features from the gray-level co-occurrence matrix</li></ul><h6 id="09-color-and-intensity-transformationshttpsgithubcommummanajagadeeshimprovetreemain9"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/9" target="_blank">09 Color and Intensity Transformations</a></strong></h6><ul><li>‚úÖ<strong>Negative Transformation</strong>: Converts an image to its negative by replacing each pixel value ( R ) with ( 255 - R )</li><li>‚úÖ<strong>Inversion</strong>: Converts an image to its negative by inverting pixel values</li><li>‚úÖ<strong>Sepia Effect</strong>: Applies a warm brown tone to an image for a vintage look</li><li>‚úÖ<strong>Brightness Adjustment</strong>: Modifies image brightness by increasing or decreasing pixel intensity</li><li>‚úÖ<strong>Gamma Correction</strong>: Adjusts brightness using a gamma function</li><li>‚úÖ<strong>Saturation Adjustment</strong>: Enhances or reduces color intensity using a scaling factor</li><li>‚úÖ<strong>Sharpness Enhancement</strong>: Increases edge contrast to make the image appear clearer</li><li>üî≤<strong>Logarithmic Transformation</strong>: Expands dark regions in an image</li><li>üî≤<strong>Power-Law Transformation</strong>: Enhances image intensity using power-law curves</li></ul><h6 id="10--object-detection-and-segmentationhttpsgithubcommummanajagadeeshimprovetreemain10"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/10" target="_blank">10 Object Detection and Segmentation</a></strong></h6><ul><li>üî≤<strong>Template Matching</strong>: Detects objects by correlating with a template</li><li>üî≤<strong>Connected Component Labeling</strong>: Labels connected regions in binary images</li><li>üî≤<strong>Watershed Algorithm</strong>: Segments images based on intensity gradients</li><li>üî≤<strong>Active Contour (Snake Algorithm)</strong>: Iteratively detects object boundaries</li><li>üî≤<strong>Region Growing</strong>: Segments images based on pixel similarity</li></ul><h6 id="11--optical-flow-and-motion-analysishttpsgithubcommummanajagadeeshimprovetreemain11"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/11" target="_blank">11 Optical Flow and Motion Analysis</a></strong></h6><ul><li>üî≤<strong>Lucas-Kanade Method</strong>: Estimates optical flow for motion detection</li><li>üî≤<strong>Horn-Schunck Method</strong>: Computes dense optical flow for pixel-level motion analysis</li><li>üî≤<strong>Frame Differencing</strong>: Detects motion by subtracting consecutive frames</li></ul><h6 id="12--image-restorationhttpsgithubcommummanajagadeeshimprovetreemain12"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/12" target="_blank">12 Image Restoration</a></strong></h6><ul><li>üî≤<strong>Deconvolution</strong>: Restores blurred images caused by motion or defocus</li><li>üî≤<strong>Wiener Filter</strong>: Reduces noise while preserving image details</li><li>üî≤<strong>Inpainting</strong>: Fills missing or corrupted image regions</li></ul><h6 id="13--compression-algorithmshttpsgithubcommummanajagadeeshimprovetreemain13"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/13" target="_blank">13 Compression Algorithms</a></strong></h6><ul><li>üî≤<strong>Run-Length Encoding (RLE)</strong>: Compresses binary or grayscale images</li><li>üî≤<strong>Huffman Encoding</strong>: Compresses data using variable-length codes</li><li>üî≤<strong>JPEG Compression</strong>: Combines DCT, quantization, and Huffman encoding for image compression</li></ul><h6 id="more-to-come-">More to Come :)</h6><hr><h4 id="todo">TODO</h4><ul><li>Ensure the code is synthesizable by removing all non-synthesizable constructs.</li><li>Use CORDIC to eliminate functions like<code>$cos</code>,<code>$sin</code>,<code>$exp</code>,<code>$sqrt</code>, and other complex mathematical operations.</li><li>For constructs related to file I/O and read/write operations, use BRAM or RAM memory to store the input image in pixels.</li><li>The output image data for all three channels should be connected to a VGA display via a communication bus like PCIe or AXI.</li><li>Optimize the solution for performance and resource efficiency.</li></ul><p><strong>Currently working on CORDIC:</strong><a href="https://github.com/Mummanajagadeesh/cordic-algorithm-verilog" target="_blank">CORDIC Algorithm in Verilog</a></p><p><strong>Currently working on OCR using Verilog as well, building a neural network from scratch for MNIST number recognition</strong></p><hr><h4 id="tools-and-technologies"><strong>Tools and Technologies</strong></h4><ul><li><strong>Icarus Verilog 12 0</strong>: Core HDL used to implement all image processing algorithms</li><li><strong>Python 3 12 1</strong>: For preprocessing image data into a format compatible with verilog</li></ul><hr><h2 id="applications-irlhttpsgithubcommummanajagadeeshimprovetreemainapplications-irl"><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/Applications-IRL" target="_blank">Applications IRL</a></h2><h4 id="label-detection"><strong>Label-Detection</strong></h4><ul><li><p>Label detection was implemented using the<strong>Prewitt operator</strong> for edge detection. The process begins by splitting the image into three separate RGB channels using Python. Next, the<strong>luminance formula (NTSC)</strong> is applied to obtain a grayscale image.</p></li><li><p>If the image is too noisy or requires preprocessing,<strong>Gaussian blur</strong> and<strong>morphological operations</strong> are applied to refine the grayscale image before edge detection.</p></li><li><p>Edge detection algorithms are then used to identify strong edges. From these edges, the<strong>flood-fill algorithm</strong> is applied to detect the<strong>largest possible contour</strong>. A bounding rectangle is drawn in the red channel to enclose this contour, which is then superimposed on the original image for clear label detection.</p></li><li><p>This entire process is executed in Verilog using text files for data handling. Python is then used for visualization to generate the final output.</p></li></ul><h6 id="for-more-detailsimagesprojectsimprovelabel-detection"><a href="images/projects/improve/label-detection/">*For more details</a></h6><table><thead><tr><th><strong>Original Image</strong></th><th><strong>After Vertical Prewitt</strong></th><th><strong>After Horizontal Prewitt</strong></th><th><strong>After Full Prewitt</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ocr_test_1_hu13919557627271502897.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ocr_test_1_hu10928806484486211239.jpeg'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ver_hu17196909480092732094.webp" alt="After Vertical Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ver_hu15462590427229067200.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/hor_hu6331698311391901480.webp" alt="After Horizontal Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/hor_hu16023435030311149684.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/sumapp_hu17447641439322402501.webp" alt="After Full Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/sumapp_hu996122263598467842.jpg'"/></td></tr></tbody></table><table><thead><tr><th><strong>Original Image</strong></th><th><strong>After Full Prewitt</strong></th><th><strong>Binary Box</strong></th><th><strong>Overlayed Image with Box</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ocr_test_1_hu13919557627271502897.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ocr_test_1_hu10928806484486211239.jpeg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/sumapp_hu17447641439322402501.webp" alt="After Full Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/sumapp_hu996122263598467842.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/output_image_hu10251344748718835422.webp" alt="Binary Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/output_image_hu487853684034261260.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/output_image_with_box_hu9308675594061094941.webp" alt="Overlayed Image with Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/output_image_with_box_hu6234429136873210945.jpg'"/></td></tr></tbody></table><table><thead><tr><th><strong>Original Image</strong></th><th><strong>After Full Prewitt</strong></th><th><strong>Binary Box</strong></th><th><strong>Overlayed Image with Box</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ocr_test_2_hu10839364649639871445.webp" alt="Original Image 2" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ocr_test_2_hu1439726894735991236.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/prewcomb2_hu13524774109780843041.webp" alt="After Full Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/prewcomb2_hu5277213214539596495.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/binarybox2_hu11453858790861498169.webp" alt="Binary Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/binarybox2_hu12819195071595147379.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/boxedlabel2_hu7046968599601609959.webp" alt="Overlayed Image with Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/boxedlabel2_hu1845987694398134625.jpg'"/></td></tr></tbody></table><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/IXgA1Ih9BAo" frameborder="0" allowfullscreen=/></div></div><h4 id="document-scanner"><strong>Document Scanner</strong></h4><ul><li><p>The initial steps of the document scanning process are similar to label detection, with<strong>Canny edge detection</strong> being the preferred method for stronger edge identification.</p></li><li><p>After detecting edges, instead of directly superimposing a bounding rectangle, the<strong>boundary-fill algorithm</strong> is used to fill the detected region with binary 1s (255). A<strong>Boolean operation</strong> is then applied to remove irrelevant parts of the image that do not contain the document.</p></li><li><p>Next, corner detection is performed using the<strong>Moravec operator</strong> (as<strong>Harris</strong> is computationally expensive). Once the corners are identified,<strong>Bresenham&rsquo;s algorithm</strong> is used to draw lines connecting them, forming a quadrilateral around the document.</p></li><li><p>This quadrilateral is then mapped to a rectangle using<strong>homogeneous perspective transformation</strong>, followed by<strong>shearing</strong> and<strong>scaling</strong> operations if needed to refine the final output.</p></li></ul><p>OTW [Stuck at Bresenham&rsquo;s algorithm implementation]</p><h4 id="stereo-vision"><strong>Stereo Vision</strong></h4><ul><li><p>The process begins by converting the input stereo image pair from RGB to grayscale. Using the camera parameters, a<strong>disparity map</strong> is computed to determine the pixel shifts between the left and right images. This disparity information is then used to generate a<strong>depth map</strong>, which represents the distance of objects in the scene.</p></li><li><p>Both the disparity and depth map calculations are implemented entirely in Verilog, using text files for intermediate data storage and processing. Once the depth information is obtained, Python is used to continue the 3D reconstruction process, where the depth map is converted into a point cloud or a<strong>3D mesh representation</strong> for visualization.</p></li></ul><p>OTW [Accuracy of disparity and depth maps is low]</p><h4 id="mnist-digit-detection-never--improved"><strong>MNIST Digit Detection [NeVer ‚à© ImProVeD]</strong></h4><ul><li><p>I implemented a simple neural network from scratch in<strong>Google Colab</strong> without using<strong>TensorFlow</strong> or<strong>Keras</strong>, relying solely on<strong>NumPy</strong> for numerical computations,<strong>Pandas</strong> for data handling, and<strong>Matplotlib</strong> for visualization. The dataset used was<strong>sample_data/mnist_train_small.csv</strong>, containing handwritten digit images in a flattened<strong>784-pixel format</strong>. Data preprocessing involved<strong>normalizing pixel values</strong> (dividing by<strong>255</strong>) and splitting it into a<strong>training set</strong> and a<strong>development set</strong>, with the first<strong>1000 samples</strong> reserved for development and the rest for training. Labels (digits 0-9) were stored separately, and data was shuffled before training to ensure randomness.</p></li><li><p>The neural network consists of an<strong>input layer (784 neurons)</strong>, a<strong>hidden layer (128 neurons, ReLU activation)</strong>, and an<strong>output layer (10 neurons, softmax activation)</strong>. Model parameters (weights and biases) were initialized randomly and updated using<strong>gradient descent</strong> over<strong>500 iterations</strong> with a learning rate of<strong>0.1</strong>. Training involved<strong>forward propagation</strong> to compute activations and<strong>backpropagation</strong> to update parameters. Accuracy was printed every<strong>10 iterations</strong>. To make the trained model compatible with<strong>Verilog</strong>, weights and biases were<strong>scaled by 10,000</strong> and saved as<strong>integer values</strong> in text files (<code>W1.txt</code>,<code>b1.txt</code>, etc.), preventing<strong>floating-point multiplication</strong> in hardware. These parameters were later reloaded for predictions on new images, verifying model accuracy on the<strong>development set</strong> before deployment in Verilog for real-time digit classification.</p></li><li><p>The model, trained on<strong>sample_data/mnist_train_small.csv</strong>, achieved over<strong>90% accuracy</strong>. It generates<code>W1</code>,<code>W2</code>,<code>b1</code>, and<code>b2</code> text files containing shape information. The trained parameters are used in Verilog to predict digits from an input image stored in<code>input_vector.txt</code>, which consists of<strong>784 space-separated integers</strong>. The predicted output is displayed in the terminal using<code>$display</code>. The original CSV file was converted into a space-separated text format where each line contains a digit followed by<strong>784 pixel values (785 total)</strong>. During prediction, the first value (label) is removed to test if the model correctly classifies the input image.</p></li><li><p>The<strong>Verilog module</strong> implements a neural network to classify handwritten digits from the MNIST dataset. It comprises an<strong>input layer (784 neurons), hidden layer (128 neurons), and output layer (10 neurons)</strong>. The module reads<strong>pre-trained weights and biases</strong> from text files (<code>W1.txt</code>,<code>b1.txt</code>,<code>W2.txt</code>,<code>b2.txt</code>) along with an<strong>input vector</strong> from<code>input_vector.txt</code>. Input values are normalized by dividing by<strong>255.0</strong>, while weights and biases are scaled using a<strong>factor of 10,000</strong>. The hidden layer performs a fully connected transformation (<code>W1 * input + b1</code>) followed by<strong>ReLU activation</strong>. The output layer computes another weighted sum (<code>W2 * hidden + b2</code>) but does not apply softmax; instead, the predicted digit is determined by selecting the index of the highest output value.</p></li><li><p>The file reading process ensures proper loading of weights, biases, and input values before computation begins. Forward propagation occurs sequentially, with an initial delay for data loading. After computing activations in both layers, the module iterates through the output layer to identify the highest value, representing the predicted class. The classification result is then displayed. This hardware implementation streamlines neural network inference by<strong>eliminating complex activation functions</strong> like softmax while preserving classification accuracy through maximum output activation.</p></li><li><p>In newer versions of the code, the text files are converted into<strong>synthesizable memory blocks</strong> using Python scripts. These scripts store<strong>weights and biases</strong> in register modules, which are finally instantiated in the<strong>top-level module</strong>. The image data is also handled in a similar way.</p></li><li><p>Only the<code>$display</code> statement,<code>$finish</code>, and the<code>real</code> datatype in the final top-level module are non-synthesizable constructs. These can be eliminated by directing the predicted output to a seven-segment display using case statements [Moved these constructs to the testbench in later versions for a cleaner top module; currently working with<code>Q24.8</code> as a replacement for the real datatype].</p></li><li><p>I am currently working on replacing the<strong>training process</strong> with a Verilog-based implementation, aiming for a fully synthesizable neural network.</p></li></ul><blockquote><p>This approach can pave a new way for POC, where text files are converted into register modules using Python scripts to automate the process. A top-level module can then connect all the generated modules, and the testbench can include $fopen, etc., to write the output text files. The testbench instantiates the top-level module, ensuring that all files are synthesizable.</p></blockquote><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/QtkdWSq25zQ" frameborder="0" allowfullscreen=/></div></div><h4 id="ocr-optical-character-recognition"><strong>OCR: Optical Character Recognition</strong></h4><p>This model is trained on the<strong>EMNIST ByClass dataset</strong> (<a href="https://greg-cohen.com/datasets/emnist/" target="_blank">source</a>), which contains<strong>62 classes</strong> (digits<code>0-9</code>, uppercase letters<code>A-Z</code>, and lowercase letters<code>a-z</code>). The dataset is preprocessed by converting it into a CSV format, normalizing pixel values, reducing dimensions, and shuffling before training.</p><p>The neural network consists of multiple layers:</p><ul><li>Input layer:<strong>784 neurons</strong></li><li>First hidden layer:<strong>256 neurons</strong> (<code>W1: 256√ó784</code>,<code>b1: 256√ó1</code>)</li><li>Second hidden layer:<strong>128 neurons</strong> (<code>W2: 128√ó256</code>,<code>b2: 128√ó1</code>)</li><li>Output layer:<strong>62 neurons</strong> (<code>W3: 62√ó128</code>,<code>b3: 62√ó1</code>)</li></ul><p>Training is done using forward propagation, computing activations at each layer using matrix multiplications and ReLU activations for hidden layers. Backpropagation is used to update weights using the gradient of the loss function. The dataset is shuffled to improve generalization, and weights (<code>W1</code>,<code>W2</code>,<code>W3</code>) and biases (<code>b1</code>,<code>b2</code>,<code>b3</code>) are updated iteratively until convergence. The model is trained over multiple epochs using stochastic gradient descent (SGD) and Adam&rsquo;s Optimiser.</p><p>To make the trained model compatible with hardware, weights and biases are<strong>scaled by 10,000</strong> and stored as integers in text files (<code>W1.txt</code>,<code>b1.txt</code>, etc.), since Verilog does not support floating-point arithmetic.</p><p>Inference in Verilog follows a similar process but supports extra layers and classes. Input images are read from<code>input_vector.txt</code> and normalized. Weights and biases are loaded from text files. The computation follows:</p><ul><li><code>hidden1 = ReLU(W1 * input + b1)</code></li><li><code>hidden2 = ReLU(W2 * hidden1 + b2)</code></li><li><code>output = W3 * hidden2 + b3</code></li></ul><p>The index of the<strong>maximum output value</strong> determines the predicted character, which is mapped to<code>"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"</code> and displayed using<code>$display</code>.</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/7YccFUtydM0" frameborder="0" allowfullscreen=/></div></div><p>The video demonstrates that<code>draw.py</code> allows us to draw anything on a square canvas. At the end, it applies grayscale, inverts the image, compresses it to a 28√ó28 resolution, and saves it as<code>drawing.jpg</code>. Then,<code>img2bin.py</code> converts this image into a 2D array of pixels (a 28√ó28 matrix) and saves it in<code>mnist_single_no.txt</code>.</p><p>Next,<code>arr2row.py</code> flattens the 2D array into a 1D array (a row of 784 values) and stores it in<code>input_vector.txt</code>. This file is then used to create<code>image_memory.v</code> with<code>memloader_from_inp_vec.py</code>, which generates a memory module for storing the image.</p><p>Following this,<code>wtbs_loader.py</code> creates six different memory modules from<code>W1</code>,<code>W2</code>,<code>W3</code>,<code>b1</code>,<code>b2</code>, and<code>b3</code> text files, generating corresponding files such as<code>W1_memory.v</code>, and so on.</p><p>All these components are instantiated in the top module<code>emnist_with_tb.v</code>, along with a testbench (<code>emnist_nn_tb.v</code>). This setup ultimately predicts the drawn character. In the demo, I showcased the characters &ldquo;H,&rdquo; &ldquo;f,&rdquo; and &ldquo;7&rdquo;‚Äîeach representing a different subclass from the 62 available classes (uppercase letters, lowercase letters, and numbers).</p><blockquote><p>Additionally, I developed a coarse-grained pipelined fully connected neural network using Finite State Machine (FSM) and integrated Softmax with a Taylor series approximation to improve computational efficiency</p></blockquote><hr><hr><h4 id="important-links-and-resources"><strong>Important Links and Resources</strong></h4><h6 id="digital-image-processing"><strong>Digital Image Processing</strong></h6><ul><li><a href="https://www.geeksforgeeks.org/digital-image-processing-tutorial" target="_blank"><strong>GeeksforGeeks: Digital Image Processing Tutorial</strong></a></li><li><a href="https://youtu.be/KuXjwB4LzSA" target="_blank"><strong>YouTube: Digital Image Processing Introduction</strong></a></li><li><a href="https://www.youtube.com/live/8rrHTtUzyZA" target="_blank"><strong>YouTube Live: Advanced Digital Image Processing Concepts</strong></a></li></ul><h6 id="mathematics-for-engineering-and-computing"><strong>Mathematics for Engineering and Computing</strong></h6><ul><li><a href="https://youtu.be/w8yWXqWQYmU" target="_blank"><strong>YouTube: Building a neural network FROM SCRATCH</strong></a></li><li><a href="https://youtu.be/cAkMcPfY_Ns" target="_blank"><strong>YouTube: I Built a Neural Network from Scratch</strong></a></li><li><a href="https://youtu.be/cAkMcPfY_Ns" target="_blank"><strong>YouTube: Linear Algebra ‚Äì Essence of Linear Algebra (Playlist)</strong></a></li></ul><h6 id="verilog"><strong>Verilog</strong></h6><ul><li><a href="http://www.asic.co.in/Index_files/verilog_files/File_IO.htm" target="_blank"><strong>Guide to Verilog File I/O and File Handling</strong></a></li><li><a href="https://steveicarus.github.io/iverilog/" target="_blank"><strong>Official Icarus Verilog Documentation</strong></a></li><li><a href="https://www.youtube.com/playlist?list=PLJ5C_6qdAvBELELTSPgzYkQg3HgclQh-5" target="_blank"><strong>NPTEL Lectures</strong></a></li></ul><h6 id="cordic-algorithm-resources"><strong>CORDIC Algorithm Resources</strong></h6><ul><li><a href="https://ieeexplore.ieee.org/document/6808249" target="_blank"><strong>IEEE Xplore: Hardware Implementation of a Math Module Based on the CORDIC Algorithm Using FPGA</strong></a></li><li><a href="http://ethesis.nitrkl.ac.in/4258/1/CORDIC_Algorithm_and_it%E2%80%99s_Applications_in_DSP.pdf" target="_blank"><strong>CORDIC Algorithm and Its Applications in DSP (NITR Thesis)</strong></a></li><li><a href="https://www.eit.lth.se/fileadmin/eit/courses/eitf35/2017/CORDIC_For_Dummies.pdf" target="_blank"><strong>CORDIC for Dummies (Introductory Guide)</strong></a></li><li><a href="https://www.st.com/resource/en/application_note/an5325-how-to-use-the-cordic-to-perform-mathematical-functions-on-stm32-mcus-stmicroelectronics.pdf" target="_blank"><strong>STMicroelectronics: Using the CORDIC for Mathematical Functions on STM32 MCUs</strong></a></li><li><a href="https://projectf.io/posts/square-root-in-verilog/" target="_blank"><strong>Square Root Calculation Using CORDIC In System Verilog</strong></a></li></ul><h6 id="datasets"><strong>Datasets</strong></h6><ul><li><a href="https://www.kaggle.com/datasets/hojjatk/mnist-dataset" target="_blank"><strong>MNIST Dataset: 0-9 Handwritten Numbers</strong></a></li><li><a href="https://greg-cohen.com/datasets/emnist/" target="_blank"><strong>EMNIST Dataset: Extended MNIST with Alphabet Support</strong></a></li><li><a href="https://www.kaggle.com/datasets/preatcher/standard-ocr-dataset" target="_blank"><strong>Standard OCR Dataset: Various Images of Characters in Different Fonts</strong></a></li></ul><h4 id="contributors"><strong>Contributors</strong></h4><ul><li><strong><a href="https://github.com/Mummanajagadeesh" target="_blank">Jagadeesh</a></strong> mummanajagadeesh97@gmail com</li></ul><p>Feel free to contribute by submitting pull requests or feature suggestions!</p><p>If interested in working together, do drop a DM or mail üôÇ</p><hr><h6 id="note">NOTE</h6><blockquote><p><strong>Missing Images</strong>:</p><ul><li>Some of the images may be missing due to unforeseen issues. If you notice any missing images, please inform me</li></ul><p><strong>Code Structure</strong>:</p><ul><li>Not all code snippets follow the same structural order. This is intentional, as some parts are specifically designed to handle their unique mathematical requirements
Priority was given to making each individual piece of code functional rather than ensuring the overall scalability of the project</li></ul><p><strong>AI Assistance</strong>:</p><ul><li>Fair use of AI (e.g., ChatGPT) was employed for syntax suggestions and debugging. Kudos to ChatGPT for its support!</li></ul><p><strong>Math Adaptations</strong>:</p><ul><li>Not every piece of code adheres strictly to its intended mathematical model. Verilog&rsquo;s limitations in computational math have necessitated ample adjustments, with liberties taken to ensure functionality.</li></ul><p><strong>Feedback &amp; Help</strong>:</p><ul><li>Please let me know if you have any suggestions or tips.</li><li>I am in desperate need of help and would greatly appreciate any assistance or advice.</li></ul><p>Thank you for your understanding and support!</p></blockquote><hr><h3 id="selected-image-processing-results">Selected Image Processing Results</h3><p>Below are some of the best results from my image processing work. While there are many more images, including all of them here without relevant explanations wouldn&rsquo;t be meaningful. For a detailed breakdown of the implementation and the mathematical concepts behind each operation, please refer to my repository.</p><h4 id="edge-detection--prewitt-operator">Edge Detection ‚Äì Prewitt Operator</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="174" src="/images/projects/improve/prew_hu14485036167346296400.webp" alt="Edge Detection using Prewitt Operator" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/prew_hu3609621892283918472.png'"/><h4 id="corner-detection---moravec">Corner Detection - Moravec</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="173" src="/images/projects/improve/moravec_hu4426639061087632241.webp" alt="Corner Detection using Moravec Operator" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/moravec_hu13206110617131018639.png'"/><h4 id="noise-reduction--gaussian-blur">Noise Reduction ‚Äì Gaussian Blur</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="410" src="/images/projects/improve/blur_hu13931810281779614461.webp" alt="Gaussian Blur for Noise Reduction" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/blur_hu16496045989595046987.png'"/><h4 id="thresholding--otsus-method">Thresholding ‚Äì Otsu&rsquo;s Method</h4><p><img title="" loading="lazy" decoding="async" class="img  " width="900" height="492" src="/images/projects/improve/otsu_hu7621719573966248452.webp" alt="Otsu Thresholding" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/otsu_hu12720199206830679443.png'"/><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="308" src="/images/projects/improve/otsu-hist_hu13993907817821689128.webp" alt="Otsu Thresholding Histogram" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/otsu-hist_hu13165393985746506984.png'"/></p><h4 id="geometric-transformations">Geometric Transformations</h4><ul><li><strong>Rotation with Same Dimensions</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="201" src="/images/projects/improve/rotcut_hu12403607722010353627.webp" alt="Rotation with Same Dimensions" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/rotcut_hu9108364962968928806.png'"/></li><li><strong>Rotation with Diagonal Dimensions</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="386" src="/images/projects/improve/rotcutfull_hu17031735047347652399.webp" alt="Rotation with Diagonal Dimensions" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/rotcutfull_hu16877135504742872457.png'"/></li><li><strong>Scaling</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="323" src="/images/projects/improve/scale_hu11629296297124285949.webp" alt="Image Scaling" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/scale_hu6655431341958216477.png'"/></li><li><strong>Translation</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="326" src="/images/projects/improve/trans_hu17118263611395243036.webp" alt="Image Translation" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/trans_hu2658960167232227844.png'"/></li><li><strong>Shearing</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="288" src="/images/projects/improve/shear_hu808802054320107791.webp" alt="Image Shearing" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/shear_hu12479457589907686955.png'"/></li><li><strong>Cropping</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="322" src="/images/projects/improve/crop_hu1867138612663489322.webp" alt="Image Cropping" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/crop_hu12490494274397994217.png'"/></li><li><strong>Reflection (Both Axes)</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="328" src="/images/projects/improve/reflect_hu11148049716556324265.webp" alt="Reflection Across Both Axes" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/reflect_hu11740995939101131997.png'"/></li><li><strong>3D Homogeneous Perspective Transformation</strong><img title="" loading="lazy" decoding="async" class="img  " width="900" height="303" src="/images/projects/improve/perspective_hu11774544397983656204.webp" alt="Homogeneous Perspective Transformation" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/perspective_hu860997924819376058.png'"/></li></ul><h4 id="color-and-intensity-transformations">Color and Intensity Transformations</h4><ul><li><strong>Gamma Correction</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="251" src="/images/projects/improve/gamma_hu12647473034062461938.webp" alt="Gamma Correction" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/gamma_hu13031868251393833673.png'"/></li><li><strong>Image Inversion</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="387" src="/images/projects/improve/invert_hu11986350512840661324.webp" alt="Image Inversion" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/invert_hu18030242693197521912.png'"/></li><li><strong>Sepia Effect</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="364" src="/images/projects/improve/sepia_hu4492659394685576999.webp" alt="Sepia Effect" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/sepia_hu15684750827536297281.png'"/></li><li><strong>Negative Transformation</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="381" src="/images/projects/improve/negative_hu5983120251068387285.webp" alt="Negative Transformation" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/negative_hu7509850049545257268.png'"/></li><li><strong>Grayscale Conversion</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="374" src="/images/projects/improve/gray_hu16204671916920617266.webp" alt="Grayscale Conversion" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/gray_hu9130351653664285082.png'"/></li><li><strong>Contrast Adjustment</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="203" src="/images/projects/improve/contrast_hu14946102901654560277.webp" alt="Contrast Adjustment" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/contrast_hu16150499439149074672.png'"/></li><li><strong>Brightness Adjustment</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="373" src="/images/projects/improve/bright_hu3341463385452583707.webp" alt="Brightness Adjustment" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/bright_hu16692706153309742860.png'"/></li><li><strong>Saturation Adjustment</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="221" src="/images/projects/improve/saturation_hu581103770668551537.webp" alt="Saturation Adjustment" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/saturation_hu1114309998585183769.png'"/></li><li><strong>Sharpness Enhancement</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="201" src="/images/projects/improve/sharpness_hu9178690489823450702.webp" alt="Sharpness Enhancement" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/sharpness_hu18410522331567221241.png'"/></li></ul><p>For more insights into the implementation, visit my repository, where I provide a comprehensive explanation of the mathematical foundations behind each operation.</p><hr><h3 id="proof-of-concept-proposal-fpga-implementation-of-improve"><strong>Proof of Concept Proposal: FPGA Implementation of ImProVe</strong></h3><p>The goal of this proof of concept is to transition<strong>ImProVe</strong> from a Verilog-based image processing simulation to a fully FPGA-compatible implementation. The current approach, while functional, relies heavily on software-based file I/O, lacks real-time processing capabilities, and does not take advantage of hardware acceleration. This proposal outlines a new FPGA-based workflow that optimizes performance, enables parallel processing, and integrates efficient mathematical computation techniques like<strong>CORDIC for trigonometric and square root calculations</strong>.</p><h4 id="current-workflow-and-its-limitations"><strong>Current Workflow and Its Limitations</strong></h4><p>The existing implementation is purely<strong>simulation-based</strong>, using<strong>Icarus Verilog</strong> without testbenches. Images are pre-processed using<strong>Python (NumPy)</strong>, converted into<strong>.hex or .txt</strong> files, and then read into Verilog through file I/O functions. After processing, the results are stored in a corresponding output file, converted back into an image, and visually verified or cross-checked with a reference Python implementation.</p><p>While this approach enables functional validation, it suffers from several limitations:</p><ul><li><strong>File I/O is slow</strong> and does not reflect real-world FPGA-based image processing.</li><li><strong>No hardware optimizations</strong>, making it unsuitable for real-time applications.</li><li><strong>No pipelining or parallelism</strong>, leading to inefficient processing for large images.</li><li><strong>Mathematical operations</strong> (like square root and trigonometric functions) rely on direct computation rather than optimized hardware-friendly methods.</li></ul><h4 id="proposed-fpga-based-workflow"><strong>Proposed FPGA-Based Workflow</strong></h4><p>The<strong>FPGA implementation</strong> will be designed to replace file-based image processing with a<strong>high-speed AXI-based pipeline</strong> that processes images in real time. Key improvements include:</p><h5 id="cordic-for-mathematical-computation"><strong>CORDIC for Mathematical Computation</strong></h5><p>Operations like<strong>image rotation, edge detection, and geometric transformations</strong> require trigonometric functions (sin, cos) and square root calculations. Instead of using costly multipliers or look-up tables, these will be implemented using<strong>CORDIC (COordinate Rotation DIgital Computer)</strong>, which efficiently computes trigonometric functions, logarithms, and square roots in hardware without requiring floating-point arithmetic.</p><h5 id="memory-optimization-ddr-for-image-storage-bram-for-intermediate-buffers"><strong>Memory Optimization: DDR for Image Storage, BRAM for Intermediate Buffers</strong></h5><ul><li><strong>DDR (Dynamic RAM)</strong> will be used to store the original image and final processed output. This allows handling large images without running into FPGA memory constraints.</li><li><strong>BRAM (Block RAM)</strong> will serve as an intermediate buffer, storing smaller<strong>overlapping regions</strong> of the image during processing.</li><li><strong>AXI4 (Advanced eXtensible Interface)</strong> will manage data transfer between<strong>DDR and the processing modules</strong>, ensuring efficient memory access without bottlenecks.</li></ul><h5 id="axi-stream-for-processing-pipelines"><strong>AXI-Stream for Processing Pipelines</strong></h5><p>Rather than processing an image sequentially,<strong>AXI-Stream will enable a pipeline approach</strong>, where multiple processing stages operate in parallel. This allows continuous data flow, reducing latency and improving throughput.</p><h5 id="parallel-processing-using-image-splitting"><strong>Parallel Processing Using Image Splitting</strong></h5><p>For<strong>operations that do not involve geometric transformations</strong>, the image will be<strong>split into overlapping regions</strong> with necessary padding to avoid edge artifacts. These smaller blocks will be processed<strong>simultaneously</strong> and later recombined. This significantly speeds up computation while ensuring accuracy. For<strong>geometric transformations</strong>, special handling will be required to correctly map pixel positions.</p><h5 id="axi-dma-for-efficient-data-transfer"><strong>AXI DMA for Efficient Data Transfer</strong></h5><p>To avoid CPU intervention in moving image data,<strong>AXI DMA (Direct Memory Access)</strong> will be used to transfer pixel data<strong>directly between DDR and processing units</strong>, allowing continuous streaming of images into the pipeline without stalling.</p><h5 id="vgawireless-display-output-optional-enhancement"><strong>VGA/Wireless Display Output (Optional Enhancement)</strong></h5><p>If real-time visualization of processed images is needed, a<strong>VGA output or a wireless display interface (such as HDMI over Wi-Fi or LVDS panels)</strong> can be integrated. This eliminates the need for software-based file conversions and external host reconstruction, allowing direct, real-time monitoring of image processing results. While not mandatory, this enhancement can significantly improve debugging efficiency and system usability.</p><h5 id="testbenches-for-validation"><strong>Testbenches for Validation</strong></h5><p>To ensure<strong>mathematical accuracy</strong>, the new FPGA implementation will include<strong>systematic testbenches</strong> that validate outputs<strong>pixel-by-pixel</strong> against a Python reference. Unlike the current workflow, which relies on visual verification, this will ensure exact mathematical equivalence.</p><h4 id="expected-outcomes"><strong>Expected Outcomes</strong></h4><p>By implementing this optimized FPGA-based workflow,<strong>ImProVe</strong> will transition from a<strong>simulated Verilog project to a real-time, hardware-accelerated image processing system</strong>. The use of<strong>CORDIC, AXI-based memory architecture, parallel processing, pipelining, and real-time display output</strong> will significantly enhance performance, making the system viable for embedded vision applications in robotics, medical imaging, and autonomous systems.</p><p>I&rsquo;m working on the POC in parallel, and as of now, I have implemented square root using CORDIC, though it still requires some fine-tuning. This is just a proposal and may evolve further based on implementation challenges and optimizations needed along the way. The PoC will serve as a proof of concept for all the modules, ensuring they can be adapted for FPGA implementation. By the end, I aim to demonstrate at least one module as synthesizable and successfully implement it on an FPGA board.</p>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/improve/edge-detec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/improve/edge-detec/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/lfr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/lfr/</guid><description>&lt;![CDATA[<h2 id="line-follower-robothttpsgithubcommummanajagadeeshline-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">Line Follower Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>LFRBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This project features a robot that follows a line using basic sensors. It detects the line on the ground and adjusts its movement to stay on track. The robot can navigate turns and intersections without needing complex algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">LFRBOTüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="line-follower-robothttpsgithubcommummanajagadeeshline-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">Line Follower Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>LFRBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This project features a robot that follows a line using basic sensors. It detects the line on the ground and adjusts its movement to stay on track. The robot can navigate turns and intersections without needing complex algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">LFRBOTüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p><h3 id="features">Features</h3><ul><li>Simulation of a simple line-following robot using two infrared (IR) sensors placed on either side of the robot.</li><li>Black track designed in Tinkercad, exported and used in the Webots simulation.</li><li>Simple control logic based on IR sensor values to adjust the robot&rsquo;s movement.</li><li>No PID controller is used; instead, the robot makes decisions using basic conditional statements to steer left or right based on sensor readings.</li></ul><h3 id="demo-video">Demo Video</h3><p>Click the image below to watch a demo of the simulation in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/rejXYcaX9NQ" frameborder="0" allowfullscreen=/></div></div><h3 id="how-it-works">How It Works</h3><h4 id="robot-design">Robot Design</h4><p>The robot used in this simulation is the<strong>e-puck</strong>, a simple differential drive robot with two IR sensors positioned on the left and right sides. These sensors detect the black line against the background, and based on their readings, the robot adjusts its movement.</p><ul><li><strong>Left IR Sensor (<code>ir0</code>)</strong>: Detects the black line on the left side.</li><li><strong>Right IR Sensor (<code>ir1</code>)</strong>: Detects the black line on the right side.</li><li><strong>Wheels</strong>: Two differential drive motors control the movement of the robot (left and right wheels).</li></ul><h4 id="track-design">Track Design</h4><p>The black track was created in<strong>Tinkercad</strong> and exported into the simulation environment. You can find the track mesh file in the<strong>meshes</strong> folder.</p><h4 id="control-logic">Control Logic</h4><p>The robot&rsquo;s movement is controlled by checking the values of the left and right IR sensors and adjusting the wheel velocities accordingly:</p><ul><li><strong>Straight Movement</strong>: If both sensors detect similar values, the robot moves forward.</li><li><strong>Turning</strong>:<ul><li>If the left IR sensor detects the black line (i.e., its value increases), the robot turns<strong>left</strong> by reducing the left motor&rsquo;s speed and potentially reversing it.</li><li>If the right IR sensor detects the black line, the robot turns<strong>right</strong> by reducing the right motor&rsquo;s speed.</li></ul></li></ul><p>The control logic does not involve a<strong>PID controller</strong>. Instead, basic threshold-based conditions are used to decide the robot‚Äôs steering direction.</p><h4 id="code-explanation">Code Explanation</h4><h6 id="key-points">Key Points:</h6><ul><li><strong>Timestep</strong>: The simulation steps are updated every 32ms.</li><li><strong>Max Speed</strong>: The maximum angular velocity for the motors is set to 25% of the full motor speed (6.28 rad/s).</li><li><strong>IR Sensor Values</strong>: The values of the IR sensors are used to detect the black line. A value between 6 and 15 indicates the robot is over the line, and the respective motor is slowed or reversed to turn the robot.</li><li><strong>Motor Control</strong>: The motors are set to velocity mode, and their speed is adjusted based on the sensor inputs. When one sensor detects a stronger signal, the robot turns in that direction.</li></ul><h3 id="installation-and-usage">Installation and Usage</h3><h4 id="requirements">Requirements</h4><ul><li><strong>Webots</strong>: Install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure that you have Python installed to run the robot controller.</li></ul><h4 id="steps-to-run">Steps to Run</h4><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/line-follower-robot-w.git</span></span><span style="display:flex;"><span>cd line-follower-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>line_follower_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation and observe the robot following the line on the black track.</li></ol><h4 id="meshes">Meshes</h4><p>The<strong>meshes</strong> folder contains the black track design exported from<strong>Tinkercad</strong>. This is used in the Webots simulation for the robot to follow.</p><h3 id="future-enhancements">Future Enhancements</h3><ul><li><strong>PID Control</strong>: Although the current implementation uses basic threshold logic, PID control can be added for smoother and more accurate line following.</li><li><strong>Speed Optimization</strong>: The robot speed can be adjusted dynamically based on how sharply it needs to turn.</li><li><strong>Additional Sensors</strong>: Adding more IR sensors could improve the robot‚Äôs accuracy when following complex curves or intersections in the track.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/obstacle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/obstacle/</guid><description>&lt;![CDATA[<h2 id="obstacle-avoidance-robothttpsgithubcommummanajagadeeshobstacle-avoidance-robot-w"><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">Obstacle Avoidance Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Obstacle Avoidance Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A robot equipped with basic sensors that detects obstacles and changes direction to avoid collisions without using advanced algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">OARüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="obstacle-avoidance-robothttpsgithubcommummanajagadeeshobstacle-avoidance-robot-w"><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">Obstacle Avoidance Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Obstacle Avoidance Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A robot equipped with basic sensors that detects obstacles and changes direction to avoid collisions without using advanced algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">OARüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p><h3 id="features">Features</h3><ul><li>Simulation of a simple line-following robot using two infrared (IR) sensors placed on either side of the robot.</li><li>Black track designed in Tinkercad, exported and used in the Webots simulation.</li><li>Simple control logic based on IR sensor values to adjust the robot&rsquo;s movement.</li><li>No PID controller is used; instead, the robot makes decisions using basic conditional statements to steer left or right based on sensor readings.</li></ul><h3 id="demo-video">Demo Video</h3><p>Click the image below to watch a demo of the simulation in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/rejXYcaX9NQ" frameborder="0" allowfullscreen=/></div></div><h3 id="how-it-works">How It Works</h3><h4 id="robot-design">Robot Design</h4><p>The robot used in this simulation is the<strong>e-puck</strong>, a simple differential drive robot with two IR sensors positioned on the left and right sides. These sensors detect the black line against the background, and based on their readings, the robot adjusts its movement.</p><ul><li><strong>Left IR Sensor (<code>ir0</code>)</strong>: Detects the black line on the left side.</li><li><strong>Right IR Sensor (<code>ir1</code>)</strong>: Detects the black line on the right side.</li><li><strong>Wheels</strong>: Two differential drive motors control the movement of the robot (left and right wheels).</li></ul><h4 id="track-design">Track Design</h4><p>The black track was created in<strong>Tinkercad</strong> and exported into the simulation environment. You can find the track mesh file in the<strong>meshes</strong> folder.</p><h4 id="control-logic">Control Logic</h4><p>The robot&rsquo;s movement is controlled by checking the values of the left and right IR sensors and adjusting the wheel velocities accordingly:</p><ul><li><strong>Straight Movement</strong>: If both sensors detect similar values, the robot moves forward.</li><li><strong>Turning</strong>:<ul><li>If the left IR sensor detects the black line (i.e., its value increases), the robot turns<strong>left</strong> by reducing the left motor&rsquo;s speed and potentially reversing it.</li><li>If the right IR sensor detects the black line, the robot turns<strong>right</strong> by reducing the right motor&rsquo;s speed.</li></ul></li></ul><p>The control logic does not involve a<strong>PID controller</strong>. Instead, basic threshold-based conditions are used to decide the robot‚Äôs steering direction.</p><h4 id="code-explanation">Code Explanation</h4><h6 id="key-points">Key Points:</h6><ul><li><strong>Timestep</strong>: The simulation steps are updated every 32ms.</li><li><strong>Max Speed</strong>: The maximum angular velocity for the motors is set to 25% of the full motor speed (6.28 rad/s).</li><li><strong>IR Sensor Values</strong>: The values of the IR sensors are used to detect the black line. A value between 6 and 15 indicates the robot is over the line, and the respective motor is slowed or reversed to turn the robot.</li><li><strong>Motor Control</strong>: The motors are set to velocity mode, and their speed is adjusted based on the sensor inputs. When one sensor detects a stronger signal, the robot turns in that direction.</li></ul><h3 id="installation-and-usage">Installation and Usage</h3><h4 id="requirements">Requirements</h4><ul><li><strong>Webots</strong>: Install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure that you have Python installed to run the robot controller.</li></ul><h4 id="steps-to-run">Steps to Run</h4><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/line-follower-robot-w.git</span></span><span style="display:flex;"><span>cd line-follower-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>line_follower_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation and observe the robot following the line on the black track.</li></ol><h4 id="meshes">Meshes</h4><p>The<strong>meshes</strong> folder contains the black track design exported from<strong>Tinkercad</strong>. This is used in the Webots simulation for the robot to follow.</p><h3 id="future-enhancements">Future Enhancements</h3><ul><li><strong>PID Control</strong>: Although the current implementation uses basic threshold logic, PID control can be added for smoother and more accurate line following.</li><li><strong>Speed Optimization</strong>: The robot speed can be adjusted dynamically based on how sharply it needs to turn.</li><li><strong>Additional Sensors</strong>: Adding more IR sensors could improve the robot‚Äôs accuracy when following complex curves or intersections in the track.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/pidc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/pidc/</guid><description>&lt;![CDATA[<h2 id="pidc---pid-controller-using-opampshttpsgithubcommummanajagadeeshpidc_ctrl"><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDC - PID Controller using OpAmps</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PIDC</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Implemented a PID controller using operational amplifiers to regulate system response and maintain desired performance. The design leverages analog circuitry to achieve precise control over error correction and stability.</td></tr><tr><td><strong>Start</strong></td><td>Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDCüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation , OpAmps</td></tr><tr><td><strong>Tools Used</strong></td><td>LtSpice</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><h4 id="pid-controller-theory-and-hardware-realization-using-op-amps"><strong>PID Controller: Theory and Hardware Realization Using Op-Amps</strong></h4><p>A<strong>PID (Proportional-Integral-Derivative) controller</strong> is a fundamental tool in control systems, widely used in industrial automation, robotics, temperature control, and motor speed regulation. It is designed to<strong>minimize error</strong> and<strong>improve stability</strong> by adjusting a system‚Äôs input based on the error between the desired setpoint and the actual output.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="pidc---pid-controller-using-opampshttpsgithubcommummanajagadeeshpidc_ctrl"><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDC - PID Controller using OpAmps</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PIDC</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Implemented a PID controller using operational amplifiers to regulate system response and maintain desired performance. The design leverages analog circuitry to achieve precise control over error correction and stability.</td></tr><tr><td><strong>Start</strong></td><td>Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDCüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation , OpAmps</td></tr><tr><td><strong>Tools Used</strong></td><td>LtSpice</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><h4 id="pid-controller-theory-and-hardware-realization-using-op-amps"><strong>PID Controller: Theory and Hardware Realization Using Op-Amps</strong></h4><p>A<strong>PID (Proportional-Integral-Derivative) controller</strong> is a fundamental tool in control systems, widely used in industrial automation, robotics, temperature control, and motor speed regulation. It is designed to<strong>minimize error</strong> and<strong>improve stability</strong> by adjusting a system‚Äôs input based on the error between the desired setpoint and the actual output.</p><h4 id="why-introduce-the-pid-controller"><strong>Why Introduce the PID Controller?</strong></h4><p>Before jumping straight into PID, it&rsquo;s useful to start with simpler controllers and gradually add complexity. This helps in understanding<strong>why</strong> each term (P, I, D) is necessary and how they contribute to system performance.</p><ul><li><strong>Proportional (P) Control</strong> ‚Äì Reacts to the current error but does not eliminate steady-state error.</li><li><strong>Integral (I) Control</strong> ‚Äì Eliminates steady-state error by integrating past errors.</li><li><strong>Derivative (D) Control</strong> ‚Äì Predicts future errors by considering the rate of change.</li></ul><p>This structured approach builds an<strong>intuitive understanding</strong> of why each term is needed before implementing them in hardware.</p><h4 id="mathematical-formulation-of-pid"><strong>Mathematical Formulation of PID</strong></h4><p>The<strong>PID control law</strong> in the time domain is:</p><p>$$
u(t) = K_p e(t) + K_i \int e(t) dt + K_d \frac{d e(t)}{dt}
$$</p><p>where:</p><ul><li>(e(t) = r(t) y(t)) (error between the desired setpoint (r(t)) and actual output (y(t))).</li><li>(K_p) is the<strong>proportional gain</strong> (how much we react to the present error).</li><li>(K_i) is the<strong>integral gain</strong> (how much we consider past errors).</li><li>(K_d) is the<strong>derivative gain</strong> (how much we predict future errors).</li></ul><p>In the<strong>Laplace domain</strong>, the PID transfer function is:</p><p>$$
U(s) = \left( K_p + \frac{K_i}{s} + K_d s \right) E(s)
$$</p><p>which represents the combined effect of<strong>P, I, and D</strong> on the system.</p><h4 id="hardware-realization-of-pid-using-op-amps"><strong>Hardware Realization of PID Using Op-Amps</strong></h4><p>Op-amps are ideal for<strong>analog PID implementation</strong> because they can easily perform<strong>amplification, integration, and differentiation</strong> using simple resistor-capacitor networks.</p><h6 id="proportional-p-controller-using-op-amps"><strong>Proportional (P) Controller Using Op-Amps</strong></h6><p>A proportional controller applies a gain (K_p) to the input error signal. This can be implemented using a<strong>non-inverting op-amp configuration</strong>:</p><p><strong>Circuit:</strong><br>
Use an<strong>op-amp in non-inverting mode</strong> with a feedback resistor (R_f) and input resistor (R_1).</p><p><strong>Gain Equation:</strong><br>
$$
K_p = 1 + \frac{R_f}{R_1}
$$</p><p><strong>Transfer Function:</strong><br>
$$
V_{out}(s) = K_p V_{in}(s)
$$</p><p><strong>Effect:</strong> Improves response speed but does not eliminate steady-state error.</p><h6 id="integral-i-controller-using-op-amps"><strong>Integral (I) Controller Using Op-Amps</strong></h6><p>The integral action sums past error signals over time, eliminating steady-state error. This is implemented using an<strong>op-amp integrator</strong>.</p><p><strong>Circuit:</strong></p><ul><li>Replace the feedback resistor with a<strong>capacitor (C)</strong>.</li><li>A resistor (R) is placed in the input path.</li></ul><p><strong>Transfer Function:</strong><br>
$$
V_{out}(s) = \frac{K_i}{s} V_{in}(s)
$$</p><p>where (K_i = \frac{1}{RC}).</p><p><strong>Effect:</strong> Eliminates steady-state error but may cause slow response or instability.</p><h6 id="derivative-d-controller-using-op-amps"><strong>Derivative (D) Controller Using Op-Amps</strong></h6><p>A differentiator predicts future errors by computing the rate of change of the input signal. This is implemented using an<strong>op-amp differentiator</strong>.</p><p><strong>Circuit:</strong><br>
Use a<strong>capacitor (C) at the input</strong> and a<strong>resistor (R) in the feedback loop</strong>.</p><p><strong>Transfer Function:</strong><br>
$$
V_{out}(s) = K_d s V_{in}(s)
$$</p><p>where (K_d = R C).</p><p><strong>Effect:</strong> Improves stability and damping but is sensitive to noise.</p><h4 id="from-p-to-pi-to-pid-full-implementation"><strong>From P to PI to PID: Full Implementation</strong></h4><h6 id="pi-controller-proportional--integral"><strong>PI Controller (Proportional + Integral)</strong></h6><p>To combine<strong>P and I</strong>, sum the outputs of the proportional and integral circuits. The transfer function becomes:</p><p>$$
U(s) = K_p E(s) + \frac{K_i}{s} E(s)
$$</p><p><strong>Implementation:</strong><br>
Use a<strong>summing amplifier</strong> to combine the outputs of the P and I circuits.</p><h6 id="pid-controller-proportional--integral--derivative"><strong>PID Controller (Proportional + Integral + Derivative)</strong></h6><p>The full<strong>PID transfer function</strong>:</p><p>$$
U(s) = \left( K_p + \frac{K_i}{s} + K_d s \right) E(s)
$$</p><p><strong>Hardware Implementation Steps:</strong></p><ol><li><strong>Sum the outputs</strong> of the P, I, and D circuits using an<strong>op-amp summing amplifier</strong>.</li><li><strong>Adjust gains</strong> (K_p, K_i, K_d) by selecting appropriate resistor and capacitor values.</li><li><strong>Fine-tune</strong> the component values based on system response.</li></ol><h4 id="summary-of-pid-hardware-implementation"><strong>Summary of PID Hardware Implementation</strong></h4><table><thead><tr><th>Controller</th><th>Circuit Type</th><th>Transfer Function</th><th>Key Components</th></tr></thead><tbody><tr><td><strong>P</strong></td><td>Non-inverting amplifier</td><td>(K_p)</td><td>(R_f, R_1)</td></tr><tr><td><strong>I</strong></td><td>Integrator</td><td>(\frac{K_i}{s})</td><td>(R, C)</td></tr><tr><td><strong>D</strong></td><td>Differentiator</td><td>(K_d s)</td><td>(R, C)</td></tr><tr><td><strong>PI</strong></td><td>Summing amplifier of P and I</td><td>(K_p + \frac{K_i}{s})</td><td>Combination of P and I circuits</td></tr><tr><td><strong>PID</strong></td><td>Summing amplifier of P, I, and D</td><td>(K_p + \frac{K_i}{s} + K_d s)</td><td>Combination of P, I, and D circuits</td></tr></tbody></table><h4 id="conclusion-and-next-steps"><strong>Conclusion and Next Steps</strong></h4><p><strong>Why use Op-Amps?</strong></p><ul><li>Fast response time.</li><li>Continuous-time operation.</li><li>Lower power consumption compared to digital implementations.</li></ul><p><strong>Practical Considerations:</strong></p><ul><li>Noise filtering is required for the derivative term (D).</li><li>Proper tuning of (K_p, K_i, K_d) is needed for optimal performance.</li></ul><hr><h3 id="pi-controller-with-square-wave-input">PI Controller with Square Wave Input</h3><h4 id="circuit-diagram">Circuit Diagram</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="518" src="/images/projects/pidc/PIDC_sq_hu8258312176216106087.webp" alt="Circuit Diagram" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/PIDC_sq_hu9638792435271427506.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="setpoint">Setpoint</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="213" src="/images/projects/pidc/sq_setpoint_hu10104047699335501269.webp" alt="Setpoint" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_setpoint_hu7413604800821180335.png'"/><h4 id="output-at-differential-amplifier">Output at Differential Amplifier</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="215" src="/images/projects/pidc/sq_diff_out_hu13366964869359382432.webp" alt="Output at Diff Amp" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_diff_out_hu18019832119747124436.png'"/><h4 id="after-integral">After Integral</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="216" src="/images/projects/pidc/sq_int_hu12355741093204094324.webp" alt="After Integral" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_int_hu14279697933822695612.png'"/><h4 id="final-output">Final Output</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="217" src="/images/projects/pidc/sq_final_hu8113955749164433724.webp" alt="Final Output" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_final_hu15706104938570525425.png'"/><hr><h3 id="pid-controller-transient-analysis">PID Controller Transient Analysis</h3><h4 id="circuit">Circuit</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="497" src="/images/projects/pidc/pidc_full_hu6796135543531041001.webp" alt="Circuit" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/pidc_full_hu3410455324003975788.png'"/><h4 id="response">Response</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="216" src="/images/projects/pidc/pidc_tran_hu9152998390288215918.webp" alt="Response" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/pidc_tran_hu4851804044525527490.png'"/>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/prosarm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/prosarm/</guid><description>&lt;![CDATA[<h2 id="pr057h371c4rmhttpsgithubcommummanajagadeeshpr057h371c4rm"><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PR057H371C4RM</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A simple prosthetic arm that utilizes servo motors to create tension in strings, replicating the function of human tendons to achieve realistic finger motion.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(2018), Implementation(Nov 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RMüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Mechanical Design, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Fusion 360, Tinkercad, Wokwi, VS Code, OpenCV, MediaPipe, Python, C++</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Mechanical model complete with updated tolerances.<br> - Finger tracking using MediaPipe is fully functional.<br> - Servo control code is operational.</td></tr><tr><td><strong>Next Steps</strong></td><td>- Analyze weight distribution.<br> - Reevaluate strength and agility for optimization.<br> - 3D print and assemble the prosthetic arm.<br> - Deploy the system on hardware.</td></tr></tbody></table><hr><h4 id="overview"><strong>Overview</strong></h4><p>PR057H371C4RM is a<strong>biomechanical prosthetic arm</strong> designed to replicate the<strong>natural movement and structure of a human hand</strong> as closely as possible. The project focuses on affordability, accessibility, and precision in design, making it a viable option for those who need a functional mechanical replacement for a lost limb.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="pr057h371c4rmhttpsgithubcommummanajagadeeshpr057h371c4rm"><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PR057H371C4RM</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A simple prosthetic arm that utilizes servo motors to create tension in strings, replicating the function of human tendons to achieve realistic finger motion.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(2018), Implementation(Nov 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RMüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Mechanical Design, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Fusion 360, Tinkercad, Wokwi, VS Code, OpenCV, MediaPipe, Python, C++</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Mechanical model complete with updated tolerances.<br> - Finger tracking using MediaPipe is fully functional.<br> - Servo control code is operational.</td></tr><tr><td><strong>Next Steps</strong></td><td>- Analyze weight distribution.<br> - Reevaluate strength and agility for optimization.<br> - 3D print and assemble the prosthetic arm.<br> - Deploy the system on hardware.</td></tr></tbody></table><hr><h4 id="overview"><strong>Overview</strong></h4><p>PR057H371C4RM is a<strong>biomechanical prosthetic arm</strong> designed to replicate the<strong>natural movement and structure of a human hand</strong> as closely as possible. The project focuses on affordability, accessibility, and precision in design, making it a viable option for those who need a functional mechanical replacement for a lost limb.</p><p>Each<strong>finger</strong> has been modeled with accurate anatomical proportions to mimic human biomechanics. The design incorporates<strong>tendons (strings), ligaments (rubber cords), and joints (pivot points)</strong> to replicate<strong>natural flexion and extension</strong>. The<strong>rubber cord system</strong> ensures the fingers return to their original position after movement, while<strong>servo motors control flexion</strong>, allowing for precise and lifelike motion.</p><p>This project has been my<strong>dream</strong>, inspired by my passion for<strong>animatronics and robotics</strong>. I discovered<em>Will Cogley&rsquo;s</em> work on YouTube, which motivated me to learn<strong>Fusion 360</strong> to model the entire hand from scratch. Due to budget constraints, I have not yet been able to fully 3D print and assemble the final prototype, but the design and simulation have been extensively tested.</p><hr><h4 id="project-inspiration--resources"><strong>Project Inspiration &amp; Resources</strong></h4><ul><li><strong>3D Printing Service:</strong><a href="https://robu.in/product/3d-printing-service/" target="_blank">Robu</a></li><li><strong>CAD Files:</strong><ul><li><a href="https://grabcad.com/library/sg90-micro-servo-9g-tower-pro-1" target="_blank">SG90 Micro Servo</a></li><li><a href="https://grabcad.com/library/arduino-uno-r3-1" target="_blank">Arduino UNO R3</a></li></ul></li><li><strong>Project Inspiration:</strong><a href="https://www.youtube.com/@WillCogley" target="_blank">Will Cogley</a></li><li><strong>Bulk Export Add-ons:</strong><a href="https://github.com/Mummanajagadeesh/Project-Archiver" target="_blank">Project-Archiver</a></li></ul><hr><h4 id="demo-videos"><strong>Demo Videos</strong></h4><h5 id="latest-prototype"><strong>Latest Prototype</strong></h5><table><thead><tr><th>Motion Study</th><th>Assembly</th></tr></thead><tbody><tr><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/mATUY7Tn4Is" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/IqjxZRdiDbM" frameborder="0" allowfullscreen=/></div></div></td></tr></tbody></table><h5 id="here-are-few-clicks">Here are few clicks</h5><p><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/F-view_hu1401584373448396367.webp" alt="Front View" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/F-view_hu10069619060956966000.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><br><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/full-arm-f_hu8238285960909339441.webp" alt="Full Arm" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/full-arm-f_hu7135783822006069172.png'"/><br><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/full-workspace-all_hu4533822951062469976.webp" alt="Full Workspace" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/full-workspace-all_hu12110544136101094587.png'"/></p><p><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/full-palm_hu15218569622499882049.webp" alt="Full Palm" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/full-palm_hu7486672459591283229.png'"/><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/finger_hu13804336961041066729.webp" alt="Finger" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/finger_hu4554102789042903001.png'"/></p><hr><h4 id="hand-anatomy--biomechanics-in-the-design"><strong>Hand Anatomy &amp; Biomechanics in the Design</strong></h4><p>The prosthetic hand is designed to closely resemble the<strong>biological structure of a human hand</strong>, including key anatomical components:</p><ol><li><p><strong>Phalanges (Finger Bones)</strong> ‚Äì Each finger consists of<strong>three segments</strong>:</p><ul><li><strong>Distal Phalanx</strong> (tip of the finger)</li><li><strong>Middle Phalanx</strong></li><li><strong>Proximal Phalanx</strong> (connects to the palm)<br>
The<strong>thumb</strong> has only two phalanges (proximal and distal).</li></ul></li><li><p><strong>Metacarpals (Palm Bones)</strong> ‚Äì The palm structure is designed to support all fingers and provide stability.</p></li><li><p><strong>Tendons (Strings/Twine)</strong> ‚Äì Artificial tendons<strong>run through the palm and wrist</strong>, connecting to servo motors in the arm.</p></li><li><p><strong>Ligaments (Rubber Cords)</strong> ‚Äì The rubber cords<strong>act like ligaments</strong>, maintaining the natural tension of the fingers.</p></li></ol><h5 id="finger-structure--naming-convention"><strong>Finger Structure &amp; Naming Convention</strong></h5><p>Each finger is labeled as follows:</p><p><strong>IX</strong> ‚Äì Index<br><strong>MX</strong> ‚Äì Middle<br><strong>RX</strong> ‚Äì Ring<br><strong>PX</strong> ‚Äì Pinky<br><strong>TX</strong> ‚Äì Thumb</p><h6 id="segment-breakdown"><strong>Segment Breakdown</strong></h6><p>Each finger consists of multiple segments:</p><ul><li><strong>IX (Index)</strong> ‚Üí I1 (Distal), I2 (Middle), I3 (Proximal)</li><li><strong>MX (Middle)</strong> ‚Üí M1 (Distal), M2 (Middle), M3 (Proximal)</li><li><strong>RX (Ring)</strong> ‚Üí R1 (Distal), R2 (Middle), R3 (Proximal)</li><li><strong>PX (Pinky)</strong> ‚Üí P1 (Distal), P2 (Middle), P3 (Proximal)</li><li><strong>TX (Thumb)</strong> ‚Üí T1 (Distal), T2 (Proximal)</li></ul><p><strong>Segment Definitions:</strong></p><ul><li><strong>Distal (1):</strong> Fingertip section</li><li><strong>Middle (2):</strong> Intermediate joint section</li><li><strong>Proximal (3):</strong> Base section connecting to the palm (except for the thumb, which has only two segments)</li></ul><hr><h4 id="finger-mechanism"><strong>Finger Mechanism</strong></h4><p>Each<strong>finger</strong> consists of<strong>three segments</strong> connected by pivot points, allowing for<strong>natural bending and extension</strong>.</p><ul><li><p><strong>Rubber Cord System:</strong></p><ul><li>A<strong>rubber cord runs twice through each finger</strong>, starting from the<strong>bottom</strong>, looping through the<strong>tip (making a U-turn)</strong>, and returning to the<strong>bottom</strong> again.</li><li>Both ends of the cord are<strong>secured at the back of the palm</strong>, ensuring controlled movement and restoring fingers to a neutral position.</li></ul></li><li><p><strong>String Control System:</strong></p><ul><li>A<strong>string runs through each finger</strong>, with a<strong>knot at the fingertip</strong> to create movement when pulled.</li><li>The<strong>strings pass through the palm, wrist, and arm</strong>, connecting to<strong>servo motors</strong> for actuation.</li></ul></li></ul><h5 id="how-it-works"><strong>How It Works</strong></h5><ol><li><strong>At rest</strong>, the rubber cords keep the fingers straight, aligning all segments.</li><li><strong>When a servo pulls a string</strong>, the corresponding finger bends.</li><li><strong>Once tension is released</strong>, the rubber cord returns the finger to its original position.</li><li><strong>Fingers can only move forward and back, preventing unnatural backward bending.</strong></li></ol><hr><h4 id="thumb-mechanism"><strong>Thumb Mechanism</strong></h4><p>The<strong>thumb</strong> requires two independent servos for realistic movement:</p><ol><li><strong>Palm Servo</strong> ‚Äì Moves the thumb<strong>up and down</strong> (abduction/adduction).</li><li><strong>Arm Servo</strong> ‚Äì Controls the<strong>folding motion</strong> (flexion/extension).</li></ol><p>This dual-motor setup allows the thumb to<strong>grip objects naturally</strong> when combined with finger movement.</p><hr><h4 id="palm--string-routing"><strong>Palm &amp; String Routing</strong></h4><ul><li><strong>Holes in the palm</strong> allow rubber cords to be secured at the back, where the fingers intersect.</li><li><strong>Channels through the palm</strong> guide the control strings from the fingertips through the wrist to the servos in the arm.</li></ul><hr><h4 id="servo-control--electronics"><strong>Servo Control &amp; Electronics</strong></h4><p>The system is powered by<strong>six SG90 servo motors</strong> controlled using an<strong>Arduino or similar microcontroller</strong>. The design allows for expansion with<strong>sensor-based or AI-driven control</strong>.</p><h5 id="simulation-links"><strong>Simulation Links</strong></h5><ul><li><p><strong>Tinkercad Circuit Simulation:</strong><a href="https://www.tinkercad.com/things/4HJGXiv97LI-servo-flex-mimic-hand" target="_blank">View Here</a></p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="560" src="/images/projects/prosarm/tinkercad_hu7485008671565594993.webp" alt="Tinkercad Model" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/tinkercad_hu987314142999971428.png'"/></li><li><p><strong>Wokwi Simulation:</strong><a href="https://wokwi.com/projects/376202815270324225" target="_blank">View Here</a></p></li></ul><hr><h4 id="future-work--goals"><strong>Future Work &amp; Goals</strong></h4><p>‚úÖ<strong>Improve Mechanical &amp; Electronic Design</strong> (70% Complete)<br>
‚úÖ<strong>Prototype &amp; Testing Phases</strong> (20% Complete)<br>
üî≤<strong>Enhance User Control via Muscle Signals (BCI) or Computer Vision (MediaPipe for Hand Tracking)</strong></p><h5 id="next-steps"><strong>Next Steps</strong></h5><ul><li><strong>Brain-Computer Interface (BCI):</strong> Connect the prosthetic arm to human muscles using electromyography (EMG) sensors.</li><li><strong>Computer Vision Integration:</strong> Use<strong>MediaPipe hand tracking</strong> to detect hand gestures and translate them into servo motor commands.</li><li><strong>Further Refinements in Mechanical Design &amp; 3D Printing.</strong></li></ul><p>This project is constantly evolving, and I welcome feedback, collaboration, and new ideas! üöÄ</p><hr>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/rubec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/rubec/</guid><description>&lt;![CDATA[<h2 id="ru83c-rubiks-cube-solving-robothttpsgithubcommummanajagadeeshru83c"><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83C: Rubik&rsquo;s Cube Solving Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>RU83C</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Rubik&rsquo;s Cube-solving robot using Kociemba algorithm, featuring computer vision for state detection, mechanical design for cube manipulation, and electronics for execution.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(July 2023), Implementation(Aug 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83Cüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Algorithms, Programming, Game Dev</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Unity3D, Python, C#, VS Code, OpenCV, Fusion 360, ArduinoIDE</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Unity3D implementation is done.<br> - Mechanical Design is started in Fusion 360<br> - CV part code is ready, color ranges yet to be tuned</td></tr><tr><td><strong>Next Steps</strong></td><td>- CV (Computer Vision): Responsible for recognizing the scrambled state of the cube via a camera.<br> - Mechanical Design: Focused on the creation of the holder and gripping mechanisms to manipulate the cube.<br> - Electronics: Controls and coordinates the robot‚Äôs movements based on the computed solution.</td></tr></tbody></table><hr><h4 id="overview">Overview</h4><p>RU83C is a Rubik&rsquo;s Cube-solving robot that leverages computer vision (CV), mechanical design, and electronics to solve a scrambled Rubik&rsquo;s Cube using the Kociemba algorithm. The robot features a camera that captures the current state of the scrambled cube, processes the image using CV, and calculates the solution. A mechanical holder grips the cube securely, and the robot executes the necessary moves to solve it.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="ru83c-rubiks-cube-solving-robothttpsgithubcommummanajagadeeshru83c"><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83C: Rubik&rsquo;s Cube Solving Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>RU83C</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Rubik&rsquo;s Cube-solving robot using Kociemba algorithm, featuring computer vision for state detection, mechanical design for cube manipulation, and electronics for execution.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(July 2023), Implementation(Aug 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83Cüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Algorithms, Programming, Game Dev</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Unity3D, Python, C#, VS Code, OpenCV, Fusion 360, ArduinoIDE</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Unity3D implementation is done.<br> - Mechanical Design is started in Fusion 360<br> - CV part code is ready, color ranges yet to be tuned</td></tr><tr><td><strong>Next Steps</strong></td><td>- CV (Computer Vision): Responsible for recognizing the scrambled state of the cube via a camera.<br> - Mechanical Design: Focused on the creation of the holder and gripping mechanisms to manipulate the cube.<br> - Electronics: Controls and coordinates the robot‚Äôs movements based on the computed solution.</td></tr></tbody></table><hr><h4 id="overview">Overview</h4><p>RU83C is a Rubik&rsquo;s Cube-solving robot that leverages computer vision (CV), mechanical design, and electronics to solve a scrambled Rubik&rsquo;s Cube using the Kociemba algorithm. The robot features a camera that captures the current state of the scrambled cube, processes the image using CV, and calculates the solution. A mechanical holder grips the cube securely, and the robot executes the necessary moves to solve it.</p><h4 id="features">Features</h4><p><strong>Computer Vision</strong>: A camera-based system to detect the current state of the Rubik&rsquo;s Cube, using image processing techniques to translate the visual input into a digital cube representation.</p><p><strong>Mechanical Design</strong>: A custom-built holder with an efficient gripping system to securely hold and rotate the cube while executing the solution.</p><p><strong>Kociemba Algorithm</strong>: The Kociemba algorithm is employed to calculate the optimal solution for the scrambled state.</p><p><strong>Electronics</strong>: The system uses electronics to control the motors and mechanical components, translating the calculated moves into physical actions.</p><h4 id="structure">Structure</h4><p>The project is divided into several key parts:</p><ol><li><p>CV (Computer Vision): Responsible for recognizing the scrambled state of the cube via a camera.</p></li><li><p>Mechanical Design: Focused on the creation of the holder and gripping mechanisms to manipulate the cube.</p></li><li><p>Algorithm: Implementation of the Kociemba algorithm to calculate the solution to any scrambled state.</p></li><li><p>Electronics: Controls and coordinates the robot‚Äôs movements based on the computed solution.</p></li></ol><h4 id="base-version">Base Version</h4><p>A base version of this project was previously developed in simulation, where users could manually or automatically scramble a virtual cube in Unity. The solution for the scrambled cube was calculated and displayed in the virtual environment. This was an intermediate step, and the current version represents the full hardware implementation of the Rubik&rsquo;s Cube-solving robot.</p><p>BASE VERSION:<a href="https://github.com/Mummanajagadeesh/V-RU81K5CU83" target="_blank">here</a> &ndash;implemented in simulation using Unity3D(C#)</p><h2 id="base-version-1">BASE VERSION</h2><h3 id="v-ru81k5cu83---virtual-rubiks-cube-using-kociemba-solverhttpsgithubcommummanajagadeeshv-ru81k5cu83"><a href="https://github.com/Mummanajagadeesh/V-RU81K5CU83" target="_blank">V-RU81K5CU83 - Virtual Rubik&rsquo;s Cube Using Kociemba Solver</a></h3><p>A virtual Rubik&rsquo;s Cube implemented using the<strong>Kociemba algorithm</strong> for solving scrambled states. This project offers an interactive 3D simulation of a Rubik&rsquo;s Cube that you can scramble, manipulate manually, and solve. The solution is computed using the Kociemba two-phase algorithm, widely known for its efficiency in solving Rubik&rsquo;s cubes with minimal moves.</p><p>Deployment: This project is deployed using a WebGL server with Node.js alongside GitHub Pages for hosting the live demo.</p><p><strong>INSPIRATION:</strong><a href="https://www.megalomobile.com/" target="_blank">@Megalomobile</a></p><p><strong><a href="https://mummanajagadeesh.github.io/v-cube-host/" target="_blank">Click here for the Live Demo</a> |<a href="https://v-cube-host.vercel.app/" target="_blank">Vercel</a></strong></p><h4 id="features-1">Features</h4><ul><li><strong>Interactive 3D Cube</strong>: Manipulate the cube by dragging and rotating different layers in 3D space.</li><li><strong>Scramble &amp; Solve</strong>: Automatically scramble the cube or solve any configuration using the Kociemba algorithm.</li><li><strong>Unity/Blender Simulation</strong>: Visual simulations and demos showcasing the solution steps.</li></ul><h4 id="demo-videos">Demo Videos</h4><table><thead><tr><th>Unity 3D Demo</th><th>Blender Solution Demo</th></tr></thead><tbody><tr><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/L4s2YYyi-70" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/pQN5wu2dtTQ" frameborder="0" allowfullscreen=/></div></div></td></tr></tbody></table><h4 id="project-overview">Project Overview</h4><p>This project leverages the pre-existing<strong>Kociemba two-phase algorithm</strong> for Rubik&rsquo;s Cube solving, and our main contribution has been the seamless integration of this algorithm into a Unity-based simulation. The role of the solver is crucial, as it computes the solution when a scrambled cube is presented.</p><p>We designed the system to fetch cube states directly from the user interface, where users can scramble or manipulate the cube. Upon clicking the &ldquo;Solve&rdquo; button, the Kociemba algorithm works under the hood to generate an optimal solution, which is then passed to the Unity engine. The Unity environment simulates this solution visually, step by step, allowing users to see the cube&rsquo;s transformation in real-time.</p><p>The<strong>Blender solution demo</strong> featured here is purely a visual mockup, simulating how the cube might appear when following a solved sequence. It serves as a demonstration for visual feedback but has no direct involvement in the solving process or algorithm implementation. This is an intermediate step showcasing the solution process and will be further integrated into Unity for enhanced user interaction.</p><h2 id="kociembas-algorithm-for-solving-a-rubiks-cube"><strong>Kociemba‚Äôs Algorithm for Solving a Rubik‚Äôs Cube</strong></h2><p>Kociemba‚Äôs Algorithm is a two-phase algorithm used to efficiently solve a 3√ó3 Rubik‚Äôs Cube in a minimal number of moves. It is an advanced method that improves upon simpler approaches, such as layer-by-layer (LBL) solving, by reducing the number of moves required to solve the cube.</p><p>Kociemba‚Äôs Algorithm is often used in optimal cube solvers, and it serves as the basis for algorithms like Herbert Kociemba‚Äôs Cube Explorer and the well-known<strong>Two-Phase Algorithm</strong>.</p><hr><h4 id="overview-of-the-algorithm"><strong>Overview of the Algorithm</strong></h4><p>The algorithm consists of two main phases:</p><ol><li><strong>Phase 1</strong>: Reducing the cube to a subset of solvable states known as the<strong>&ldquo;G1 group&rdquo;</strong>.</li><li><strong>Phase 2</strong>: Solving the cube optimally from this subset.</li></ol><p>By breaking the problem into these two phases, Kociemba‚Äôs Algorithm achieves solutions that typically require around 20 moves (or fewer), which is significantly shorter than beginner methods.</p><hr><h4 id="mathematical-background"><strong>Mathematical Background</strong></h4><p>The algorithm relies on<strong>group theory</strong>, particularly the concept of<strong>cosets</strong> and<strong>group reductions</strong>. In simple terms, it works by reducing the number of legal states the cube can be in while maintaining solvability.</p><p>The Rubik‚Äôs Cube has a<strong>state space</strong> of<strong>43,252,003,274,489,856,000 (43 quintillion) possible arrangements</strong>. Finding an optimal solution in this space is extremely complex, but by using the concept of<strong>group reduction</strong>, the problem is split into two more manageable parts.</p><hr><h4 id="phase-1-reduction-to-g1-group"><strong>PHASE 1: Reduction to G1 Group</strong></h4><p>In this phase, the cube is transformed into a<strong>restricted subset</strong> of states where:</p><ul><li>All edge orientations are correct (edges are in the correct flipped orientation).</li><li>All corner orientations are correct.</li><li>The positioning of the U/D (Up/Down) face edges falls into a specific allowed pattern.</li></ul><p>This phase<strong>does not solve</strong> the cube completely but simplifies it to a structured form that is easier to solve in the second phase.</p><h6 id="mathematical-properties-of-g1-group"><strong>Mathematical Properties of G1 Group</strong></h6><p>The group G1 is a subset of all possible cube states that satisfies the following conditions:</p><ol><li><strong>Edge Orientation is Solved</strong>: Each edge must be in its correct orientation.</li><li><strong>Corner Orientation is Solved</strong>: Each corner must be in its correct orientation.</li><li><strong>UD-Slice Edges Must Stay in the UD-Slice</strong>: The four edges belonging to the U (Up) and D (Down) face centers must remain within that slice.</li></ol><p>The key insight is that reducing the cube to this state significantly reduces the number of possible positions, making the final solving phase much easier.</p><h6 id="how-this-phase-works"><strong>How This Phase Works</strong></h6><ul><li>Kociemba‚Äôs algorithm uses a<strong>pruning table</strong> that precomputes the minimum number of moves required to reach the G1 state from any given configuration.</li><li>Using<strong>bidirectional search</strong>, the algorithm efficiently finds the shortest path to reach G1.</li><li>Typically, this phase takes<strong>at most 12 moves</strong>.</li></ul><hr><h4 id="phase-2-solving-the-cube-from-g1"><strong>PHASE 2: Solving the Cube from G1</strong></h4><p>Once the cube is in the<strong>G1 subset</strong>, the next step is to solve it completely while maintaining the constraints of G1.</p><h6 id="mathematical-properties-of-phase-2"><strong>Mathematical Properties of Phase 2</strong></h6><p>In this phase, we solve the cube while ensuring:</p><ol><li><strong>The E-Slice (Middle Layer Edges) is Correct</strong>: The four middle layer edges must be correctly positioned.</li><li><strong>Corner Permutation is Correct</strong>: The corners must be arranged correctly.</li><li><strong>Edge Permutation is Correct</strong>: All edges must be positioned correctly.</li></ol><p>At this point, the cube is already simplified, so a<strong>brute-force or optimized search</strong> (using a<strong>pruning table</strong>) is performed to find the shortest solution sequence.</p><ul><li>This phase usually takes around<strong>10 moves</strong> in most cases.</li><li>Since the cube is already in a reduced state,<strong>only a limited number of moves are needed</strong> to reach the solved state.</li></ul><hr><h4 id="key-techniques-used-in-kociembas-algorithm"><strong>Key Techniques Used in Kociemba‚Äôs Algorithm</strong></h4><h6 id="pruning-tables"><strong>Pruning Tables</strong></h6><ul><li>The algorithm precomputes<strong>lookup tables</strong> that store the shortest paths for solving different cube states.</li><li>These tables help the algorithm efficiently determine the best next move without unnecessary computations.</li></ul><h6 id="heuristic-search"><strong>Heuristic Search</strong></h6><ul><li>Kociemba‚Äôs Algorithm uses<em><em>A</em> search</em>* (or similar algorithms) to minimize the number of moves required to reach a solved state.</li><li>It evaluates different move sequences and picks the shortest one.</li></ul><h6 id="group-theory-based-reduction"><strong>Group Theory-Based Reduction</strong></h6><ul><li>The algorithm does not directly solve the cube but instead<strong>reduces it</strong> step by step to smaller solvable subsets.</li><li>By using<strong>cosets</strong> and<strong>subgroups</strong>, the problem is broken down into manageable parts.</li></ul><h6 id="move-pruning--bidirectional-search"><strong>Move Pruning &amp; Bidirectional Search</strong></h6><ul><li>The algorithm avoids unnecessary moves by pruning branches that lead to longer solutions.</li><li>It uses<strong>bidirectional search</strong> (searching both forward and backward) to quickly find the optimal solution.</li></ul><hr><h4 id="why-is-kociembas-algorithm-efficient"><strong>Why is Kociemba‚Äôs Algorithm Efficient?</strong></h4><p><strong>It significantly reduces the search space</strong>: Instead of searching through 43 quintillion possible states, it first reduces the cube to G1, making the search much easier.<strong>It finds near-optimal solutions</strong>: While not always the absolute shortest solution, Kociemba‚Äôs Algorithm typically finds solutions within 20 moves, close to the<strong>God‚Äôs Number</strong> (20 moves).<strong>It is practical for human and computer solvers</strong>: Many advanced cube solvers and speedcubing programs use this approach for efficient solving.</p><hr><h4 id="comparison-to-other-solving-methods"><strong>Comparison to Other Solving Methods</strong></h4><table><thead><tr><th>Algorithm</th><th>Average Move Count</th><th>Approach</th></tr></thead><tbody><tr><td>Layer-by-Layer (Beginner Method)</td><td>100+ moves</td><td>Step-by-step solving</td></tr><tr><td>CFOP (Fridrich Method)</td><td>50-60 moves</td><td>Speedcubing method</td></tr><tr><td>Kociemba‚Äôs Algorithm</td><td>~20 moves</td><td>Two-phase optimal solving</td></tr><tr><td>Thistlethwaite‚Äôs Algorithm</td><td>40-50 moves</td><td>Four-phase group theory approach</td></tr><tr><td>God‚Äôs Algorithm</td><td>20 moves (optimal)</td><td>Brute-force minimum solution</td></tr></tbody></table><p>Kociemba‚Äôs Algorithm is<strong>not always optimal</strong>, but it is extremely<strong>efficient</strong> and can be computed<strong>very quickly</strong> compared to brute-force approaches.</p><hr><h4 id="applications-of-kociembas-algorithm"><strong>Applications of Kociemba‚Äôs Algorithm</strong></h4><ul><li><strong>Speedcubing</strong>: Used in optimal cube-solving software.</li><li><strong>Computer Solvers</strong>: Implemented in AI-based solvers and robotic Rubik‚Äôs Cube solvers.</li><li><strong>Mathematical Research</strong>: Used to study<strong>group theory and combinatorial optimization</strong>.</li><li><strong>God‚Äôs Number Research</strong>: Helps find efficient solutions near the<strong>20-move optimal bound</strong>.</li></ul><hr><h4 id="controls">Controls</h4><ul><li><strong>Right Click + Drag</strong>: Rotate the entire cube in 3D space.</li><li><strong>Left Click + Drag on Layers</strong>: Rotate specific layers of the Rubik&rsquo;s Cube.</li></ul><h4 id="buttons">Buttons</h4><ul><li><strong>SCRAMBLE</strong>: Randomly scrambles the Rubik&rsquo;s Cube.</li><li><strong>SOLVE</strong>: Solves the scrambled cube using the Kociemba solver. (Note: Initial solve may take some time to compute.)</li></ul><h5 style="text-align: center;">Layout</h5><img title="" loading="lazy" decoding="async" class="img  " width="1201" height="802" src="/images/projects/rubec/layout_hu14405346715368994746.webp" alt="Unity Layout" onerror="this.onerror='null';this.src='\/images\/projects\/rubec\/layout_hu8176224447079097799.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="installation--setup">Installation &amp; Setup</h4><p>To run the project locally, follow these steps:</p><ol><li><p>Clone the repository:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/v-rubiks-cube.git</span></span><span style="display:flex;"><span>cd v-rubiks-cube</span></span></code></pre></div></li><li><p>Open the project in your preferred IDE or deploy it on a web hosting service.</p></li><li><p>To modify or extend the project, ensure you have:</p><ul><li>A working knowledge of 3D engines such as Unity or Blender.</li><li>Familiarity with the Kociemba algorithm and basic Rubik‚Äôs Cube concepts.</li></ul></li></ol><h4 id="how-the-solver-works">How the Solver Works</h4><p>This project uses the<strong>Kociemba two-phase algorithm</strong>, which is an optimized approach for solving the Rubik&rsquo;s Cube in under 20 moves. The first phase reduces the problem to a manageable subset of configurations, and the second phase finds an optimal solution from that subset.</p><h4 id="performance-notes">Performance Notes</h4><ul><li>The first time you run the solver, it may take longer due to the initial calculation of move tables.</li><li>Subsequent solves will be faster as the tables are cached.</li></ul><h4 id="future-goals">Future Goals</h4><p>We have exciting plans for the future of this project:</p><ul><li><strong>Hardware Integration</strong>: The next step is to bring this solution into the physical world. Using computer vision (CV) techniques, we aim to read the Rubik&rsquo;s Cube faces via a camera and translate the detected state into a solvable format.</li><li><strong>3D Design</strong>: We are currently working on the 3D design of the hardware, which is under construction. This will involve a mechanism where gripper-like structures hold and manipulate the cube for solving.</li><li><strong>Optimization</strong>: Another goal is to reduce the time required for solving, making the process as fast and efficient as possible.</li><li><strong>Physical Cube Solving</strong>: Ultimately, the project will be able to solve a real Rubik&rsquo;s Cube using robotic structures that simulate the virtual environment.</li></ul><p>We are open to contributions from anyone interested in participating in this exciting journey. If you&rsquo;d like to help us push the project forward, feel free to reach out!</p><p>Enjoy solving the cube! üé≤</p>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/shopping-cart-bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/shopping-cart-bot/</guid><description>&lt;![CDATA[<h2 id="shopping-cart-bothttpsgithubcommummanajagadeeshshopping-cart-bot-rig"><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Bot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Shopping Cart Bot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The Shopping Cart Bot is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</td></tr><tr><td><strong>Start</strong></td><td>30 Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Botüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, ROS2, GeminiAPI, PyQt, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><p>The<strong>Shopping Cart Bot</strong> is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="shopping-cart-bothttpsgithubcommummanajagadeeshshopping-cart-bot-rig"><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Bot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Shopping Cart Bot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The Shopping Cart Bot is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</td></tr><tr><td><strong>Start</strong></td><td>30 Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Botüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, ROS2, GeminiAPI, PyQt, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><p>The<strong>Shopping Cart Bot</strong> is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</p><h4 id="problem-statement">Problem Statement</h4><p>The project aims to address the following challenges:</p><ul><li><strong>Object Detection and Classification:</strong> Implement computer vision techniques to identify and categorize products.</li><li><strong>Person Following:</strong> Develop a system that enables the bot to follow a shopper autonomously.</li><li><strong>Barcode and Label Recognition:</strong> Use image processing and OCR to extract information from labels and barcodes.</li><li><strong>Discount Application and Payment System:</strong> Calculate the final bill with category-wise discounts and generate a QR code for payment.</li></ul><h4 id="motivation">Motivation</h4><p>This project was developed as part of the<strong>Round 3 induction project for my college robotics club</strong>. The objective was to explore the integration of robotics and computer vision in real-world applications, enhancing the retail shopping experience.</p><h4 id="hardware-design">Hardware Design</h4><ul><li><strong>Frame:</strong> Designed using aluminum extrusion in<strong>Fusion 360</strong>.</li><li><strong>Wheels:</strong> Mecanum wheels were chosen due to the<strong>restricted motion in malls</strong> (tight spaces, high foot traffic, and the need for omnidirectional movement).</li></ul><h4 id="person-following-implementation">Person Following Implementation</h4><h5 id="simulation-environment"><strong>Simulation Environment</strong></h5><ul><li>Implemented in<strong>Webots</strong> simulation.</li><li>The world was divided into separate tracks for the person to walk and collect items.</li><li>The cart was equipped with a<strong>camera and GPS</strong>, mounted on a mecanum-wheeled base.</li><li>The person was equipped with a<strong>GPS sensor</strong> embedded in their body slot, transmitting signals via a dedicated channel.</li><li>The bot‚Äôs camera continuously monitored the person, following them wherever they moved.</li><li>The<strong>GPS signal</strong> served as an additional reference for tracking the person‚Äôs location.</li></ul><video width="1000" autoplay= loop= muted= controls= class="embed-responsive "><source src="/images/projects/scbot/pedfollowbot.mp4" type="video/mp4"/>
Your browser does not support the video tag.</video><h5 id="unimplemented-features-due-to-time-constraints"><strong>Unimplemented Features Due to Time Constraints</strong></h5><ul><li>Handling the scenario where the person moves out of the camera frame, using GPS as a fallback.</li><li>Detecting when the bot is stuck without any input stimulus.</li></ul><h4 id="object-detection-and-classification">Object Detection and Classification</h4><ul><li><p><strong>YOLOv5 Model:</strong> Trained using a<strong>Roboflow dataset</strong> to detect and categorize shopping items.</p></li><li><p><strong>Label Detection Pipeline:</strong></p><ul><li>Convert the image from<strong>RGB to grayscale</strong>.</li><li>Apply<strong>Canny edge detection</strong>.</li><li>Identify the<strong>largest contour</strong> and create a<strong>bounding box</strong> around the label.</li><li>Extract the<strong>bounded region</strong> from the original image.</li><li>Perform<strong>OCR (Optical Character Recognition)</strong> using an API to extract text.</li><li>Utilize<strong>Gemini API</strong> for text correction and cost retrieval.</li></ul><video width="1000" autoplay= loop= muted= controls= class="embed-responsive "><source src="/images/projects/scbot/shpbotrecog.mp4" type="video/mp4"/>
Your browser does not support the video tag.</video></li></ul><blockquote><p>Implemented a ROS2 node to enable communication between mecanum base motors and code via a UDP server.</p></blockquote><h4 id="payment-system">Payment System</h4><ul><li><p>The total cost is calculated based on item quantity, category-wise discounts, and final pricing.</p></li><li><p>A<strong>UPI URL</strong> is used to generate a<strong>QR code</strong>.</p></li><li><p>Scanning the QR code prompts the user to pay the exact calculated amount.</p><video width="500" autoplay= loop= muted= controls= class="embed-responsive "><source src="/images/projects/scbot/upiqr.mp4" type="video/mp4"/>
Your browser does not support the video tag.</video></li></ul><p>The<strong>Shopping Cart Bot</strong> successfully integrates multiple robotics and computer vision techniques to automate the shopping experience. Despite some unimplemented features due to time constraints, the project demonstrates a proof of concept for autonomous retail assistance.</p><hr><h5 id="future-improvements">Future Improvements</h5><ul><li>Implement fallback mechanisms for lost person tracking.</li><li>Enhance navigation strategies for obstacle avoidance.</li><li>Develop a fully integrated hardware prototype for real-world testing.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/tlcv/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/tlcv/</guid><description>&lt;![CDATA[<h2 id="traffic-light-controller-httpsgithubcommummanajagadeeshtrafficlightcontroller-verilog"><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TRAFFIC LIGHT CONTROLLER üö¶</a></h2><table><thead><tr><th><strong>Name</strong></th><th>TLC using Verilog</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of Traffic Light Controller</td></tr><tr><td><strong>Start</strong></td><td>05 Apr 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TLCVüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><blockquote><p>The original version, which utilizes FSM, is currently on hold. Here is the base version, which does not use FSM and instead relies directly on Boolean logic expressions. Below is the explanation for the base version.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="traffic-light-controller-httpsgithubcommummanajagadeeshtrafficlightcontroller-verilog"><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TRAFFIC LIGHT CONTROLLER üö¶</a></h2><table><thead><tr><th><strong>Name</strong></th><th>TLC using Verilog</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of Traffic Light Controller</td></tr><tr><td><strong>Start</strong></td><td>05 Apr 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TLCVüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><blockquote><p>The original version, which utilizes FSM, is currently on hold. Here is the base version, which does not use FSM and instead relies directly on Boolean logic expressions. Below is the explanation for the base version.</p></blockquote><h2 id="base-version">BASE VERSION</h2><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="737" src="/images/projects/tlc/lane-picture_hu4146720103007524920.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/lane-picture_hu7639973906903205819.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><p>Consider the problem of controlling a traffic light at the intersection of two equally busy streets, A Street and B Street. Our traffic light controller takes two inputs ‚Äì CarA (which is high when there is a car just before the intersection on A Street ‚Äì in either direction), and CarB (which is high when there is a car just before the intersection on B street). The controller needs to generate six outputs ‚Äì RedA, YellowA, GreenA, RedB, YellowB, and GreenB ‚Äì which drive the respective traffic lights for A Street and B Street. In the figure above, CarA will be high, since there is a car (the rectangle) on A Street, and CarB will be low, since there is no car on B Street. Also in the Figure RedA is high since A Street has a red light, and GreenB is high since B Street has a green light. All other outputs are low. We can think of the traffic light controller as a black box that takes two inputs (and a clock) and generates six outputs as shown below.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="689" src="/images/projects/tlc/tlcblock_hu9325997977067735153.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/tlcblock_hu904393213427707066.png'"/><ol><li>When the light is green on A Street and a car is waiting on B Street, give A Street a yellow light for one clock cycle and then give A Street a red light and B Street a green light for at least two cycles.</li><li>When the light is green on A Street and there is no car on B Street, leave the light green on A Street.</li><li>When the is green on B Street (and we‚Äôve finished the two cycles from step 1) and a car is waiting on A Street, give B Street a yellow light for one clock cycle and then give B Street a red light and A Street a green light for at least two cycles.</li><li>When the light is green on B Street and there is no car on A Street, leave the light green on B Street.</li><li>When you press the reset switch, after no more than six cycles, the light should be initially green on A Street and red on B Street and the controller should be ready for operation.</li></ol><h4 id="working">WORKING:</h4><p>We can translate these five rules into the following state diagram. For clarity, we omit the transitions that take all states to state AG2 (A Green 2nd cycle) when reset is true.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="817" src="/images/projects/tlc/state-diagram_hu7133944902976557533.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/state-diagram_hu3948849623443658779.png'"/><p>Each circle in the state diagram represents a state. The name of the state is in the circle and the state of the six output lines (in the order listed above) is shown below that state. The transitions between the states are labeled with the signals that make these transitions occur. Most of the edges have no label which indicates that the transition always occurs (unless reset is asserted).
When our finite-state machine (FSM) is in state AG2, A Street has a green light and B Street has a red light. The transition from AG2 back to itself indicates that as long as there is no car on B Street we keep the A Street light green. The transition to AY (for A Yellow) indicates that if there is a car on B Street, we make the A Street light yellow on the next cycle. AY always transitions to BG1 (for B Green 1st cycle) where the A Street light becomes red and the B Street light becomes green. BG1 always transitions to BG2 where the FSM waits for a car on A Street before sequencing through BY and AG1 back to AG2.</p><p>From this state diagram we can write the following state table:</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/tlc/state-table_hu3048702135184146678.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/state-table_hu15547272149258596845.png'"/><table><tr><th>State</th><th colspan="3">Inputs</th><th>nextState</th><th colspan="2">Outputs</th></tr><tr><th/><th>reset</th><th>CarA</th><th>CarB</th><th/><th>A lights</th><th>B lights</th></tr><tr><td>*</td><td>1</td><td>*</td><td>*</td><td>AG2</td><td>Green</td><td>Red</td></tr><tr><td>AG2</td><td>0</td><td>0</td><td>*</td><td>AG2</td><td>Green</td><td>Red</td></tr><tr><td>AG2</td><td>0</td><td>*</td><td>1</td><td>AY</td><td>Green</td><td>Red</td></tr><tr><td>AY</td><td>0</td><td>*</td><td>*</td><td>BG1</td><td>Yellow</td><td>Red</td></tr><tr><td>BG1</td><td>0</td><td>*</td><td>*</td><td>BG2</td><td>Red</td><td>Green</td></tr><tr><td>BG2</td><td>0</td><td>*</td><td>1</td><td>BY</td><td>Red</td><td>Green</td></tr><tr><td>BG2</td><td>0</td><td>0</td><td>1</td><td>BY</td><td>Red</td><td>Green</td></tr><tr><td>BY</td><td>0</td><td>*</td><td>*</td><td>AG1</td><td>Red</td><td>Yellow</td></tr><tr><td>AG1</td><td>0</td><td>*</td><td>*</td><td>AG2</td><td>Green</td><td>Red</td></tr></table><h4 id="circuit-diagram-implemented">CIRCUIT DIAGRAM IMPLEMENTED:</h4><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="372" src="/images/projects/tlc/circuit-diagram_hu4954760165853522568.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/circuit-diagram_hu2516666750173183316.jpg'"/><h5 id="inputs-for-d-flip-flops">INPUTS FOR D FLIP FLOPS:</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span>D1<span style="color:#f92672">=</span> Q3<span style="color:#f92672">+</span> (<span style="color:#f92672">~</span>CB)<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(Q1)<span style="color:#f92672">+</span> reset</span></span><span style="display:flex;"><span>D2<span style="color:#f92672">=</span> Q1<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>CB</span></span><span style="display:flex;"><span>D3<span style="color:#f92672">=</span> Q5</span></span><span style="display:flex;"><span>D4<span style="color:#f92672">=</span> (Q6<span style="color:#f92672">+</span> (Q4<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(<span style="color:#f92672">~</span>CA))<span style="color:#f92672">+</span> reset</span></span><span style="display:flex;"><span>D5<span style="color:#f92672">=</span> Q4<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>CB</span></span><span style="display:flex;"><span>D6<span style="color:#f92672">=</span> Q2</span></span></code></pre></div><h5 id="overall-ouputs">OVERALL OUPUTS:</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span>RedA<span style="color:#f92672">=</span> Q5<span style="color:#f92672">+</span> reset<span style="color:#f92672">+</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(Q4<span style="color:#f92672">+</span> Q6)</span></span><span style="display:flex;"><span>YellowA<span style="color:#f92672">=</span> Q2<span style="color:#960050;background-color:#1e0010">‚Ä¢</span> (<span style="color:#f92672">~</span>reset)</span></span><span style="display:flex;"><span>GreenA<span style="color:#f92672">=</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(Q1<span style="color:#f92672">+</span> Q3)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>RedB<span style="color:#f92672">=</span> Q2<span style="color:#f92672">+</span> reset<span style="color:#f92672">+</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(Q1<span style="color:#f92672">+</span> Q3)</span></span><span style="display:flex;"><span>YellowB<span style="color:#f92672">=</span> Q5<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(<span style="color:#f92672">~</span>reset)</span></span><span style="display:flex;"><span>GreenB<span style="color:#f92672">=</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">‚Ä¢</span>(Q5<span style="color:#f92672">+</span> Q6)</span></span></code></pre></div><h4 id="design-code">DESIGN CODE:</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">module</span> TLC(clk, reset, carA, carB, lightsA, lightsB) ;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span> clk ;<span style="color:#75715e">// clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span> reset ;<span style="color:#75715e">// reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span> carA ;<span style="color:#75715e">// a car is waiting on A Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span> carB ;<span style="color:#75715e">// a car is waiting on B Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span>[<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsA ;<span style="color:#75715e">// Red, Yellow, Green lights for A Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span>[<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsB ;<span style="color:#75715e">// Red, Yellow, Green lights for B Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> ag2, ay, ag1, bg2, by, bg1 ;<span style="color:#75715e">// state bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> nag2, nay, nag1, nbg2, nby, nbg1 ;<span style="color:#75715e">// next state bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span>[<span style="color:#ae81ff">5</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state ;<span style="color:#75715e">// for observation only</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> state<span style="color:#f92672">=</span> {ag2, ay, ag1, bg2, by, bg1} ;</span></span><span style="display:flex;"><span><span style="color:#75715e">// state equations</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span></span></span><span style="display:flex;"><span>nag2<span style="color:#f92672">=</span> ag1<span style="color:#f92672">|</span>(ag2<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>carB)<span style="color:#f92672">|</span>reset ,<span style="color:#75715e">// D1 = Q3 + (~CB)‚Ä¢(Q1) + reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nay<span style="color:#f92672">=</span> ag2<span style="color:#f92672">&amp;</span> carB ,<span style="color:#75715e">// D2 = Q1‚Ä¢CB</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nbg1<span style="color:#f92672">=</span> ay ,<span style="color:#75715e">// D3 = Q5</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nbg2<span style="color:#f92672">=</span> (bg1<span style="color:#f92672">|</span>(bg2<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>carA))<span style="color:#f92672">&amp;~</span>reset,<span style="color:#75715e">// D4 = (Q6 + (Q4‚Ä¢(~CA)) + reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nby<span style="color:#f92672">=</span> bg2<span style="color:#f92672">&amp;</span> carA ,<span style="color:#75715e">// D5 = Q4‚Ä¢CA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nag1<span style="color:#f92672">=</span> by ;<span style="color:#75715e">// D6 = Q2</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// flip flops</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)</span></span><span style="display:flex;"><span>{ag2, ay, ag1, bg2, by, bg1}<span style="color:#f92672">=</span> {nag2, nay, nag1, nbg2, nby, nbg1} ;</span></span><span style="display:flex;"><span><span style="color:#75715e">// output equations</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span></span></span><span style="display:flex;"><span>lightsA[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">=</span> by<span style="color:#f92672">|</span> lightsB[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">|</span> reset ,<span style="color:#75715e">// red</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsA[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">=</span> ay<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset ,<span style="color:#75715e">// yellow</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsA[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">=</span> (ag1<span style="color:#f92672">|</span> ag2)<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset,<span style="color:#75715e">// green</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsB[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">=</span> ay<span style="color:#f92672">|</span> lightsA[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">|</span> reset,<span style="color:#75715e">// red</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsB[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">=</span> by<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset,<span style="color:#75715e">// yellow</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsB[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">=</span> (bg1<span style="color:#f92672">|</span> bg2)<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset ;<span style="color:#75715e">// green</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h4 id="testbench-code">TESTBENCH CODE:</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ns</span></span><span style="display:flex;"><span><span style="color:#66d9ef">module</span> TLC_tb;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Parameters</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">parameter</span> CLK_PERIOD<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>;<span style="color:#75715e">// Clock period in ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Inputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> clk;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> reset;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> carA;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> carB;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Outputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsA;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsB;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">5</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the TLC module</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>TLC uut (</span></span><span style="display:flex;"><span> .clk(clk),</span></span><span style="display:flex;"><span> .reset(reset),</span></span><span style="display:flex;"><span> .carA(carA),</span></span><span style="display:flex;"><span> .carB(carB),</span></span><span style="display:flex;"><span> .lightsA(lightsA),</span></span><span style="display:flex;"><span> .lightsB(lightsB)</span></span><span style="display:flex;"><span>);</span></span><span style="display:flex;"><span><span style="color:#75715e">// Connect the state output of TLC to state wire in testbench</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> state<span style="color:#f92672">=</span> uut.state;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Clock generation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> #((CLK_PERIOD)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>) clk<span style="color:#f92672">=</span><span style="color:#f92672">~</span>clk;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Initial values</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">initial</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> clk<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span> #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// Wait for a few cycles</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// Test cases</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 1</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 2</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 3</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 4</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 5</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 6</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 7</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 8</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 9</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 10</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 11</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 12</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> $finish;<span style="color:#75715e">// End simulation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Display outputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> $display(<span style="color:#e6db74">"reset = %b carA = %b carB = %b : lightsA = %b lightsB = %b state =%b%b%b%b%b%b"</span>,</span></span><span style="display:flex;"><span> reset, carA, carB, lightsA, lightsB, state[<span style="color:#ae81ff">5</span>], state[<span style="color:#ae81ff">4</span>], state[<span style="color:#ae81ff">3</span>], state[<span style="color:#ae81ff">2</span>], state[<span style="color:#ae81ff">1</span>], state[<span style="color:#ae81ff">0</span>]);</span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="code-explanation">CODE EXPLANATION:</h5><h6 id="design-code-1">DESIGN CODE:</h6><p>Functionality:
The Verilog module TLC defines a traffic light controller with inputs for clock (clk), reset (reset), and car presence on streets A and B (carA, carB). It generates outputs (lightsA, lightsB) to control the traffic lights and uses registers (ag2, ay, ag1, bg2, by, bg1) and wires (nag2, nay, nag1, nbg2, nby, nbg1) to manage internal state transitions and next state calculations (state).</p><p>Operation:
The module updates its internal state (ag2, ay, ag1, bg2, by, bg1) based on clock edges and input conditions, calculates next state bits (nag2, nay, nag1, nbg2, nby, nbg1) using state equations, and determines the output state of traffic lights (lightsA, lightsB) based on the current state and reset conditions using output equations.</p><h6 id="testbench-code-1">TESTBENCH CODE:</h6><p>Purpose:
This Verilog testbench (TLC_tb) is designed to simulate the behavior of the TLC module by providing input stimuli (clk, reset, carA, carB) and observing the corresponding outputs (lightsA, lightsB) and internal state (state). It helps validate the functionality and correctness of the TLC module under various test cases.</p><p>Operation:
The testbench initializes the inputs, generates a clock signal (clk), applies test cases with different input combinations, and displays the resulting outputs and state changes using $display. The testbench also connects the state wire to observe the internal state of the TLC module during simulation.</p><h4 id="ouput">OUPUT:</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">100000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">100000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">010</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000010</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span></code></pre></div><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="112" src="/images/projects/tlc/waveform_hu14643348579372039064.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/waveform_hu2771881731006117160.png'"/><p><strong>Output Columns Explanation</strong>:</p><ol><li><code>reset</code>: Indicates whether the controller is in reset mode (<code>1</code> = reset active,<code>0</code> = normal operation).</li><li><code>carA</code>: Indicates whether there is a car waiting on Street A (<code>1</code> = car present,<code>0</code> = no car).</li><li><code>carB</code>: Indicates whether there is a car waiting on Street B (<code>1</code> = car present,<code>0</code> = no car).</li><li><code>lightsA</code> and<code>lightsB</code>: 3-bit outputs indicating the light status for streets A and B, respectively:<ul><li><code>100</code>: Red</li><li><code>010</code>: Yellow</li><li><code>001</code>: Green</li></ul></li><li><code>state</code>: 6-bit internal state of the controller, where each bit corresponds to one of the states (<code>ag2</code>,<code>ay</code>,<code>ag1</code>,<code>bg2</code>,<code>by</code>,<code>bg1</code>).</li></ol><p><strong>Key Observations from the Output</strong>:</p><ol><li><p><strong>Reset Behavior</strong>:</p><ul><li>When<code>reset = 1</code>, the controller initializes to the default state (<code>AG2</code>), where Street A has a green light (<code>lightsA = 100</code>) and Street B has a red light (<code>lightsB = 100</code>).</li></ul></li><li><p><strong>State Transitions</strong>:</p><ul><li><strong>Initial State</strong> (<code>AG2</code>): Street A has a green light, and Street B has a red light. The controller remains in this state as long as<code>carB = 0</code>.</li><li><strong>Transition to AY</strong>: When<code>carB = 1</code>, the controller transitions to<code>AY</code> (A Yellow), giving Street A a yellow light while preparing to switch to B Street.</li><li><strong>Transition to BG1/BG2</strong>: After<code>AY</code>, the controller transitions to<code>BG1</code> and<code>BG2</code>, giving Street B the green light and Street A the red light. The controller waits for at least two cycles on Street B (<code>BG1</code> and<code>BG2</code>) before checking for<code>carA</code>.</li><li><strong>Transition to BY</strong>: When<code>carA = 1</code>, the controller transitions to<code>BY</code> (B Yellow), switching from Street B back to Street A.</li></ul></li><li><p><strong>Input-Driven State Changes</strong>:</p><ul><li>The controller responds dynamically to<code>carA</code> and<code>carB</code>, switching states and light colors based on the presence of cars. For example:<ul><li><code>carA = 0, carB = 1</code>: Street B gets priority (transition from<code>AG2</code> ‚Üí<code>AY</code> ‚Üí<code>BG1</code>).</li><li><code>carA = 1, carB = 0</code>: Street A gets priority (transition from<code>BG2</code> ‚Üí<code>BY</code> ‚Üí<code>AG1</code>).</li></ul></li></ul></li><li><p><strong>Output Consistency</strong>:</p><ul><li>The outputs (<code>lightsA</code> and<code>lightsB</code>) match the expected light status for each state in the state table:<ul><li><code>lightsA = 100</code> (Red for A) corresponds to<code>BG1</code>/<code>BG2</code> states.</li><li><code>lightsB = 001</code> (Green for B) corresponds to<code>BG1</code>/<code>BG2</code> states.</li><li><code>lightsA = 001</code> (Green for A) corresponds to<code>AG1</code>/<code>AG2</code> states.</li></ul></li></ul></li></ol><p><strong>Waveform Analysis</strong>:
The waveform visualizes the same transitions observed in the output table. Key points:</p><ul><li>The state bits change in accordance with the state transitions defined by the FSM.</li><li>The<code>lightsA</code> and<code>lightsB</code> signals follow the expected traffic light rules.</li><li><code>Reset</code> enforces the initial state (<code>AG2</code>), confirming the correctness of initialization.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/wallfollow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/wallfollow/</guid><description>&lt;![CDATA[<h2 id="wall-follower-robot-simulationhttpsgithubcommummanajagadeeshwall-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">Wall Follower Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Wall Follower Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The wall-following robot travels along walls in a maze. It uses basic sensors to detect the distance to the wall and adjusts its path to stay close. The robot explores all possible paths to find its destination without relying on algorithms, simply following the wall as it moves</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">WFRüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project contains the<strong>Wall Follower Robot</strong> simulation, which utilizes an<strong>e-puck</strong> model to navigate a maze using proximity sensors. The robot follows walls and explores paths randomly until it reaches its destination. This implementation does not use pathfinding algorithms or PID controllers; instead, it relies on basic logic to avoid obstacles and move along the walls.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="wall-follower-robot-simulationhttpsgithubcommummanajagadeeshwall-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">Wall Follower Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Wall Follower Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The wall-following robot travels along walls in a maze. It uses basic sensors to detect the distance to the wall and adjusts its path to stay close. The robot explores all possible paths to find its destination without relying on algorithms, simply following the wall as it moves</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">WFRüîó</a></td></tr><tr><td><strong>Type</strong></td><td>SOLO</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project contains the<strong>Wall Follower Robot</strong> simulation, which utilizes an<strong>e-puck</strong> model to navigate a maze using proximity sensors. The robot follows walls and explores paths randomly until it reaches its destination. This implementation does not use pathfinding algorithms or PID controllers; instead, it relies on basic logic to avoid obstacles and move along the walls.</p><h4 id="maze">Maze</h4><p>The robot navigates through a structured maze, as shown below:</p><p>[<img src="https://github.com/Mummanajagadeesh/wall-follower-robot/blob/main/maze_reference.jpg" alt="Maze">]</p><h4 id="demo-video">Demo Video</h4><p>Click the image below to watch a demo of the simulation in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/aZBT_TVdFZY" frameborder="0" allowfullscreen=/></div></div><h4 id="how-it-works">How It Works</h4><h5 id="robot-design">Robot Design</h5><p>The<strong>e-puck</strong> robot is equipped with multiple proximity sensors positioned around its body. These sensors allow the robot to detect nearby walls and navigate through the maze by adjusting its movement. The robot makes decisions based on sensor readings to move forward or turn as needed.</p><ul><li><strong>Proximity Sensors</strong>: The robot has eight proximity sensors (<code>ps0</code> to<code>ps7</code>) that detect walls and obstacles on all sides.</li><li><strong>Motors</strong>: Independent left and right wheel motors control the robot‚Äôs movement, enabling it to move forward, turn in place, or steer based on sensor inputs.</li></ul><h5 id="maze-exploration-strategy">Maze Exploration Strategy</h5><ul><li>The robot starts at a predefined position within the maze.</li><li>It explores the maze by following walls and avoiding obstacles until it reaches the target area.</li><li>The robot does not attempt to find the shortest path but instead explores all possible routes until it reaches the destination.</li></ul><h5 id="control-logic">Control Logic</h5><ul><li>The robot detects walls using its proximity sensors and adjusts its movement accordingly.</li><li>If there is a wall directly in front, it turns right.</li><li>If there is a wall on the left but none in front, it moves forward along the wall.</li><li>If no walls are detected, the robot makes a right turn.</li><li>The robot stops when it reaches the designated target region within the maze.</li></ul><hr><h4 id="installation-and-usage">Installation and Usage</h4><h5 id="requirements">Requirements</h5><ul><li><strong>Webots</strong>: Install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure Python is installed to run the robot controller.</li></ul><h5 id="steps-to-run">Steps to Run</h5><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/wall-follower-robot-w.git</span></span><span style="display:flex;"><span>cd wall-follower-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>wall_follower_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation and observe the robot navigating through the maze.</li></ol><hr><h4 id="future-enhancements">Future Enhancements</h4><ul><li><strong>Optimized Pathfinding</strong>: Implementing algorithms like DFS, BFS, or A* to find the shortest path.</li><li><strong>PID Controller</strong>: Enhancing the robot‚Äôs movement with a PID controller for smoother turns and wall-following.</li><li><strong>Increased Maze Complexity</strong>: Introducing more challenging mazes with multiple solutions and dead-ends.</li></ul><hr>
]]></content:encoded></item><item><title>:~$ whoami</title><link>https://mummanajagadeesh.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/</guid><description>&lt;![CDATA[<h5 id="jagadeesh97">/jagadeesh97</h5><p>I‚Äôm from Visakhapatnam, Andhra Pradesh, and currently a sophomore at NIT Calicut, studying Electronics and Communication Engineering.</p><p>I‚Äôm passionate about robotics and AI, and I enjoy working with electronics, microcontrollers, and everything that goes into building robots. I‚Äôm always open to learning and working on projects‚Äîwhether in digital and analog circuits, robotic simulations, or hands-on robotics at my college‚Äôs Mechatronics Lab.</p>]]></description><content:encoded>&lt;![CDATA[<h5 id="jagadeesh97">/jagadeesh97</h5><p>I‚Äôm from Visakhapatnam, Andhra Pradesh, and currently a sophomore at NIT Calicut, studying Electronics and Communication Engineering.</p><p>I‚Äôm passionate about robotics and AI, and I enjoy working with electronics, microcontrollers, and everything that goes into building robots. I‚Äôm always open to learning and working on projects‚Äîwhether in digital and analog circuits, robotic simulations, or hands-on robotics at my college‚Äôs Mechatronics Lab.</p><p>Most of my projects come from curiosity rather than prior experience, making each one a learning process. You can check them out on my projects page or on GitHub. If you&rsquo;re interested in similar work or just want to discuss tech, feel free to reach out!</p><h5 id="my-blog">My Blog</h5><p>This year, I started a blog as a space to document my projects in detail. It serves as both a personal reference and a way to share insights with others who might be working on similar things.</p><p>Here, I keep track of my progress, challenges, and the technical details behind what I build. Whether it&rsquo;s breaking down a complex problem, showcasing a project, or just reflecting on the process, this blog helps me organize my thoughts while contributing to a shared pool of knowledge.</p><p>By documenting my work, I not only reinforce my own learning but also create something that might be useful for others. If you&rsquo;re interested in similar projects, you might find something helpful here too!</p>
]]></content:encoded></item><item><title>:~$ whoami</title><link>https://mummanajagadeesh.github.io/about_1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about_1/</guid><description>&lt;![CDATA[<h5 id="jagadeesh97">/jagadeesh97</h5><p>I&rsquo;m from Visakhapatnam, Andhra Pradesh, and currently a sophomore at NIT Calicut, studying Electronics and Communication Engineering.</p><p>I&rsquo;m passionate about robotics and AI, constantly exploring electronics, microcontrollers, and everything that makes robots tick. I love collaborating with like-minded individuals, especially in robotics, AI, and embedded systems.</p>]]></description><content:encoded>&lt;![CDATA[<h5 id="jagadeesh97">/jagadeesh97</h5><p>I&rsquo;m from Visakhapatnam, Andhra Pradesh, and currently a sophomore at NIT Calicut, studying Electronics and Communication Engineering.</p><p>I&rsquo;m passionate about robotics and AI, constantly exploring electronics, microcontrollers, and everything that makes robots tick. I love collaborating with like-minded individuals, especially in robotics, AI, and embedded systems.</p><p>I work on all kinds of projects‚Äîdriven purely by curiosity, independent of prior experience. My interests span digital and analog circuits, robotic simulations, and real-world robotics projects (including those in my college&rsquo;s Mechatronics Lab).
More on my<a href="../projects">projects</a> page :)</p><p>Check out my projects on GitHub, and if you&rsquo;re interested in collaborating or just chatting about tech, feel free to reach out!</p><h5 id="my-blog">My Blog</h5><p>This year, I launched a blog to share project updates, breakdowns of how they work, and personal insights. I also include tips that might help others working on similar projects.</p><p>Here, I document my experiences, challenges, and the exciting things I build. Whether it&rsquo;s explaining a tricky concept, showcasing a hands-on project, or just sharing something cool in tech, my goal is to keep it relatable and useful.</p><p>I believe the best way to grow is by sharing knowledge‚Äîso stick around, there&rsquo;s always something new to learn here!</p>
]]></content:encoded></item><item><title>Contact</title><link>https://mummanajagadeesh.github.io/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/contact/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item><item><title>Other Achievements [Secondary School]</title><link>https://mummanajagadeesh.github.io/about/achievements/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/achievements/</guid><description>&lt;![CDATA[<h6 id="karate-black-belt-dan--holder"><strong>Karate Black Belt [DAN ‚Ö†] Holder</strong></h6><ul><li>Achieved a<strong>Black Belt (DAN ‚Ö†)</strong></li></ul><h6 id="gold-medalist--district-level-karate-tournament"><strong>Gold Medalist ‚Äì District Level Karate Tournament</strong></h6><ul><li>Secured<strong>1st place</strong> in a district-level Karate tournament, showcasing excellence in martial arts</li></ul><h6 id="sports-kid-of-the-year-2018-19"><strong>Sports Kid of the Year [2018-19]</strong></h6><ul><li>Honored as the<strong>Sports Kid of the Year</strong> for outstanding performance across multiple sports disciplines</li></ul><h6 id="creative-kid-of-the-year-2018-19--nominee"><strong>Creative Kid of the Year [2018-19] ‚Äì Nominee</strong></h6><ul><li>Recognized for creativity and innovation in various fields, making it to the final nominee list</li></ul><h6 id="gold-medalist--essay-writing"><strong>Gold Medalist ‚Äì Essay Writing</strong></h6><ul><li>Won<strong>1st place</strong> in an<strong>essay writing competition</strong>, demonstrating strong writing and analytical skills</li></ul><h6 id="silver-medalist--vedic-math"><strong>Silver Medalist ‚Äì Vedic Math</strong></h6><ul><li>Achieved<strong>2nd place</strong> in a<strong>Vedic Mathematics competition</strong>, excelling in mental arithmetic and problem-solving</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="karate-black-belt-dan--holder"><strong>Karate Black Belt [DAN ‚Ö†] Holder</strong></h6><ul><li>Achieved a<strong>Black Belt (DAN ‚Ö†)</strong></li></ul><h6 id="gold-medalist--district-level-karate-tournament"><strong>Gold Medalist ‚Äì District Level Karate Tournament</strong></h6><ul><li>Secured<strong>1st place</strong> in a district-level Karate tournament, showcasing excellence in martial arts</li></ul><h6 id="sports-kid-of-the-year-2018-19"><strong>Sports Kid of the Year [2018-19]</strong></h6><ul><li>Honored as the<strong>Sports Kid of the Year</strong> for outstanding performance across multiple sports disciplines</li></ul><h6 id="creative-kid-of-the-year-2018-19--nominee"><strong>Creative Kid of the Year [2018-19] ‚Äì Nominee</strong></h6><ul><li>Recognized for creativity and innovation in various fields, making it to the final nominee list</li></ul><h6 id="gold-medalist--essay-writing"><strong>Gold Medalist ‚Äì Essay Writing</strong></h6><ul><li>Won<strong>1st place</strong> in an<strong>essay writing competition</strong>, demonstrating strong writing and analytical skills</li></ul><h6 id="silver-medalist--vedic-math"><strong>Silver Medalist ‚Äì Vedic Math</strong></h6><ul><li>Achieved<strong>2nd place</strong> in a<strong>Vedic Mathematics competition</strong>, excelling in mental arithmetic and problem-solving</li></ul>
]]></content:encoded></item><item><title>Other Achievements [Secondary School]</title><link>https://mummanajagadeesh.github.io/about/courses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/courses/</guid><description>&lt;![CDATA[<h6 id="edx"><strong>EDX</strong></h6><ul><li><strong>CS50P 2022</strong> Harvard | Jan'24</li><li><strong>CS50X 2024</strong> Harvard | Sep'24</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="edx"><strong>EDX</strong></h6><ul><li><strong>CS50P 2022</strong> Harvard | Jan'24</li><li><strong>CS50X 2024</strong> Harvard | Sep'24</li></ul>
]]></content:encoded></item><item><title>Personal Accomplishments and Competitions</title><link>https://mummanajagadeesh.github.io/about/accomplishments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/accomplishments/</guid><description>&lt;![CDATA[<h6 id="circuit-conclave--nitc-tathva--1st-place-team-oct-24"><strong>Circuit Conclave | NITC Tathva ‚Äì 1st Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Secured<strong>1st place</strong> in<strong>Circuit Conclave</strong>, an electronics design competition focused on innovative circuit solutions</li></ul><h6 id="disarmamine--nitc-tathva--3rd-place-team-oct-24"><strong>Disarmamine | NITC Tathva ‚Äì 3rd Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Achieved<strong>3rd place</strong> in<strong>Disarmamine</strong>, showcasing expertise in electronics and problem-solving</li></ul><h6 id="robotrix24--nit-surathkal--1st-round-qualified-solo-dec-24"><strong>Robotrix'24 | NIT Surathkal ‚Äì 1st Round Qualified</strong><em>(Solo, Dec &lsquo;24)</em></h6><ul><li>Successfully cleared<strong>Round 1</strong> of<strong>Robotrix'24</strong> and participated in the<strong>24-hour robotics simulation hackathon (Round 2)</strong> using<strong>CoppeliaSim</strong></li></ul><h6 id="isro-iroc-u-robotics-challenge--round-1-qualified-team-jan-25"><strong>ISRO IROC-U Robotics Challenge ‚Äì Round 1 Qualified</strong><em>(Team, Jan &lsquo;25)</em></h6><ul><li>Designing an<strong>autonomous drone</strong> for operations on the<strong>Martian surface</strong> as part of the<strong>ISRO IROC-U Robotics Challenge</strong></li><li>Successfully<strong>qualified for Round 1</strong>;<strong>Round 2 is ongoing</strong></li></ul><h6 id="digital-design-circuit-challenge--nit-trichy--1st-round-qualified-team-feb-25"><strong>Digital Design Circuit Challenge | NIT Trichy ‚Äì 1st Round Qualified</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Cleared<strong>Round 1</strong> in<strong>Digital Design Circuit Challenge</strong>, a challenge focusing on digital electronics and logic design</li></ul><h6 id="flipkart-grid-robotics-challenge--1st-round-qualified-solo-aug-24"><strong>Flipkart GRID Robotics Challenge ‚Äì 1st Round Qualified</strong><em>(Solo, Aug &lsquo;24)</em></h6><ul><li>Advanced past<strong>Round 1</strong> in the<strong>Flipkart GRID Robotics Challenge</strong>, an AI-driven robotics competition</li></ul><hr><hr><h6 id="aws-aiml-nano-degree-scholarship--udacity--amazon-mar-24"><strong>AWS AI/ML Nano Degree Scholarship | Udacity &amp; Amazon</strong><em>(Mar &lsquo;24)</em></h6><ul><li>Completed<strong>two AI/ML courses</strong> and cleared<strong>evaluation test</strong> as part of the<strong>AWS AI/ML Scholarship Program</strong></li><li>Trained an<strong>autonomous racing car</strong> using<strong>reinforcement learning (RL)</strong> to compete against a lap, making it to the<strong>leaderboards</strong></li><li>Became<strong>eligible to apply</strong> for the<strong>AWS AI/ML Nano Degree Scholarship</strong></li></ul><hr><hr><h6 id="c2s-chip-to-startup-digital-hackathon--participated-team-feb-25"><strong>C2S Chip to Startup &ldquo;Digital Hackathon&rdquo; ‚Äì Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Competed in<strong>Digital Hackathon</strong> with a focus on<strong>digital electronics</strong>, organized under<strong>C2S Chip to Startup</strong> by<strong>Ministry of Electronics &amp; Information Technology (MeitY)</strong></li></ul><h6 id="bajaj-auto-ohm-challenge--participated-team-feb-25"><strong>Bajaj Auto Ohm Challenge ‚Äì Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Took part in the<strong>Bajaj Auto Ohm Challenge</strong>, an engineering competition emphasizing<strong>electrical and electronic innovations</strong></li></ul><h6 id="bharatiya-antariksh-hackathon-bah-24--participated-team-july-24"><strong>Bharatiya Antariksh Hackathon (BAH &lsquo;24) ‚Äì Participated</strong><em>(Team, July &lsquo;24)</em></h6><ul><li>Developed an<strong>AI/ML-based system</strong> for<strong>automatic detection of craters and boulders</strong> from<strong>Orbiter High-Resolution Camera (OHRC) images</strong></li><li>Focused on<strong>enhancing planetary exploration</strong> through automation and computer vision</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="circuit-conclave--nitc-tathva--1st-place-team-oct-24"><strong>Circuit Conclave | NITC Tathva ‚Äì 1st Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Secured<strong>1st place</strong> in<strong>Circuit Conclave</strong>, an electronics design competition focused on innovative circuit solutions</li></ul><h6 id="disarmamine--nitc-tathva--3rd-place-team-oct-24"><strong>Disarmamine | NITC Tathva ‚Äì 3rd Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Achieved<strong>3rd place</strong> in<strong>Disarmamine</strong>, showcasing expertise in electronics and problem-solving</li></ul><h6 id="robotrix24--nit-surathkal--1st-round-qualified-solo-dec-24"><strong>Robotrix'24 | NIT Surathkal ‚Äì 1st Round Qualified</strong><em>(Solo, Dec &lsquo;24)</em></h6><ul><li>Successfully cleared<strong>Round 1</strong> of<strong>Robotrix'24</strong> and participated in the<strong>24-hour robotics simulation hackathon (Round 2)</strong> using<strong>CoppeliaSim</strong></li></ul><h6 id="isro-iroc-u-robotics-challenge--round-1-qualified-team-jan-25"><strong>ISRO IROC-U Robotics Challenge ‚Äì Round 1 Qualified</strong><em>(Team, Jan &lsquo;25)</em></h6><ul><li>Designing an<strong>autonomous drone</strong> for operations on the<strong>Martian surface</strong> as part of the<strong>ISRO IROC-U Robotics Challenge</strong></li><li>Successfully<strong>qualified for Round 1</strong>;<strong>Round 2 is ongoing</strong></li></ul><h6 id="digital-design-circuit-challenge--nit-trichy--1st-round-qualified-team-feb-25"><strong>Digital Design Circuit Challenge | NIT Trichy ‚Äì 1st Round Qualified</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Cleared<strong>Round 1</strong> in<strong>Digital Design Circuit Challenge</strong>, a challenge focusing on digital electronics and logic design</li></ul><h6 id="flipkart-grid-robotics-challenge--1st-round-qualified-solo-aug-24"><strong>Flipkart GRID Robotics Challenge ‚Äì 1st Round Qualified</strong><em>(Solo, Aug &lsquo;24)</em></h6><ul><li>Advanced past<strong>Round 1</strong> in the<strong>Flipkart GRID Robotics Challenge</strong>, an AI-driven robotics competition</li></ul><hr><hr><h6 id="aws-aiml-nano-degree-scholarship--udacity--amazon-mar-24"><strong>AWS AI/ML Nano Degree Scholarship | Udacity &amp; Amazon</strong><em>(Mar &lsquo;24)</em></h6><ul><li>Completed<strong>two AI/ML courses</strong> and cleared<strong>evaluation test</strong> as part of the<strong>AWS AI/ML Scholarship Program</strong></li><li>Trained an<strong>autonomous racing car</strong> using<strong>reinforcement learning (RL)</strong> to compete against a lap, making it to the<strong>leaderboards</strong></li><li>Became<strong>eligible to apply</strong> for the<strong>AWS AI/ML Nano Degree Scholarship</strong></li></ul><hr><hr><h6 id="c2s-chip-to-startup-digital-hackathon--participated-team-feb-25"><strong>C2S Chip to Startup &ldquo;Digital Hackathon&rdquo; ‚Äì Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Competed in<strong>Digital Hackathon</strong> with a focus on<strong>digital electronics</strong>, organized under<strong>C2S Chip to Startup</strong> by<strong>Ministry of Electronics &amp; Information Technology (MeitY)</strong></li></ul><h6 id="bajaj-auto-ohm-challenge--participated-team-feb-25"><strong>Bajaj Auto Ohm Challenge ‚Äì Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Took part in the<strong>Bajaj Auto Ohm Challenge</strong>, an engineering competition emphasizing<strong>electrical and electronic innovations</strong></li></ul><h6 id="bharatiya-antariksh-hackathon-bah-24--participated-team-july-24"><strong>Bharatiya Antariksh Hackathon (BAH &lsquo;24) ‚Äì Participated</strong><em>(Team, July &lsquo;24)</em></h6><ul><li>Developed an<strong>AI/ML-based system</strong> for<strong>automatic detection of craters and boulders</strong> from<strong>Orbiter High-Resolution Camera (OHRC) images</strong></li><li>Focused on<strong>enhancing planetary exploration</strong> through automation and computer vision</li></ul>
]]></content:encoded></item><item><title>Positions Held</title><link>https://mummanajagadeesh.github.io/about/positions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/positions/</guid><description>&lt;![CDATA[<h6 id="ecea-executive-assistant--event-management--techincal-team--oct24---present"><strong>ECEA Executive Assistant | Event Management | Techincal Team , Oct'24 - Present</strong></h6><ul><li><strong>ECEA - Electronics And Communication Engineering Association @ NITC</strong></li><li>Arranged workshops and seminars in ECE department blocks</li><li>Helped freshers connect with faculty</li><li>Built relations with alumni and learned a lot during the process</li></ul><h6 id="tathva24-junior-executive--tech-conclave-committee-oct24"><strong>Tathva'24 Junior Executive | Tech Conclave Committee, Oct'24</strong></h6><ul><li><strong>Tathva - South India&rsquo;s Largest Techno-management Fest @ NITC</strong></li><li>Reaching out to YouTubers and influencers via cold emails to invite them to the event; successfully secured one guest attendee</li><li>Contributed to content writing and poster ideation for event promotion</li><li>Managed crowd coordination and logistics on the event day</li></ul><h6 id="rignitc-tech-member--nov24---forever"><strong>RIGNITC Tech Member | Nov'24 - Forever</strong></h6><ul><li><strong>RIGNITC - Robotics Interest Group @ NITC</strong></li><li>Worked on several real-world interdisciplinary projects as part of robotics enthusiast teams</li><li>Assisted in explaining lab visits to students from various schools</li><li>Helped in organizing Origo'25, the annual tech workshop by team RIG</li></ul><hr><hr><h6 id="scientific-volunteer--sep23"><strong>Scientific Volunteer | Sep'23</strong></h6><ul><li><strong>Institute for Plasma Research (IPR √ó NITC) | Plasma Exhibition</strong></li><li>Trained to explain plasma science, its applications, and nuclear fusion to exhibition visitors</li><li>Demonstrated and provided in-depth explanations of<strong>5+ plasma exhibits</strong> to over<strong>100 students</strong>, detailing their functions and construction while addressing queries</li></ul><h6 id="asteroid-hunter--may-24---aug-24"><strong>Asteroid Hunter | May &lsquo;24 - Aug &lsquo;24</strong></h6><ul><li><strong>International Astronomical Search Collaboration (IASC √ó NASA √ó Saptarshi India | STAC)</strong></li><li>Trained in using<strong>Astrometrica</strong> software to analyze astronomical data for asteroid detection</li><li>Identified<strong>10+ potential asteroid</strong> signatures as part of<strong>NASA‚Äôs Citizen Science</strong> initiative</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="ecea-executive-assistant--event-management--techincal-team--oct24---present"><strong>ECEA Executive Assistant | Event Management | Techincal Team , Oct'24 - Present</strong></h6><ul><li><strong>ECEA - Electronics And Communication Engineering Association @ NITC</strong></li><li>Arranged workshops and seminars in ECE department blocks</li><li>Helped freshers connect with faculty</li><li>Built relations with alumni and learned a lot during the process</li></ul><h6 id="tathva24-junior-executive--tech-conclave-committee-oct24"><strong>Tathva'24 Junior Executive | Tech Conclave Committee, Oct'24</strong></h6><ul><li><strong>Tathva - South India&rsquo;s Largest Techno-management Fest @ NITC</strong></li><li>Reaching out to YouTubers and influencers via cold emails to invite them to the event; successfully secured one guest attendee</li><li>Contributed to content writing and poster ideation for event promotion</li><li>Managed crowd coordination and logistics on the event day</li></ul><h6 id="rignitc-tech-member--nov24---forever"><strong>RIGNITC Tech Member | Nov'24 - Forever</strong></h6><ul><li><strong>RIGNITC - Robotics Interest Group @ NITC</strong></li><li>Worked on several real-world interdisciplinary projects as part of robotics enthusiast teams</li><li>Assisted in explaining lab visits to students from various schools</li><li>Helped in organizing Origo'25, the annual tech workshop by team RIG</li></ul><hr><hr><h6 id="scientific-volunteer--sep23"><strong>Scientific Volunteer | Sep'23</strong></h6><ul><li><strong>Institute for Plasma Research (IPR √ó NITC) | Plasma Exhibition</strong></li><li>Trained to explain plasma science, its applications, and nuclear fusion to exhibition visitors</li><li>Demonstrated and provided in-depth explanations of<strong>5+ plasma exhibits</strong> to over<strong>100 students</strong>, detailing their functions and construction while addressing queries</li></ul><h6 id="asteroid-hunter--may-24---aug-24"><strong>Asteroid Hunter | May &lsquo;24 - Aug &lsquo;24</strong></h6><ul><li><strong>International Astronomical Search Collaboration (IASC √ó NASA √ó Saptarshi India | STAC)</strong></li><li>Trained in using<strong>Astrometrica</strong> software to analyze astronomical data for asteroid detection</li><li>Identified<strong>10+ potential asteroid</strong> signatures as part of<strong>NASA‚Äôs Citizen Science</strong> initiative</li></ul>
]]></content:encoded></item><item><title>Privacy Policy</title><link>https://mummanajagadeesh.github.io/privacy-policy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/privacy-policy/</guid><description>&lt;![CDATA[<h3 id="wait-why-is-this-even-here">Wait‚Ä¶ Why Is This Even Here?</h3><p>No one will ever notice this privacy policy. I don‚Äôt even know why it exists. Except for someone like me. And now you. If you‚Äôre reading this, you found it. Regret it now.</p>]]></description><content:encoded>&lt;![CDATA[<h3 id="wait-why-is-this-even-here">Wait‚Ä¶ Why Is This Even Here?</h3><p>No one will ever notice this privacy policy. I don‚Äôt even know why it exists. Except for someone like me. And now you. If you‚Äôre reading this, you found it. Regret it now.</p><h4 id="we-need-your-email-to-send-you-stuff">We Need Your Email (To Send You Stuff)</h4><p>By signing up, you give me your email. But don‚Äôt forget‚Äîonce I have it, it could be used in ways you might not expect. Stay subscribed if you want to stay in the loop.</p><h4 id="your-info-is-safe-but-not-forever">Your Info Is Safe (But Not Forever)</h4><p>I keep your email secure, but once it‚Äôs in my system, it might end up in unexpected places. I won‚Äôt share it with random strangers, but I‚Äôll use it to its full potential.</p><h4 id="cookies-are-just-for-the-website-and-we-track-you">Cookies Are Just for the Website (And We Track You)</h4><p>I use cookies to improve your experience on my site, and yes, I track you. It‚Äôs not personal‚Äîit‚Äôs business. You‚Äôre here, and I‚Äôm going to make sure you keep coming back.</p><h4 id="unsubscribe-yeah-you-can-but-seriously">Unsubscribe? Yeah, You Can. But Seriously‚Ä¶</h4><p>You can unsubscribe at any time, but you‚Äôll miss out on all the cool stuff. Think hard before you hit that button. Once you‚Äôre gone, you might not come back.</p><h4 id="accidentally-ended-up-here">Accidentally Ended Up Here?</h4><p>If you clicked on this by mistake, too bad. You‚Äôre in it now. Might as well stick around and see what happens.</p><h4 id="questions-better-ask-quickly">Questions? Better Ask Quickly.</h4><p>Got questions? Reach out, but remember‚ÄîI don‚Äôt do apologies. I do business.</p><hr><h3 id="tldr-yes-i-sell-your-email-ids-deal-with-it">TL;DR: Yes, I Sell Your Email IDs. Deal With It.</h3><p>Here‚Äôs the hard truth about your email. When you sign up, I collect your email address to send you updates. And guess what? I might share it with others. So if you want to keep getting my emails, you better stick around.</p>
]]></content:encoded></item><item><title>Projects</title><link>https://mummanajagadeesh.github.io/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item><item><title>Scholarships Received</title><link>https://mummanajagadeesh.github.io/about/scholarships/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/scholarships/</guid><description>&lt;![CDATA[<h6 id="crec-sjet-scholarship"><strong>CREC-SJET Scholarship</strong></h6><ul><li><strong>Issued by:</strong> CREC Silver Jubilee Endowment Trust ¬∑<em>Apr 2024</em></li><li><strong>Associated with:</strong> National Institute of Technology Calicut</li><li>Awarded in recognition of academic merit and financial need, enabling me to pursue my education and overcome financial barriers.</li></ul><h6 id="reliance-foundation-scholarship"><strong>Reliance Foundation Scholarship</strong></h6><ul><li><strong>Issued by:</strong> Reliance Foundation ¬∑<em>Feb 2024</em></li><li><strong>Description:</strong> Recipient of a prestigious scholarship supporting meritorious first-year undergraduate students nationwide.</li><li><strong>Selection:</strong> Awarded on a merit-cum-means basis, with up to 5,000 scholars selected.</li><li><strong>Benefits:</strong> Besides financial aid, it also connects students to a strong alumni network.</li></ul><h6 id="fiitjee-tuition-fee-waiver"><strong>FIITJEE Tuition Fee Waiver</strong></h6><ul><li><strong>Issued by:</strong> FIITJEE ¬∑<em>Mar 2021</em></li><li><strong>Associated with:</strong> FIITJEE</li><li><strong>Award:</strong> Received 100% tuition fee waiver for excelling in the admission test</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="crec-sjet-scholarship"><strong>CREC-SJET Scholarship</strong></h6><ul><li><strong>Issued by:</strong> CREC Silver Jubilee Endowment Trust ¬∑<em>Apr 2024</em></li><li><strong>Associated with:</strong> National Institute of Technology Calicut</li><li>Awarded in recognition of academic merit and financial need, enabling me to pursue my education and overcome financial barriers.</li></ul><h6 id="reliance-foundation-scholarship"><strong>Reliance Foundation Scholarship</strong></h6><ul><li><strong>Issued by:</strong> Reliance Foundation ¬∑<em>Feb 2024</em></li><li><strong>Description:</strong> Recipient of a prestigious scholarship supporting meritorious first-year undergraduate students nationwide.</li><li><strong>Selection:</strong> Awarded on a merit-cum-means basis, with up to 5,000 scholars selected.</li><li><strong>Benefits:</strong> Besides financial aid, it also connects students to a strong alumni network.</li></ul><h6 id="fiitjee-tuition-fee-waiver"><strong>FIITJEE Tuition Fee Waiver</strong></h6><ul><li><strong>Issued by:</strong> FIITJEE ¬∑<em>Mar 2021</em></li><li><strong>Associated with:</strong> FIITJEE</li><li><strong>Award:</strong> Received 100% tuition fee waiver for excelling in the admission test</li></ul>
]]></content:encoded></item><item><title>Search Result</title><link>https://mummanajagadeesh.github.io/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/search/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item></channel></rss>