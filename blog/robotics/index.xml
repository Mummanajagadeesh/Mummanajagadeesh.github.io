<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>robotics on Jagadeesh Mummana | Portfolio</title><link>https://mummanajagadeesh.github.io/blog/robotics/</link><description>Recent content in robotics on Jagadeesh Mummana | Portfolio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 10 Jun 2025 05:30:00 +0000</lastBuildDate><atom:link href="https://mummanajagadeesh.github.io/blog/robotics/index.xml" rel="self" type="application/rss+xml"/><item><title>Sensors in Robotics: How Ultrasonic, LiDAR, and IMU Work</title><link>https://mummanajagadeesh.github.io/blog/sensors-in-robotics/</link><pubDate>Tue, 10 Jun 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/sensors-in-robotics/</guid><description>Sensors are to robots what eyes, ears, and skin are to humans—but with far fewer limits. While we rely on just five senses, robots can be equipped with many more, sensing distances, movement, vibrations, orientation, light intensity, and even chemical properties.</description></item><item><title>Debugging a Robot In Simulation Before You Burn Wires</title><link>https://mummanajagadeesh.github.io/blog/robotics-simulation-tools/</link><pubDate>Wed, 04 Jun 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/robotics-simulation-tools/</guid><description>Hardware does not come with an undo button. Once you power it on, mistakes—from reversed wiring to faulty code—can result in costly damage.</description></item><item><title>Computer Vision vs. Sensor Fusion: Who Wins the Self-Driving Car Race?</title><link>https://mummanajagadeesh.github.io/blog/cv-vs-sensor-fusion/</link><pubDate>Fri, 30 May 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/cv-vs-sensor-fusion/</guid><description>Tesla&amp;rsquo;s bold claim that “humans drive with eyes and a brain, so our cars will too” sparked one of the most polarizing debates in autonomous vehicle (AV) technology: Can vision-only systems truly compete with—or even outperform—multi-sensor fusion architectures?</description></item><item><title>ROS 2 vs ROS 1: What Changed and Why It Matters?</title><link>https://mummanajagadeesh.github.io/blog/ros1-vs-ros2/</link><pubDate>Fri, 02 May 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/ros1-vs-ros2/</guid><description>Is ROS 1 still the right choice for your next robotics project, with its well-established tools and wide community support? Or, given the growing demand for real-time performance, scalability, and modern middleware, is it finally time to make the move to ROS 2?</description></item><item><title>What is SLAM? And Why It’s the Brain of Mobile Robots</title><link>https://mummanajagadeesh.github.io/blog/what-is-slam/</link><pubDate>Sun, 20 Apr 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/what-is-slam/</guid><description>In robotics, SLAM—Simultaneous Localization and Mapping—is regarded as one of the most fundamental and complex problems. At its core, SLAM addresses a deceptively simple question: &amp;ldquo;Where am I, and what does the world around me look like?</description></item><item><title>My RosConIN'24 (+GNOME Asia Summit) Experience</title><link>https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/</link><pubDate>Fri, 17 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/</guid><description>Last year, I missed ROSCon India due to exams and, honestly, had no idea what I was missing out on. This year, though, I made it, and it turned out to be more than I ever imagined.</description></item></channel></rss>