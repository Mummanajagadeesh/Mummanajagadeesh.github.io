&lt;?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jagadeesh Mummana | Portfolio</title><link>https://mummanajagadeesh.github.io/</link><description>Jagadeesh Mummana Personal Portfolio Site</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://mummanajagadeesh.github.io/blog/communication-protocols/" rel="self" type="application/rss+xml"/><item><title>Understanding the Basics of Machine Learning</title><link>https://mummanajagadeesh.github.io/blog/understanding-the-basics-of-ml/</link><pubDate>Thu, 22 May 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/understanding-the-basics-of-ml/</guid><description>&lt;![CDATA[<p>Machine learning is something that shows up all around us today—whether we&rsquo;re aware of it or not. From personalized suggestions on YouTube and Netflix to automatic spam filtering in our inboxes, it’s quietly powering a lot of the tools we use daily.</p>]]></description><content:encoded>&lt;![CDATA[<p>Machine learning is something that shows up all around us today—whether we&rsquo;re aware of it or not. From personalized suggestions on YouTube and Netflix to automatic spam filtering in our inboxes, it’s quietly powering a lot of the tools we use daily.</p><p>If you’re just starting out and trying to figure out what machine learning actually<em>is</em>, this post is for you. I’ll try to keep things simple and honest, with no jargon or unnecessary complexity.</p><h4 id="what-is-machine-learning">What is Machine Learning?</h4><p>At its core, machine learning is about teaching computers to make decisions or predictions by learning from data, rather than following hard-coded instructions.</p><p>In traditional programming, we tell the computer exactly what to do in every situation. But for tasks like recognizing a handwritten digit or classifying whether an email is spam, it’s almost impossible to write those rules by hand.</p><p>That’s where machine learning comes in—it lets the computer<strong>learn patterns</strong> from examples instead.</p><h4 id="why-its-useful">Why It’s Useful</h4><p>There are many problems that are too complex or too fuzzy for us to define in exact rules. For example:</p><ul><li>How do you program a robot to recognize a cat in a photo?</li><li>Can you write fixed rules to understand spoken language?</li></ul><p>Rather than trying to write these rules ourselves, we let the machine figure them out by showing it many examples. The idea is: the more data it sees, the better it gets.</p><h4 id="the-ingredients">The Ingredients</h4><p>While machine learning can get quite advanced, the basic building blocks stay the same. Here are a few core ideas:</p><p><strong>Data</strong>
This is where everything begins. We usually have inputs (like images or text) and sometimes labels (like the correct digit or category). The quality and quantity of data heavily affect how well the model learns.</p><p><strong>Model</strong>
This is the actual system that tries to learn patterns from the data. Think of it as a function that maps inputs to outputs—like taking an image and predicting the digit it shows.</p><p><strong>Training</strong>
During training, the model looks at the data and tries to adjust itself to make better predictions. This involves a lot of trial and error, usually guided by math behind the scenes.</p><p><strong>Testing</strong>
After training, we check how well the model does on new data it hasn’t seen before. This helps us understand how well it might work in the real world.</p><h4 id="different-types-of-learning">Different Types of Learning</h4><p>Depending on the kind of data and problem we’re dealing with, machine learning can work in a few different ways.</p><p><strong>Supervised Learning</strong>
Here, we have both the input and the correct output (label). The model learns by comparing its predictions to the actual answers. This is used for tasks like image classification or spam detection.</p><p><strong>Unsupervised Learning</strong>
In this case, the data doesn’t come with labels. The model tries to find patterns or groupings in the data on its own. It’s useful for things like clustering customers based on behavior.</p><p><strong>Reinforcement Learning</strong>
This is a bit different. The model learns by interacting with an environment and getting feedback in the form of rewards or penalties. It&rsquo;s often used in games or robotics.</p><h4 id="a-simple-example">A Simple Example</h4><p>Let’s say we’re building a model to recognize handwritten digits.</p><ul><li>We collect thousands of images of digits (like from the MNIST dataset).</li><li>We train a model by showing it these images along with the correct digit.</li><li>Over time, it learns to recognize which patterns match which numbers.</li><li>We then test it on new images to see how well it does.</li></ul><p>No need to manually define what a “2” looks like—it learns from seeing enough examples.</p><h4 id="where-its-used">Where It’s Used</h4><p>Machine learning shows up in more places than we might expect:</p><ul><li>Email spam filters</li><li>Voice assistants like Siri or Google Assistant</li><li>Self-driving car systems</li><li>Personalized news feeds</li><li>Predicting stock prices or health conditions</li></ul><p>It’s not always perfect, but in many cases, it’s a practical and powerful tool.</p><h4 id="algorithms-you-might-hear-about">Algorithms You Might Hear About</h4><p>If you start looking into ML, you’ll come across names like:</p><ul><li>Linear Regression</li><li>Decision Trees</li><li>Neural Networks</li><li>K-Nearest Neighbors</li><li>Random Forests</li><li>Support Vector Machines</li></ul><p>Each of these is a different way to learn from data. You don’t need to memorize them right away—just knowing the names can help when you come across them later.</p><h4 id="want-to-explore-it-yourself">Want to Explore It Yourself?</h4><p>If you&rsquo;re curious to try things out, here are a few beginner-friendly ways to get started:</p><ul><li>Play with<a href="https://teachablemachine.withgoogle.com/" target="_blank">Google’s Teachable Machine</a>, where you can train simple models without writing any code.</li><li>Learn Python if you&rsquo;re new to coding—it’s the go-to language for ML.</li><li>Look into tools like<code>scikit-learn</code>, which make it easier to build and test models.</li><li>Explore beginner datasets like the Iris dataset or handwritten digits.</li></ul><p>The best way to learn is to get your hands dirty. Start small, make mistakes, and keep going.</p><h4 id="final-thoughts">Final Thoughts</h4><p>Machine learning can seem intimidating at first, especially with all the terminology and math behind it. But at the heart of it, it’s really just about using data to make better decisions.</p><p>If you’re interested in this space, there’s plenty of room to grow—step by step. You don’t need to know everything to get started. I definitely don’t. But the more you explore, the clearer things become.</p>
]]></content:encoded></item><item><title>Why RISC-V Can Be a Game Changer?</title><link>https://mummanajagadeesh.github.io/blog/why-riscv-is-better/</link><pubDate>Thu, 15 May 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/why-riscv-is-better/</guid><description>&lt;![CDATA[<p>In a world dominated by proprietary chip architectures, a quiet shift is underway. RISC-V, an open-source alternative, is redefining how we think about processor design—especially in the VLSI world.</p>]]></description><content:encoded>&lt;![CDATA[<p>In a world dominated by proprietary chip architectures, a quiet shift is underway. RISC-V, an open-source alternative, is redefining how we think about processor design—especially in the VLSI world.</p><h4 id="understanding-architecture-in-processor-design">Understanding Architecture in Processor Design</h4><p>At the heart of any computing system is the<strong>Instruction Set Architecture (ISA)</strong>. This defines the set of operations a processor can perform and how software communicates with the hardware. It’s an essential layer—one that shapes not just how processors work internally, but also how software is written and optimized.</p><p>Two of the most dominant ISAs in the current landscape are<strong>x86</strong> (used in most desktops and servers) and<strong>ARM</strong> (widely used in mobile and embedded systems). Both are proprietary: x86 is maintained by Intel and AMD under strict licensing, while ARM is owned by Arm Holdings, which licenses the ISA and IP cores to companies building chips.</p><p>This proprietary nature has shaped the semiconductor industry’s development for decades. Companies that want to build processors with these architectures must license them—an approach that can be restrictive in terms of both cost and flexibility, especially for those developing custom silicon solutions or working in academia and research.</p><h4 id="the-introduction-of-risc-v">The Introduction of RISC-V</h4><p><strong>RISC-V</strong> emerged in 2010 from the University of California, Berkeley, as the fifth iteration of a RISC (Reduced Instruction Set Computing) design project—hence the “V” in the name. It was created as an open and extensible ISA suitable for modern processor designs, intended to be used freely by academia, startups, and industry without the legal or financial constraints that come with traditional ISAs.</p><p>Unlike x86 and ARM,<strong>RISC-V is open source</strong>. The specification is maintained by the RISC-V Foundation (now RISC-V International), and anyone can implement it in silicon without paying royalties or signing restrictive agreements.</p><p>This makes RISC-V particularly relevant in the context of<strong>VLSI (Very Large Scale Integration)</strong> design, where flexibility and cost-efficiency are key. RISC-V’s modularity allows chip designers to start with a small base instruction set and add only the extensions they need, avoiding unnecessary hardware overhead and simplifying verification.</p><h4 id="risc-and-cisc-architectural-context">RISC and CISC: Architectural Context</h4><p>To understand RISC-V’s approach, it helps to compare it with traditional<strong>CISC (Complex Instruction Set Computing)</strong> and<strong>RISC</strong> philosophies.</p><ul><li><p><strong>CISC</strong>, exemplified by x86, includes complex instructions that can perform multi-step operations in a single instruction. This can reduce code size but leads to more complex hardware, longer decode stages, and more challenging verification.</p></li><li><p><strong>RISC</strong>, which underlies both ARM and RISC-V, focuses on simplicity and consistency. Each instruction typically performs a single task and is designed to execute in a uniform number of cycles. This results in simpler hardware, better energy efficiency, and easier pipelining.</p></li></ul><p>RISC-V follows the RISC design principle, but modernizes it with a clean, extensible specification. This is particularly advantageous in current VLSI workflows, where modular design, toolchain compatibility, and post-layout timing closure benefit from simplified and predictable instruction sets.</p><h4 id="why-open-source-architecture-matters">Why Open Source Architecture Matters</h4><p>From a VLSI perspective, an open ISA like RISC-V introduces significant benefits:</p><ul><li><p><strong>Design Freedom</strong>: Engineers can develop processors tailored to specific workloads—whether low-power IoT, real-time control, or high-performance computing—without unnecessary instruction logic.</p></li><li><p><strong>Lower Cost</strong>: There are no licensing fees to use RISC-V, making it suitable for cost-sensitive applications or regions investing in local semiconductor development.</p></li><li><p><strong>Transparency and Customization</strong>: Because the specification is open, it can be audited, extended, and customized. This is useful for security-focused designs and domain-specific accelerators.</p></li><li><p><strong>Toolchain Ecosystem</strong>: Compiler support (e.g., GCC, LLVM), simulation tools, verification environments, and EDA workflows are increasingly supporting RISC-V out of the box. This lowers the barrier to entry for VLSI teams.</p></li></ul><p>This is particularly important as custom silicon becomes more prominent. In chiplet-based systems, AI accelerators, and domain-specific SoCs, the ability to adjust the architecture to fit power, area, and performance goals is critical.</p><h4 id="industrial-adoption-and-ecosystem-growth">Industrial Adoption and Ecosystem Growth</h4><p>Although RISC-V started in academia, it is now gaining industry traction. Several companies have released or are developing commercial RISC-V processors, targeting a range of applications—from microcontrollers to edge AI and datacenter compute.</p><p>The ecosystem around RISC-V has also expanded to include:</p><ul><li><strong>IP vendors</strong> offering synthesizable RISC-V cores</li><li><strong>Verification tools</strong> with compliance suites and assertion libraries</li><li><strong>Synthesis and P&amp;R support</strong> from major EDA tools</li><li><strong>Standard extensions</strong> (like vector processing, bit manipulation, and DSP-friendly instructions)</li></ul><p>This makes RISC-V viable not just for experimental designs, but also for production-grade chips.</p><h4 id="relevance-for-vlsi-design-teams">Relevance for VLSI Design Teams</h4><p>In traditional chip development, ISA constraints often limit how much the architecture can be optimized for silicon. RISC-V offers a different approach: define only what is necessary, customize as needed, and avoid overhead.</p><p>In practical terms, this can lead to:</p><ul><li><strong>Reduced logic area</strong>, due to the use of minimal instruction sets</li><li><strong>Simplified pipeline design</strong>, making it easier to meet timing during backend flow</li><li><strong>Faster verification</strong>, as smaller and cleaner ISAs reduce the state space and potential corner cases</li><li><strong>Easier integration</strong> with accelerators or specialized coprocessors</li></ul><p>For teams building chips under aggressive schedules or for specific application domains (automotive, aerospace, edge computing), this flexibility is a significant advantage.</p><h4 id="looking-ahead">Looking Ahead</h4><p>As the industry continues to move beyond general-purpose processors and toward<strong>application-specific silicon</strong>, ISA flexibility will become increasingly important. Whether it&rsquo;s to build energy-efficient edge AI processors, secure microcontrollers, or scalable chiplets for cloud systems, having an open, extensible architecture makes a difference.</p><p>RISC-V fits well within this evolving VLSI landscape, offering a foundation that is adaptable, license-free, and backed by a growing ecosystem.</p><p>It’s not intended to replace all existing architectures overnight, but it provides a strong alternative—especially in environments where customization, openness, and control over the full stack are important.</p><h4 id="conclusion">Conclusion</h4><p>RISC-V represents a shift in how processor architectures are developed, shared, and implemented. For VLSI engineers, it removes several constraints imposed by proprietary ISAs and opens up new possibilities for silicon-level innovation.</p><p>As the semiconductor industry increasingly focuses on specialized hardware and design reuse, RISC-V is positioned to be a practical and strategic tool—especially for teams seeking flexibility and long-term control over their designs.</p><p>In that context, RISC-V isn’t just another architecture. It’s a response to the changing demands of modern chip design.</p>
]]></content:encoded></item><item><title>Introduction to VLSI Design Flow: RTL to GDSII</title><link>https://mummanajagadeesh.github.io/blog/vlsi-design-flow/</link><pubDate>Thu, 08 May 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/vlsi-design-flow/</guid><description>&lt;![CDATA[<p>Wonder why AI, modern smartphones, and countless digital devices have become so powerful yet compact? The secret lies in the ability to pack billions of transistors into tiny silicon chips — a feat accomplished through<strong>Very Large-Scale Integration (VLSI)</strong>. At the core of this accomplishment is a complex, multi-step design flow that transforms abstract hardware concepts into a physical chip ready for fabrication.</p>]]></description><content:encoded>&lt;![CDATA[<p>Wonder why AI, modern smartphones, and countless digital devices have become so powerful yet compact? The secret lies in the ability to pack billions of transistors into tiny silicon chips — a feat accomplished through<strong>Very Large-Scale Integration (VLSI)</strong>. At the core of this accomplishment is a complex, multi-step design flow that transforms abstract hardware concepts into a physical chip ready for fabrication.</p><p>This flow spans multiple abstraction layers, engineering disciplines, and verification cycles, culminating in a<strong>GDSII</strong> layout file — the silicon mask data sent to the foundry. The path from<strong>Register Transfer Level (RTL)</strong> to<strong>GDSII</strong> involves a series of crucial steps, each demanding specialized tools and deep expertise. Understanding this journey is essential to appreciate how high-level design intentions translate into intricate transistor arrangements and interconnected metal layers, ultimately defining chip functionality, performance, power, and reliability.</p><h4 id="overview-of-vlsi-design-flow-stages">Overview of VLSI Design Flow Stages</h4><p>Before diving into the details, here is a list of the core stages in the VLSI design flow, following the journey from high-level design to final chip layout:</p><ul><li>RTL Design</li><li>Functional Verification</li><li>Logic Synthesis</li><li>Design for Testability (DFT) Insertion</li><li>Floorplanning</li><li>Placement</li><li>Clock Tree Synthesis (CTS)</li><li>Routing</li><li>Static Timing Analysis (STA)</li><li>Physical Verification (DRC, LVS, etc.)</li><li>GDSII File Generation</li></ul><p>Each stage transforms the design closer to a physical reality and imposes critical constraints for the subsequent steps. Let’s explore each of these stages with a detailed, low-level perspective.</p><h4 id="rtl-design-abstract-behavioral-description">RTL Design: Abstract Behavioral Description</h4><p>At the foundation of any digital IC design lies the<strong>Register Transfer Level (RTL)</strong> description. Here, engineers use Hardware Description Languages like Verilog or VHDL to describe data flow between registers and the combinational logic applied to that data during clock cycles.</p><p>The RTL is an algorithmic, cycle-accurate model specifying how registers transfer data, how multiplexers select inputs, how finite state machines transition between states, and how arithmetic operations execute. It abstracts away transistor-level details and focuses on the logic-level function.</p><p>This abstraction allows for flexible architectural exploration — for example, deciding the number of pipeline stages or datapath widths — long before hardware resources are allocated. The RTL code forms the contract between what the chip<em>should</em> do and how it will later be implemented.</p><h4 id="functional-verification-exhaustive-behavioral-testing">Functional Verification: Exhaustive Behavioral Testing</h4><p>Designing a complex chip solely based on code is risky without rigorous validation.<strong>Functional verification</strong> ensures that the RTL code behaves exactly as intended, catching logical errors, corner cases, and unexpected behaviors.</p><p>Verification engineers write testbenches, which generate input stimulus and check outputs against expected results. They use simulation tools to emulate the design cycle-by-cycle, checking timing, control signals, and data correctness. Formal verification techniques and assertion-based verification (SVA) are also employed to mathematically prove design properties.</p><p>The verification scope covers both typical and edge cases, attempting to exhaustively exercise all possible scenarios. Detecting and correcting bugs at this stage prevents costly iterations in physical design.</p><h4 id="logic-synthesis-mapping-rtl-to-gate-level-implementation">Logic Synthesis: Mapping RTL to Gate-Level Implementation</h4><p>Once the RTL passes functional verification, it enters<strong>logic synthesis</strong> — the translation of behavioral code into a gate-level netlist of standard cells.</p><p>Synthesis tools map abstract RTL constructs like if-else statements and case blocks into logic gates such as NANDs, NORs, and flip-flops from a predefined standard cell library. The process includes:</p><ul><li><strong>Technology mapping</strong>: Choosing gate types optimized for the target fabrication technology node (e.g., 7nm, 14nm).</li><li><strong>Logic optimization</strong>: Minimizing gate count, reducing delay, and balancing power consumption.</li><li><strong>Constraint application</strong>: Incorporating timing goals, area budgets, and power constraints specified by the designer.</li></ul><p>The synthesized netlist represents a logical implementation ready for physical design. However, it remains technology-dependent and not yet placed or routed on silicon.</p><h4 id="design-for-testability-dft-insertion-facilitating-post-silicon-testing">Design for Testability (DFT) Insertion: Facilitating Post-Silicon Testing</h4><p>Modern chips consist of billions of transistors, making direct transistor-level testing impractical. Therefore,<strong>Design for Testability (DFT)</strong> techniques are integrated to enable effective manufacturing tests.</p><p>Common DFT techniques include:</p><ul><li><strong>Scan insertion</strong>: Flip-flops are replaced or augmented with scan cells connected into scan chains, allowing serial loading and observation of internal states.</li><li><strong>Built-In Self-Test (BIST)</strong>: Logic to generate test patterns internally to check memory arrays or logic blocks.</li><li><strong>Boundary scan</strong>: For I/O pin testing using standardized protocols (IEEE 1149.1).</li></ul><p>DFT insertion is carefully balanced against area overhead and timing impact but is essential to detect manufacturing defects and improve yield.</p><h4 id="floorplanning-defining-the-physical-architecture">Floorplanning: Defining the Physical Architecture</h4><p>Transitioning from logical netlists to a physical layout starts with<strong>floorplanning</strong>. This stage defines the macro-level organization of the chip:</p><ul><li>Silicon core size and aspect ratio</li><li>Placement of Input/Output (I/O) pads</li><li>Approximate locations for large blocks like memories and IP cores</li><li>Power grid and clock domain planning</li></ul><p>Floorplanning establishes the canvas for subsequent steps. It aims to reduce routing congestion, optimize timing, and provide sufficient space for power delivery networks. Poor floorplanning choices can cascade into routing difficulties, timing violations, and increased power consumption.</p><h4 id="placement-detailed-cell-positioning">Placement: Detailed Cell Positioning</h4><p>With a floorplan set, the standard cells from the netlist must be precisely placed.<strong>Placement tools</strong> assign exact coordinates for each cell to:</p><ul><li>Minimize interconnect wirelength, which impacts delay and power</li><li>Reduce congestion to facilitate routing</li><li>Optimize timing by clustering cells on critical paths</li></ul><p>Placement algorithms consider timing slack, cell density, and power grid connections to ensure a balanced, manufacturable layout. Placement quality significantly affects the chip’s speed, power, and routability.</p><h4 id="clock-tree-synthesis-cts-distributing-the-clock-signal">Clock Tree Synthesis (CTS): Distributing the Clock Signal</h4><p>The clock signal synchronizes operations across the chip and must arrive at every sequential element with minimal skew and jitter.<strong>Clock Tree Synthesis (CTS)</strong> constructs a buffered network of clock drivers and buffers:</p><ul><li>Distributes the clock signal evenly</li><li>Minimizes clock skew between registers</li><li>Balances clock latency</li><li>Reduces power consumption of clock distribution</li></ul><p>A well-constructed clock tree is critical to meet timing constraints and avoid data corruption caused by clock uncertainties.</p><h4 id="routing-connecting-the-circuit">Routing: Connecting the Circuit</h4><p>Routing completes the physical implementation by creating metal interconnections between placed cells. Routing is performed in two phases:</p><ul><li><strong>Global routing</strong>: Assigns approximate routing regions to avoid congestion hotspots</li><li><strong>Detailed routing</strong>: Lays out exact wire paths on available metal layers</li></ul><p>Routing must obey design rules, spacing, and layer usage constraints. It must also mitigate parasitic effects such as crosstalk and signal delay, which can impact signal integrity and timing.</p><p>Routing is often the most time-consuming step due to the sheer complexity and number of nets.</p><h4 id="static-timing-analysis-sta-timing-closure-verification">Static Timing Analysis (STA): Timing Closure Verification</h4><p>Post-routing, the design undergoes<strong>Static Timing Analysis (STA)</strong> to verify all timing paths meet constraints:</p><ul><li>Checks setup and hold times for sequential elements</li><li>Computes timing slack for all paths</li><li>Detects timing violations that can cause malfunction at the target clock frequency</li></ul><p>STA is exhaustive and deterministic, analyzing every possible timing path without requiring test vectors. Timing failures must be resolved iteratively through design changes or buffering until timing closure is achieved.</p><h4 id="physical-verification-ensuring-manufacturability-and-correctness">Physical Verification: Ensuring Manufacturability and Correctness</h4><p>Before sending the design for fabrication, it undergoes rigorous<strong>physical verification</strong> to ensure manufacturability:</p><ul><li><strong>Design Rule Checks (DRC)</strong>: Verify all layout geometry complies with foundry spacing, width, and layering rules.</li><li><strong>Layout Versus Schematic (LVS)</strong>: Ensures the physical layout matches the netlist connectivity and topology.</li><li>Additional checks for antenna effects, electromigration, and other reliability concerns are performed.</li></ul><p>These steps prevent costly manufacturing errors and guarantee that the chip will function as designed.</p><h4 id="gdsii-file-generation-the-final-tape-out">GDSII File Generation: The Final Tape-Out</h4><p>The entire physical design is converted into a<strong>GDSII</strong> file, a binary format that contains detailed polygonal data representing every layer and feature of the chip layout.</p><p>This file is the definitive mask data used by the semiconductor foundry to fabricate the chip via photolithography. It encapsulates the result of months of design effort, verification, and optimization into a manufacturable format.</p><p>The GDSII is often the final output delivered to fabrication, marking the transition from design to physical silicon.</p><h4 id="conclusion">Conclusion</h4><p>The VLSI design flow from RTL to GDSII is a meticulous, multi-disciplinary journey that transforms abstract digital logic into a physical silicon chip. Each step — from writing behavioral code to verifying manufacturability — involves deep technical challenges and precision engineering.</p><p>Understanding this flow is critical for anyone engaged in semiconductor design, as it reveals how a digital idea becomes a tangible, functioning integrated circuit powering today’s technology landscape.</p><p>The constant interplay between design abstraction, physical constraints, and verification rigor drives innovation and ensures chips meet ever-increasing demands for speed, power efficiency, and functionality.</p>
]]></content:encoded></item><item><title>ROS 2 vs ROS 1: What Changed and Why It Matters?</title><link>https://mummanajagadeesh.github.io/blog/ros1-vs-ros2/</link><pubDate>Fri, 02 May 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/ros1-vs-ros2/</guid><description>&lt;![CDATA[<p>Is ROS 1 still the right choice for your next robotics project, with its well-established tools and wide community support? Or, given the growing demand for real-time performance, scalability, and modern middleware, is it finally time to make the move to ROS 2?</p>]]></description><content:encoded>&lt;![CDATA[<p>Is ROS 1 still the right choice for your next robotics project, with its well-established tools and wide community support? Or, given the growing demand for real-time performance, scalability, and modern middleware, is it finally time to make the move to ROS 2?</p><p>As of the end of this month—<strong>May 2025</strong>—official support for<strong>ROS 1</strong> will come to a close. This marks a major turning point in the robotics software ecosystem. For over a decade, ROS 1 (Robot Operating System) has served as the backbone of robotic development across research and industry. But the shift to ROS 2 is more than just an upgrade—it&rsquo;s a rethinking of the platform from the ground up.</p><p>This article provides a clear look at the changes introduced in ROS 2, why ROS 1 is being sunset, and what this means for developers, researchers, and organizations working in robotics.</p><h3 id="what-is-ros">What is ROS?</h3><p>ROS (Robot Operating System) is a flexible framework for writing robot software. Despite the name, it’s not a full-fledged OS but a middleware layer that sits on top of your actual operating system, handling the complexity of communication, modularity, and distributed execution.</p><p>At its core, ROS provides:</p><ul><li>A message-passing architecture for processes (nodes) to communicate.</li><li>Tools to visualize data, record logs, and debug system behavior.</li><li>Packages to handle everything from perception and motion planning to hardware abstraction.</li></ul><p>It’s the glue that connects sensors, control logic, actuators, and high-level decision-making in a robotics application. In ROS, each node performs a specific task—say, reading from a LIDAR sensor or planning a path—and publishes/subscribes to messages over topics. This enables a clean, modular architecture where components are reusable and decoupled.</p><h3 id="why-ros-what-difference-does-it-make">Why ROS? What Difference Does It Make?</h3><p>Building robot software is not like writing a web app or scripting a microcontroller. Robots deal with real-world inputs—noisy data, real-time constraints, hardware failures—and are inherently distributed systems. Without a framework like ROS, you&rsquo;d have to write your own communication protocols, serialization formats, data pipelines, logging infrastructure, and process management tools.</p><p>ROS abstracts these repetitive tasks. It provides:</p><ul><li><strong>Standardized communication</strong>: Publish/subscribe and service-based interaction.</li><li><strong>Sensor integration</strong>: Drivers for cameras, IMUs, GPS, and more.</li><li><strong>Visualization</strong>: RViz, rqt, and introspection tools.</li><li><strong>Hardware abstraction</strong>: URDF and ROS Control for modeling and interfacing with robot hardware.</li></ul><p>With ROS, developers focus on algorithms and behavior, not the plumbing. It also offers a large open-source ecosystem, so you’re rarely starting from scratch. Whether you&rsquo;re working on SLAM, navigation, or perception, someone’s likely already done 70% of the work.</p><h3 id="why-ros-1-was-right-and-also-wrong">Why ROS 1 Was Right (and Also Wrong)</h3><p>ROS 1 got a lot of things right. It gave researchers a shared language, simplified complex system integration, and accelerated robotics development. But its architecture was never built with real-time guarantees, security, or modern networking in mind.</p><p><strong>What ROS 1 did well:</strong></p><ul><li>Made robotics accessible and modular.</li><li>Encouraged rapid prototyping and experimentation.</li><li>Built a massive ecosystem and developer base.</li><li>Created tools like<code>rosbag</code>,<code>RViz</code>, and<code>rqt</code> that became industry standards.</li></ul><p><strong>Where ROS 1 struggled:</strong></p><ul><li>Communication relied on a centralized ROS Master node, a single point of failure.</li><li>No support for real-time scheduling or deterministic behavior.</li><li>Lacked Quality of Service (QoS) configuration for topics.</li><li>Poor multi-robot support—nodes weren’t namespace-aware by default.</li><li>No native support for embedded devices or resource-constrained platforms.</li><li>No built-in security model—data over the network was unencrypted and unauthenticated.</li></ul><p>These issues became roadblocks as robotics moved out of the lab and into industrial, consumer, and mission-critical environments.</p><h3 id="what-changed-why-ros-2-is-better">What Changed? Why ROS 2 is Better</h3><p>ROS 2 was designed to address the structural limitations of ROS 1. It’s a complete architectural rewrite based on modern software engineering practices and real-world deployment needs.</p><p>Here&rsquo;s a deeper look at what&rsquo;s new:</p><h4 id="dds-based-communication-no-more-ros-master">DDS-Based Communication (No More ROS Master)</h4><p>ROS 2 uses the<strong>Data Distribution Service (DDS)</strong> protocol for inter-process communication. DDS is decentralized, so there’s no need for a master node. Nodes can come and go freely, discover each other dynamically, and communicate peer-to-peer.</p><p>This enables:</p><ul><li><strong>Distributed multi-robot systems</strong> with zero configuration.</li><li><strong>Fault tolerance</strong>—if a node dies, the system doesn’t collapse.</li><li><strong>Scalability</strong> across networks, platforms, and locations.</li></ul><h4 id="real-time-support">Real-Time Support</h4><p>Unlike ROS 1, ROS 2 supports<strong>real-time execution</strong>. You can now:</p><ul><li>Run control loops with deterministic timing.</li><li>Assign thread priorities and memory bounds.</li><li>Interface directly with real-time operating systems (RTOS).</li></ul><p>This makes ROS 2 viable for hard real-time applications like industrial robot arms, autonomous vehicles, and flight controllers.</p><h4 id="quality-of-service-qos">Quality of Service (QoS)</h4><p>DDS allows developers to fine-tune how messages are delivered with<strong>QoS profiles</strong>. You can configure:</p><ul><li><strong>Reliability</strong> (best effort vs guaranteed delivery)</li><li><strong>Durability</strong> (do new subscribers get old messages?)</li><li><strong>Latency budgets</strong></li><li><strong>Liveliness detection</strong> (detecting dead publishers)</li></ul><p>This gives developers precise control over how nodes interact, especially in lossy or high-throughput networks.</p><h4 id="security-built-in">Security Built-In</h4><p>Security was an afterthought in ROS 1. In ROS 2, it’s a first-class citizen. It includes:</p><ul><li><strong>Encryption</strong> of messages in transit</li><li><strong>Authentication</strong> of nodes</li><li><strong>Access control policies</strong> to restrict who can publish/subscribe</li></ul><p>Security is crucial for commercial robotics, especially in fields like healthcare, defense, and autonomous transport.</p><h4 id="improved-node-lifecycle-management">Improved Node Lifecycle Management</h4><p>ROS 2 introduces<strong>managed lifecycles</strong> for nodes. A node can be explicitly initialized, activated, deactivated, and shut down. This allows:</p><ul><li>Cleaner startup and shutdown sequences</li><li>Better error handling</li><li>Easier introspection and supervision</li></ul><p>This is particularly useful in systems that require staged initialization or watchdog monitoring.</p><h4 id="cross-platform--embedded-ready">Cross-Platform &amp; Embedded Ready</h4><p>ROS 2 is designed to work across platforms:</p><ul><li>Native support for Linux, Windows, and macOS (though Windows and macOS are not considered production-grade for most robotics deployments)</li><li>Builds on ARM and embedded Linux devices</li><li>Supports cross-compilation for real-time microcontrollers</li></ul><p>This means you can build a system with a Jetson for perception, a Raspberry Pi for control, and a desktop for planning—ROS 2 will tie it all together.</p><h3 id="ros-1-doesnt-stop-overnight">ROS 1 Doesn’t Stop Overnight</h3><p>The end of official support doesn’t mean that ROS 1 systems will suddenly break. Existing applications and research projects built on ROS 1 will continue to run. But the risks will grow over time:</p><ul><li><strong>No new bug fixes or security patches</strong></li><li><strong>Incompatibility with newer operating systems and compilers</strong></li><li><strong>Reduced community activity and package maintenance</strong></li><li><strong>No support for evolving hardware or standards</strong></li></ul><p>For small-scale projects, this may not matter. But for production environments, long-term maintenance, and scalable deployments—ROS 2 is the way forward.</p><h3 id="final-thoughts">Final Thoughts</h3><p>ROS 2 isn’t just a newer version of ROS—it’s a complete rethink, engineered for where robotics is headed. Real-time control, secure communication, decentralized systems, and embedded readiness are no longer optional—they’re essential.</p><p>Yes, migrating to ROS 2 can be a non-trivial effort. APIs are different. Not all ROS 1 packages have 1-to-1 equivalents. But the foundational improvements are worth it—and necessary.</p><p>If you&rsquo;re starting a new robotics project in 2025, choosing ROS 1 now would be like choosing Python 2 for a new web app. It might work, but you’re building on borrowed time.</p><p>So—<strong>what changed? Everything.</strong> And that’s why it matters.</p>
]]></content:encoded></item><item><title>What is SLAM? And Why It’s the Brain of Mobile Robots</title><link>https://mummanajagadeesh.github.io/blog/what-is-slam/</link><pubDate>Sun, 20 Apr 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/what-is-slam/</guid><description>&lt;![CDATA[<p>In robotics,<strong>SLAM</strong>—<strong>Simultaneous Localization and Mapping</strong>—is regarded as one of the most fundamental and complex problems. At its core, SLAM addresses a deceptively simple question:<em>&ldquo;Where am I, and what does the world around me look like?&rdquo;</em></p>]]></description><content:encoded>&lt;![CDATA[<p>In robotics,<strong>SLAM</strong>—<strong>Simultaneous Localization and Mapping</strong>—is regarded as one of the most fundamental and complex problems. At its core, SLAM addresses a deceptively simple question:<em>&ldquo;Where am I, and what does the world around me look like?&rdquo;</em></p><p>For a robot to navigate autonomously, it must construct a map of an unknown environment while simultaneously localizing itself within that map. This dual-estimation problem underpins most mobile robotics systems, making SLAM essentially the<strong>cognitive core or brain</strong> that enables autonomy.</p><h4 id="the-formal-problem-definition">The Formal Problem Definition</h4><p>The SLAM problem can be formally expressed in probabilistic terms. Let:</p><ul><li><strong>xₜ</strong> denote the robot’s state (pose) at time<em>t</em>.</li><li><strong>m</strong> represent the map of the environment (which may be feature-based, occupancy grid, or landmark-based).</li><li><strong>uₜ</strong> be the control input (e.g., wheel velocity commands).</li><li><strong>zₜ</strong> be the observation or sensor measurement at time<em>t</em>.</li></ul><p>The goal of SLAM is to compute the posterior distribution:</p><p>$$
P(x_{1:t}, m \mid z_{1:t}, u_{1:t})
$$</p><p>That is, we want to estimate the trajectory of the robot<strong>x₁:t</strong> and the map<strong>m</strong>, given all sensor observations<strong>z₁:t</strong> and control inputs<strong>u₁:t</strong> up to time<em>t</em>. This joint estimation makes SLAM non-trivial, since errors in one (pose or map) propagate into the other.</p><h4 id="a-bayesian-perspective">A Bayesian Perspective</h4><p>The SLAM problem is inherently a<strong>Bayesian inference</strong> problem. The recursive Bayes filter provides the framework:</p><p>$$
P(x_t, m \mid z_{1:t}, u_{1:t}) = \eta \cdot P(z_t \mid x_t, m) \cdot \int P(x_t \mid x_{t-1}, u_t) P(x_{t-1}, m \mid z_{1:t-1}, u_{1:t-1}) dx_{t-1}
$$</p><p>Where:</p><ul><li>\(\eta\) is a normalizing constant.</li><li>\(P(z_t \mid x_t, m)\) is the<strong>observation model</strong>, also known as the likelihood.</li><li>\(P(x_t \mid x_{t-1}, u_t)\) is the<strong>motion model</strong>, describing the robot&rsquo;s kinematics.</li></ul><p>This recursive structure is at the heart of many SLAM algorithms and leads to various implementations like<strong>Extended Kalman Filter SLAM</strong>,<strong>Particle Filter SLAM (FastSLAM)</strong>, and<strong>Graph-Based SLAM</strong>.</p><h4 id="state-estimation-and-mapping">State Estimation and Mapping</h4><p>In SLAM, there are two intertwined estimation problems:</p><ol><li><strong>Localization</strong>: Estimating the robot’s pose \(x_t\) given a map.</li><li><strong>Mapping</strong>: Estimating the map \(m\) given the pose history.</li></ol><p>These are not independent—if the robot’s pose is uncertain, the resulting map will be too. This mutual dependency necessitates a<strong>joint estimation</strong>.</p><h5 id="motion-model">Motion Model</h5><p>Assuming a differential drive robot, the motion model is often modeled as:</p><p>$$
x_t = f(x_{t-1}, u_t) + w_t
$$</p><p>Where:</p><ul><li>\(f\) is the motion function (e.g., based on odometry).</li><li>\(w_t\) is process noise, often modeled as zero-mean Gaussian noise with covariance \(Q_t\).</li></ul><h5 id="observation-model">Observation Model</h5><p>Sensor measurements (from LIDAR, sonar, or cameras) depend on the robot&rsquo;s pose and the environment:</p><p>$$
z_t = h(x_t, m) + v_t
$$</p><p>Where:</p><ul><li>\(h\) is the observation function.</li><li>\(v_t\) is observation noise, modeled as Gaussian with covariance \(R_t\).</li></ul><h4 id="variants-and-algorithms">Variants and Algorithms</h4><p>Depending on how one approximates the posterior, several algorithmic variants of SLAM arise:</p><h5 id="extended-kalman-filter-slam-ekf-slam">Extended Kalman Filter SLAM (EKF-SLAM)</h5><p>EKF-SLAM linearizes the motion and observation models around the current estimate and tracks the mean and covariance of the joint state \((x_t, m)\). It scales poorly with the number of landmarks due to quadratic complexity in the state size.</p><h5 id="particle-filter-slam-fastslam">Particle Filter SLAM (FastSLAM)</h5><p>FastSLAM uses a<strong>Rao-Blackwellized particle filter</strong>, factorizing the SLAM posterior:</p><p>$$
P(x_{1:t}, m \mid z_{1:t}, u_{1:t}) = P(m \mid x_{1:t}, z_{1:t}) \cdot P(x_{1:t} \mid z_{1:t}, u_{1:t})
$$</p><p>Particles represent different possible robot trajectories, and each particle maintains its own map, allowing for greater scalability and handling of non-linear, non-Gaussian systems.</p><h5 id="graph-based-slam">Graph-Based SLAM</h5><p>Graph SLAM formulates SLAM as a<strong>nonlinear optimization</strong> problem. Nodes in the graph represent robot poses and landmarks, while edges represent spatial constraints derived from motion and sensor data. The optimization seeks to find the configuration that minimizes the total error (e.g., via least-squares):</p><p>$$
x^* = \arg \min_x \sum_{i,j} | z_{ij} - h(x_i, x_j) |^2_{\Omega_{ij}}
$$</p><p>Where \(\Omega_{ij}\) is the information matrix (inverse of the covariance).</p><p>Graph SLAM is currently one of the most popular SLAM formulations, especially in systems like<strong>g2o</strong> and<strong>Ceres Solver</strong>, due to its flexibility and ability to incorporate loop closures and global constraints.</p><h4 id="the-role-of-slam-in-mobile-robots">The Role of SLAM in Mobile Robots</h4><p>In the broader system architecture of a mobile robot, SLAM functions as the<strong>spatial intelligence unit</strong>. All downstream tasks—<strong>path planning</strong>,<strong>obstacle avoidance</strong>,<strong>exploration</strong>, and<strong>task execution</strong>—rely on accurate state and environment estimates.</p><p>SLAM enables:</p><ul><li>Real-time tracking of the robot&rsquo;s pose.</li><li>Dynamic updates to the map as new observations are made.</li><li>Consistent correction of errors via<strong>loop closure</strong> detection.</li><li>Integration with higher-level cognition systems like planning and decision-making.</li></ul><p>Without SLAM, a mobile robot is effectively blind and disoriented—capable of sensing but not<em>understanding</em> its environment.</p><h4 id="slam-and-lie-groups">SLAM and Lie Groups</h4><p>For robots operating in 2D or 3D, pose estimation involves dealing with<strong>SE(2)</strong> or<strong>SE(3)</strong> Lie groups. A pose is not just a vector but a transformation matrix involving rotation and translation:</p><p>$$
T = \begin{bmatrix}
R &amp; t \
0 &amp; 1
\end{bmatrix} \in SE(3)
$$</p><p>Where:</p><ul><li>\(R \in SO(3)\) is a rotation matrix.</li><li>\(t \in \mathbb{R}^3\) is a translation vector.</li></ul><p>Modern SLAM back-ends incorporate these group structures to ensure consistency in optimization, using tools like<strong>manifold-aware optimization</strong> and<strong>Lie algebra exponential maps</strong>.</p><h4 id="slam-beyond-geometry">SLAM Beyond Geometry</h4><p>While SLAM traditionally focuses on geometric mapping, there is increasing interest in<strong>semantic SLAM</strong>—embedding meaning and object-level understanding into the map. This blends SLAM with computer vision and deep learning, creating a more human-interpretable world model.</p><h4 id="final-thoughts">Final Thoughts</h4><p>SLAM is not just a technique—it is the cognitive foundation of spatial intelligence in autonomous robots. It encapsulates estimation theory, probability, optimization, geometry, and control into a cohesive framework. As robotics systems grow more complex and dynamic, SLAM continues to evolve at the intersection of theory and real-world performance.</p><p>Whether using Kalman filters, particle filters, or factor graphs, SLAM remains the mathematical brain that allows robots to think spatially—bridging perception with action.</p>
]]></content:encoded></item><item><title>Switch to Linux and Thank Me Later</title><link>https://mummanajagadeesh.github.io/blog/switch-to-linux-and-thank-me-later/</link><pubDate>Tue, 15 Apr 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/switch-to-linux-and-thank-me-later/</guid><description>&lt;![CDATA[<p>You&rsquo;re not really using your computer — you&rsquo;re being allowed to.
If the system decides how you work, who’s really in control?
Linux doesn’t assume how you want to use your machine — it asks.</p>]]></description><content:encoded>&lt;![CDATA[<p>You&rsquo;re not really using your computer — you&rsquo;re being allowed to.
If the system decides how you work, who’s really in control?
Linux doesn’t assume how you want to use your machine — it asks.</p><h4 id="what-is-an-operating-system">What is an Operating System?</h4><p>An operating system (OS) is a low-level software layer responsible for managing hardware resources and providing services to user-level applications. It handles memory allocation, process scheduling, file systems, I/O operations, and device management.</p><p>If you&rsquo;re using Windows or macOS, you&rsquo;re already relying on an OS to abstract hardware complexity and provide user-facing utilities. These platforms are tightly integrated, prioritize consistency, and limit exposure to internal system mechanisms. For most users, this abstraction works. But it comes at the cost of reduced flexibility and limited access to internals.</p><h4 id="what-is-linux">What Is Linux?</h4><p>Linux refers to the<strong>kernel</strong>, not the entire OS. It&rsquo;s a monolithic kernel that manages system-level operations. When combined with userland tools (like GNU coreutils, shells, systemd, libraries), you get a<strong>Linux distribution</strong>.</p><p>Unlike proprietary OSes, Linux is:</p><ul><li><strong>Modular</strong> – Components can be swapped or removed entirely.</li><li><strong>Transparent</strong> – Everything can be inspected or modified, from the bootloader to the shell.</li><li><strong>Open Source</strong> – Source code is available for nearly all components, from the kernel to window managers.</li></ul><p>You can control the boot process, recompile the kernel, trace syscalls, patch drivers, and monitor performance in real-time — all with native tools.</p><h4 id="why-use-linux">Why Use Linux?</h4><h5 id="full-system-visibility-and-control">Full System Visibility and Control</h5><p>On Linux, logs are in<code>/var/log</code> or accessible via<code>journalctl</code>. Services are managed with<code>systemd</code>, and devices are exposed in<code>/dev</code>. Nothing is hidden behind a registry or proprietary interface.</p><h5 id="rich-cli-and-scripting-ecosystem">Rich CLI and Scripting Ecosystem</h5><p>The command-line interface (CLI) is a first-class environment, not a fallback. Tools like<code>grep</code>,<code>awk</code>,<code>sed</code>,<code>find</code>,<code>cut</code>, and<code>xargs</code> make text processing and system automation efficient.</p><h5 id="package-management">Package Management</h5><p>Software is installed via package managers (<code>apt</code>,<code>dnf</code>,<code>pacman</code>, etc.), with cryptographic signature verification and automatic dependency resolution.</p><h5 id="security">Security</h5><ul><li><strong>User and group-based permissions</strong> (UMASK,<code>chmod</code>,<code>chown</code>)</li><li><strong>Access Control Lists (ACLs)</strong> and<strong>capabilities</strong></li><li><strong>Mandatory Access Control (MAC)</strong> via SELinux, AppArmor</li><li><strong>No admin by default</strong> – root privileges require<code>sudo</code> or root shell</li></ul><h5 id="performance-and-efficiency">Performance and Efficiency</h5><p>Linux runs on everything from embedded devices with &lt;64 MB RAM to multi-core servers. You can run headless servers, real-time systems, or full-fledged graphical environments — all tuned to your use case.</p><h4 id="understanding-linux-distributions-distros">Understanding Linux Distributions (Distros)</h4><p>A<strong>distribution</strong> is a collection of:</p><ul><li>The Linux kernel</li><li>Core userland tools (from GNU or others)</li><li>Package manager</li><li>Optional GUI (X11/Wayland + DE/WM)</li><li>Configuration and init system (usually<code>systemd</code>, sometimes<code>OpenRC</code> or others)</li></ul><p>Some common distributions:</p><h5 id="ubuntu">Ubuntu</h5><ul><li>Beginner-friendly, maintained by Canonical</li><li>Uses<code>apt</code> package manager</li><li>Default DE: GNOME</li><li>Good hardware support, LTS releases available</li></ul><h5 id="debian">Debian</h5><ul><li>Parent of Ubuntu, more conservative</li><li>Very stable, large repositories</li><li>Suitable for servers and advanced users</li></ul><h5 id="fedora">Fedora</h5><ul><li>Sponsored by Red Hat</li><li>Cutting-edge packages, SELinux by default</li><li>Uses<code>dnf</code> for package management</li></ul><h5 id="arch-linux">Arch Linux</h5><ul><li>Rolling release, minimal install</li><li>User builds system from ground up</li><li><code>pacman</code> for package management</li><li>Requires good understanding of Linux internals</li></ul><h5 id="others">Others</h5><ul><li><strong>openSUSE</strong> (uses<code>zypper</code>)</li><li><strong>Alpine Linux</strong> (musl libc, great for containers)</li><li><strong>Void Linux</strong> (runit init system)</li><li><strong>Gentoo</strong> (source-based, maximum customization)</li></ul><h4 id="how-to-try-linux">How to Try Linux</h4><h5 id="live-usb">Live USB</h5><ul><li>Download ISO from distro website (e.g., ubuntu.com, debian.org, archlinux.org)</li><li>Use tools like<strong>Rufus</strong>,<strong>Etcher</strong>, or<code>dd</code> to flash the ISO to a USB stick</li><li>Boot from USB, run the OS live without installing</li></ul><h5 id="virtual-machine">Virtual Machine</h5><ul><li>Use<strong>VirtualBox</strong>,<strong>QEMU</strong>, or<strong>VMware</strong></li><li>Create a VM, allocate resources, and boot into the ISO</li><li>Great for learning CLI tools and basic configuration</li></ul><h5 id="dual-boot">Dual Boot</h5><ul><li>Shrink existing OS partition</li><li>Install Linux alongside Windows/macOS</li><li>Choose OS on boot via GRUB</li></ul><h4 id="linux-command-line-where-to-start">Linux Command Line: Where to Start</h4><h5 id="navigation">Navigation</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pwd<span style="color:#75715e"># Print current directory</span></span></span><span style="display:flex;"><span>cd /path<span style="color:#75715e"># Change directory</span></span></span><span style="display:flex;"><span>ls -l<span style="color:#75715e"># List files with details</span></span></span></code></pre></div><h5 id="file-operations">File Operations</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>touch file.txt<span style="color:#75715e"># Create file</span></span></span><span style="display:flex;"><span>mkdir dir<span style="color:#75715e"># Make directory</span></span></span><span style="display:flex;"><span>cp src dest<span style="color:#75715e"># Copy file</span></span></span><span style="display:flex;"><span>mv old new<span style="color:#75715e"># Move/rename file</span></span></span><span style="display:flex;"><span>rm -rf dir<span style="color:#75715e"># Delete directory recursively</span></span></span></code></pre></div><h5 id="package-management-debianubuntu">Package Management (Debian/Ubuntu)</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt update<span style="color:#75715e"># Update package list</span></span></span><span style="display:flex;"><span>sudo apt upgrade<span style="color:#75715e"># Upgrade all packages</span></span></span><span style="display:flex;"><span>sudo apt install pkg<span style="color:#75715e"># Install package</span></span></span><span style="display:flex;"><span>sudo apt remove pkg<span style="color:#75715e"># Remove package</span></span></span></code></pre></div><h5 id="processes-and-system">Processes and System</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ps aux<span style="color:#75715e"># List all processes</span></span></span><span style="display:flex;"><span>top / htop<span style="color:#75715e"># System monitor</span></span></span><span style="display:flex;"><span>kill PID<span style="color:#75715e"># Terminate process</span></span></span><span style="display:flex;"><span>df -h<span style="color:#75715e"># Disk usage</span></span></span><span style="display:flex;"><span>free -m<span style="color:#75715e"># RAM usage</span></span></span><span style="display:flex;"><span>uname -r<span style="color:#75715e"># Kernel version</span></span></span></code></pre></div><h5 id="networking">Networking</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ip a<span style="color:#75715e"># Show IP addresses</span></span></span><span style="display:flex;"><span>ping 8.8.8.8<span style="color:#75715e"># Check connectivity</span></span></span><span style="display:flex;"><span>netstat -tulnp<span style="color:#75715e"># Show open ports</span></span></span></code></pre></div><h5 id="logs-and-services">Logs and Services</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>journalctl -xe<span style="color:#75715e"># View system logs</span></span></span><span style="display:flex;"><span>systemctl status ssh<span style="color:#75715e"># Check SSH service</span></span></span><span style="display:flex;"><span>sudo systemctl restart ssh</span></span></code></pre></div><h4 id="linux-community-and-ecosystem">Linux Community and Ecosystem</h4><p>One of Linux’s strengths is its global, active developer and user community. Resources include:</p><ul><li><strong>Arch Wiki</strong> – Best technical documentation, not limited to Arch</li><li><strong>Stack Overflow / Unix StackExchange</strong> – Troubleshooting, config help</li><li><strong>Reddit</strong> – r/linux, r/linuxadmin, r/linux4noobs</li><li><strong>IRC / Matrix / Discord</strong> – Real-time help for specific distros</li><li><strong>Mailing Lists and Git Repos</strong> – Access to upstream development discussions</li></ul><p>Bug reports and patches are community-driven. Discussions happen in public. You can track issues, read commits, or contribute code.</p><h4 id="common-use-cases">Common Use Cases</h4><ul><li><strong>Development</strong>: Native GCC, Clang, Python, Rust, Go, Node, etc. Bash/Python scripting, Makefiles, CI/CD tools all integrate natively.</li><li><strong>Servers</strong>: SSH, Docker, NGINX, PostgreSQL, systemd timers, firewall rules</li><li><strong>Embedded</strong>: Custom kernel builds, cross-compilation, BusyBox, buildroot</li><li><strong>Networking</strong>: IPTables, WireGuard, TCPDump, Netplan, NetworkManager CLI</li><li><strong>Security</strong>: GPG, TPM, AppArmor, auditd, fail2ban</li><li><strong>Minimal Systems</strong>: CLI-only builds, tiling WMs, no unnecessary services</li></ul><h4 id="where-linux-falls-short">Where Linux Falls Short</h4><ul><li>Some commercial software (Adobe Suite, MS Office) isn’t natively supported.</li><li>Hardware vendors may not provide official Linux drivers (especially Wi-Fi or GPUs).</li><li>Gaming is improving, but anti-cheat and some titles still rely on Windows-only libraries.</li><li>The learning curve is real if you&rsquo;re new to the CLI or package management.</li></ul><h4 id="final-notes">Final Notes</h4><p>Linux gives you the system as-is. No unnecessary abstraction, no locked settings, no background processes phoning home. You&rsquo;re responsible for maintaining your system — and in return, you gain deep insight and full control.</p><p>The trade-off is worth it if you care about reproducibility, transparency, and performance.</p>
]]></content:encoded></item><item><title>I²C: Fundamentals and Practical Aspects of Inter-Integrated Circuit Communication</title><link>https://mummanajagadeesh.github.io/blog/i2c/</link><pubDate>Tue, 08 Apr 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/i2c/</guid><description>&lt;![CDATA[<p>I²C is a<strong>synchronous, half-duplex, multi-master, multi-slave</strong> serial communication protocol developed by Philips (now NXP) in the 1980s. It was designed for<strong>on-board communication between integrated circuits</strong>, especially in systems with multiple low-speed peripherals controlled by a microcontroller.</p>]]></description><content:encoded>&lt;![CDATA[<p>I²C is a<strong>synchronous, half-duplex, multi-master, multi-slave</strong> serial communication protocol developed by Philips (now NXP) in the 1980s. It was designed for<strong>on-board communication between integrated circuits</strong>, especially in systems with multiple low-speed peripherals controlled by a microcontroller.</p><p>It prioritizes<strong>simplicity and scalability over speed</strong>, making it ideal for communication over short distances with minimal wiring.</p><h4 id="fundamental-signal-lines"><strong>Fundamental Signal Lines</strong></h4><p>I²C uses<strong>only two bi-directional lines</strong>:</p><ul><li><strong>SDA (Serial Data Line)</strong> – Carries the data.</li><li><strong>SCL (Serial Clock Line)</strong> – Carries the clock signal generated by the master.</li></ul><p>Both lines are<strong>open-drain (or open-collector)</strong>, meaning devices can pull the line low but<strong>cannot drive it high</strong>. Instead,<strong>external pull-up resistors</strong> are required to bring the lines to a logic HIGH when not pulled LOW. This ensures multiple devices can safely share the bus.</p><p>Common pull-up resistor values range from 2.2kΩ to 10kΩ, depending on bus speed and capacitance.</p><h4 id="bus-topology-and-roles"><strong>Bus Topology and Roles</strong></h4><ul><li><strong>Multi-master</strong>: Any device capable of initiating communication can act as a master.</li><li><strong>Multi-slave</strong>: All devices on the bus have unique addresses, allowing shared access over just two wires.</li></ul><p>Every transaction is initiated by a<strong>master</strong>, and the addressed<strong>slave</strong> responds.</p><p>The bus supports<strong>hot-swapping</strong>—devices can be connected/disconnected dynamically as long as the electrical characteristics are observed.</p><h4 id="addressing-scheme"><strong>Addressing Scheme</strong></h4><p>Each I²C device has a<strong>7-bit or 10-bit address</strong>:</p><ul><li><strong>7-bit addressing</strong> is standard (supports up to 128 devices)</li><li>Some modern devices use<strong>10-bit addressing</strong> (rare in practice)</li></ul><p>The master begins communication by sending a<strong>START condition</strong>, followed by the<strong>7-bit address</strong> and a<strong>R/W bit</strong>:</p><ul><li><code>0</code>: Write to slave</li><li><code>1</code>: Read from slave</li></ul><p>The addressed slave responds with an<strong>ACK</strong> (acknowledge) bit.</p><h4 id="basic-transaction-format"><strong>Basic Transaction Format</strong></h4><p>A typical I²C communication consists of:</p><ol><li><strong>START condition</strong>: SDA goes LOW while SCL is HIGH</li><li><strong>Address + R/W bit</strong></li><li><strong>ACK/NACK from slave</strong></li><li><strong>Data byte</strong></li><li><strong>ACK/NACK</strong></li><li>[Optional] More data bytes and ACKs</li><li><strong>STOP condition</strong>: SDA goes HIGH while SCL is HIGH</li></ol><p><strong>Clock stretching</strong>: Slaves can hold SCL LOW to delay communication if they&rsquo;re not ready to respond, allowing for flow control.</p><h4 id="data-framing-and-timing"><strong>Data Framing and Timing</strong></h4><ul><li>All data is sent<strong>MSB-first</strong></li><li>Each byte is 8 bits, followed by a 1-bit ACK/NACK</li><li>Timing is defined by<strong>Standard-mode (100 kHz)</strong>,<strong>Fast-mode (400 kHz)</strong>,<strong>Fast-mode Plus (1 MHz)</strong>, and<strong>High-Speed mode (3.4 MHz)</strong></li></ul><p>Master controls the clock in all modes, but in<strong>clock stretching</strong>, slaves can pause the clock by holding SCL low.</p><h4 id="electrical-and-physical-characteristics"><strong>Electrical and Physical Characteristics</strong></h4><ul><li><strong>Voltage levels</strong>: Typically 3.3V or 5V (must match or use level shifters)</li><li><strong>Bus capacitance</strong>: Must be below 400pF for reliable operation</li><li><strong>Open-drain lines</strong>: Essential for multi-master and shared-bus safety</li><li><strong>Wiring</strong>: Only two lines needed, which makes I²C excellent for PCB routing and connector reduction</li></ul><h4 id="advantages-of-ic"><strong>Advantages of I²C</strong></h4><ul><li><strong>Minimal wiring</strong>: Just two wires for all devices</li><li><strong>Addressable devices</strong>: Built-in addressing supports multiple devices with no extra CS logic</li><li><strong>Standardized protocol</strong>: Robust and well-documented across microcontrollers and ICs</li><li><strong>Clock stretching</strong>: Enables slow slaves to hold off the master</li><li><strong>Multiple masters</strong>: Optional, with arbitration built-in</li><li><strong>ACK/NACK mechanism</strong>: Basic error detection</li></ul><h4 id="limitations"><strong>Limitations</strong></h4><ul><li><strong>Slower speeds</strong> compared to SPI: Maxes out at 3.4 MHz (HS mode), with most devices using 100–400 kHz</li><li><strong>Half-duplex</strong>: One direction at a time</li><li><strong>Protocol overhead</strong>: Extra bits for addresses and ACKs reduce net throughput</li><li><strong>Complexity in software</strong>: Due to start/stop conditions, arbitration, and retries</li><li><strong>Shared bus</strong>: A fault in one device (e.g., pulling SDA low) can hang the whole bus</li><li><strong>Less suitable for high-speed or large data transfers</strong></li></ul><h4 id="multi-master-arbitration"><strong>Multi-Master Arbitration</strong></h4><p>I²C allows multiple masters to coexist. If two masters start communication simultaneously:</p><ul><li>Arbitration is resolved by checking the SDA line during transmission</li><li>The master that detects a mismatch (it sends 1 but sees 0)<strong>backs off</strong></li><li>The one that wins continues the transfer</li></ul><p>This makes the protocol robust in multi-master environments but slightly complex to implement in firmware.</p><img title="" loading="lazy" decoding="async" class="img  " width="" height="" src="/images/post/protocols/i2c.gif" alt="comp" onerror="this.onerror='null';this.src=''"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="debugging-and-analysis"><strong>Debugging and Analysis</strong></h4><p>I²C can be debugged using:</p><ul><li><p><strong>Logic analyzers</strong>: With I²C protocol decoders to inspect address, R/W, data, and ACK bits</p></li><li><p><strong>Oscilloscopes</strong>: To check waveform timing, pull-up voltage levels, and START/STOP conditions</p></li><li><p>Watch out for:</p><ul><li>Missing ACKs (bad address, bad wiring)</li><li>Stuck SDA/SCL (often due to a crashed device or improper pull-ups)</li><li>Incorrect pull-up resistor values (signal degradation or failure to reach Vcc)</li></ul></li></ul><h4 id="common-use-cases"><strong>Common Use Cases</strong></h4><p>I²C is ideal for connecting<strong>moderately slow devices</strong> to a microcontroller where simplicity and pin efficiency are key:</p><ul><li>Temperature, humidity, pressure sensors</li><li>RTCs (Real-Time Clocks)</li><li>EEPROMs</li><li>GPIO expanders</li><li>OLED displays (lower resolution)</li><li>Low-speed ADCs/DACs</li><li>Power management ICs</li></ul><p>Microcontrollers often have<strong>dedicated I²C hardware modules</strong>, and many system-on-chips expose I²C buses for configuration or control.</p><h4 id="conclusion"><strong>Conclusion</strong></h4><p>I²C is the go-to protocol for<strong>short-range, low-speed communication between chips</strong>, especially when<strong>pin count and simplicity</strong> are important. Its<strong>addressing, shared bus, and clock control features</strong> make it extremely efficient for connecting dozens of devices with just two wires. While it&rsquo;s not designed for high-throughput or time-critical tasks, it excels in environments where convenience and integration matter more than speed.</p>
]]></content:encoded></item><item><title>SPI: Understanding the Serial Peripheral Interface Protocol</title><link>https://mummanajagadeesh.github.io/blog/spi/</link><pubDate>Tue, 01 Apr 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/spi/</guid><description>&lt;![CDATA[<p>SPI is a<strong>synchronous</strong> serial communication protocol designed for<strong>high-speed, full-duplex data exchange</strong> between a master device and one or more peripheral (slave) devices. It was originally developed by Motorola and remains widely adopted in microcontrollers, sensors, memory chips, ADCs/DACs, displays, and more.</p>]]></description><content:encoded>&lt;![CDATA[<p>SPI is a<strong>synchronous</strong> serial communication protocol designed for<strong>high-speed, full-duplex data exchange</strong> between a master device and one or more peripheral (slave) devices. It was originally developed by Motorola and remains widely adopted in microcontrollers, sensors, memory chips, ADCs/DACs, displays, and more.</p><p>Unlike UART, SPI uses a shared clock line, which allows for more precise timing, faster communication, and simpler hardware synchronization.</p><h4 id="fundamental-signal-lines"><strong>Fundamental Signal Lines</strong></h4><p>A typical SPI bus consists of four essential lines:</p><ul><li><strong>SCLK (Serial Clock)</strong> – Generated by the master. Synchronizes data transfer.</li><li><strong>MOSI (Master Out Slave In)</strong> – Data sent from master to slave.</li><li><strong>MISO (Master In Slave Out)</strong> – Data sent from slave to master.</li><li><strong>SS or CS (Slave Select or Chip Select)</strong> – Active-low line used to select individual slave devices.</li></ul><p>In a basic setup, the<strong>master controls the clock</strong> and selects which slave to talk to by asserting its dedicated<strong>CS</strong> line low. All data transmission is<strong>synchronized to the clock signal</strong> generated by the master.</p><h4 id="full-duplex-operation"><strong>Full-Duplex Operation</strong></h4><p>SPI is<strong>inherently full-duplex</strong>, meaning data can be transmitted and received simultaneously. Every clock pulse shifts one bit out on MOSI and one bit in on MISO.</p><p>This also means that<strong>every transmission is bi-directional</strong>, even if you only care about one direction (e.g., writing to a DAC—you still receive bits back, which are usually ignored).</p><h4 id="data-framing-and-configuration-parameters"><strong>Data Framing and Configuration Parameters</strong></h4><p>SPI doesn’t have a fixed data frame like UART. Instead, the configuration is flexible, and both master and slave must be set to agree on several parameters:</p><ul><li><p><strong>Clock Polarity (CPOL)</strong>: Determines the idle state of the clock.</p><ul><li>CPOL = 0: Clock idles low</li><li>CPOL = 1: Clock idles high</li></ul></li><li><p><strong>Clock Phase (CPHA)</strong>: Defines on which clock edge data is sampled.</p><ul><li>CPHA = 0: Data sampled on the first clock edge</li><li>CPHA = 1: Data sampled on the second clock edge</li></ul></li></ul><p>These two parameters define<strong>four SPI modes</strong> (Mode 0 to Mode 3). Master and slave must use the same mode:</p><table><thead><tr><th>Mode</th><th>CPOL</th><th>CPHA</th><th>Clock Idle</th><th>Sample Edge</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>Low</td><td>Rising edge</td></tr><tr><td>1</td><td>0</td><td>1</td><td>Low</td><td>Falling edge</td></tr><tr><td>2</td><td>1</td><td>0</td><td>High</td><td>Falling edge</td></tr><tr><td>3</td><td>1</td><td>1</td><td>High</td><td>Rising edge</td></tr></tbody></table><p>Also configurable:</p><ul><li><strong>Bit Order</strong>: MSB-first (default) or LSB-first</li><li><strong>Word Size</strong>: Usually 8 bits, but 16-bit, 32-bit, or arbitrary-length transfers are possible</li></ul><h4 id="multi-slave-topology"><strong>Multi-Slave Topology</strong></h4><p>SPI supports multiple slaves, but with limitations:</p><ul><li><strong>Independent CS lines</strong>: Each slave must have a dedicated chip-select line from the master. Only one CS line is asserted low at a time.</li><li><strong>Shared MISO/MOSI/SCLK</strong>: All other lines can be shared between devices.</li></ul><p>Alternatives to reduce pin count:</p><ul><li><strong>SPI daisy-chaining</strong>: Used in some chips (e.g., shift registers) where MISO of one device connects to MOSI of the next.</li><li><strong>Multiplexers</strong> or<strong>SPI expanders</strong>: Manage CS lines via GPIO expanders.</li></ul><p>This makes SPI<strong>not truly multi-master or multi-drop</strong>—it&rsquo;s a master-driven protocol with limited scalability in terms of wiring.</p><h4 id="electrical-and-speed-characteristics"><strong>Electrical and Speed Characteristics</strong></h4><ul><li><strong>No fixed electrical standard</strong>: Logic levels depend on devices (e.g., 3.3V, 5V). Always match or level-shift.</li><li><strong>No inherent error checking</strong>: Unlike UART or I2C, SPI has no parity, ACK/NACK, or CRC by default.</li><li><strong>Extremely fast</strong>: Speeds of 1–50+ Mbps are common. Some devices can go beyond 100 MHz.</li></ul><p>Maximum reliable speed depends on:</p><ul><li>Bus capacitance (wiring length)</li><li>PCB layout and impedance matching</li><li>Slave device timing limitations (check datasheets)</li></ul><h4 id="advantages-of-spi"><strong>Advantages of SPI</strong></h4><ul><li><strong>High speed</strong>: Ideal for large data throughput (e.g., sensors, memory, screens)</li><li><strong>Simple hardware</strong>: No addressing or arbitration logic</li><li><strong>Full-duplex</strong>: Allows simultaneous send/receive</li><li><strong>Flexible data word size</strong>: Can send arbitrary-length packets</li><li><strong>No protocol overhead</strong>: Efficient raw data transfer</li></ul><h4 id="limitations"><strong>Limitations</strong></h4><ul><li><strong>No standard device addressing</strong>: Requires separate CS per slave or custom protocol</li><li><strong>No error detection or correction</strong>: Needs to be implemented at the application layer</li><li><strong>Requires more wires</strong>: 4 signals minimum, plus extra CS lines for more slaves</li><li><strong>Single master only (in most practical implementations)</strong></li></ul><h4 id="flow-control-and-interrupts"><strong>Flow Control and Interrupts</strong></h4><p>SPI typically does<strong>not use flow control</strong>. The master initiates all communication and must ensure that:</p><ul><li>The slave is ready (by polling a READY pin or delay)</li><li>Data is handled fast enough (especially for high-speed transfers)</li></ul><p>Slaves may offer:</p><ul><li><strong>READY/BUSY lines</strong>: Optional GPIO used by the slave to signal status</li><li><strong>DMA support</strong>: Offloads high-speed SPI to memory without CPU intervention</li></ul><img title="" loading="lazy" decoding="async" class="img  " width="" height="" src="/images/post/protocols/spi.gif" alt="comp" onerror="this.onerror='null';this.src=''"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="applications-and-use-cases"><strong>Applications and Use Cases</strong></h4><p>SPI is preferred when<strong>speed and efficiency are key</strong>. Typical applications include:</p><ul><li>Flash memory chips (e.g., NOR, NAND)</li><li>SD cards (in SPI mode)</li><li>LCD/OLED display modules</li><li>High-speed ADCs and DACs</li><li>Real-time sensors (gyroscopes, accelerometers)</li><li>Audio CODECs (I2S is a variant of SPI)</li></ul><p>Many sensors come in both SPI and I2C versions, letting designers choose between higher performance (SPI) or fewer wires (I2C).</p><h4 id="debugging-spi"><strong>Debugging SPI</strong></h4><p>Debugging SPI can be trickier than UART because it’s clocked and often involves multiple devices. Use:</p><ul><li><p><strong>Logic analyzers</strong> (Saleae, Logic Pro) to decode SPI frames</p></li><li><p><strong>Oscilloscopes</strong> to confirm proper edge alignment (especially CPOL/CPHA)</p></li><li><p>Check for:</p><ul><li>Misconfigured SPI mode</li><li>Incorrect bit order</li><li>Bad CS handling (glitches, multiple CS active)</li><li>Slave not responding (often a sign of CS or mode mismatch)</li></ul></li></ul><h4 id="conclusion"><strong>Conclusion</strong></h4><p>SPI is a powerful and versatile protocol, especially when speed, simplicity, and full-duplex operation are required. Though it doesn’t scale well in large multi-device systems and lacks built-in error checking, its deterministic timing, low protocol overhead, and wide support make it an essential tool in any embedded engineer’s arsenal.</p><p>Whether you&rsquo;re streaming data to a display, reading high-speed sensors, or managing memory chips, SPI provides a direct and efficient path for raw, fast communication.</p>
]]></content:encoded></item><item><title>UART: A Detailed Overview of Asynchronous Serial Communication</title><link>https://mummanajagadeesh.github.io/blog/uart/</link><pubDate>Thu, 27 Mar 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/uart/</guid><description>&lt;![CDATA[<p>UART is one of the oldest and most fundamental methods of serial communication in embedded systems. As its name suggests, it operates asynchronously, meaning<strong>there is no shared clock signal</strong> between the transmitter and the receiver. This makes UART especially attractive in scenarios where simplicity and minimal wiring are important.</p>]]></description><content:encoded>&lt;![CDATA[<p>UART is one of the oldest and most fundamental methods of serial communication in embedded systems. As its name suggests, it operates asynchronously, meaning<strong>there is no shared clock signal</strong> between the transmitter and the receiver. This makes UART especially attractive in scenarios where simplicity and minimal wiring are important.</p><h4 id="fundamental-concept"><strong>Fundamental Concept</strong></h4><p>In a UART communication system, data is transmitted<strong>serially</strong>, bit by bit, over a single wire (TX), and received on another (RX). Each device in the communication link has its own<strong>internal clock</strong>, and both must agree on a<strong>common baud rate</strong> (bits per second). Because there’s no external clock signal, this baud rate agreement is critical—if either side drifts too much, communication breaks down.</p><h4 id="data-framing-structure"><strong>Data Framing Structure</strong></h4><p>Every UART frame consists of several components to delimit and validate the transmission:</p><ul><li><strong>Start bit</strong> – Marks the beginning of a data frame. It&rsquo;s always a<strong>logic 0</strong> (low).</li><li><strong>Data bits</strong> – Typically 5 to 9 bits, though 8 bits is most common. Sent LSB-first.</li><li><strong>Optional parity bit</strong> – Used for rudimentary error checking (even or odd parity).</li><li><strong>Stop bit(s)</strong> – One or more bits of<strong>logic 1</strong> (high) to signal the end of the frame.</li></ul><p>A typical 8-N-1 UART frame (8 data bits, no parity, 1 stop bit) looks like this:</p><pre tabindex="0"><code>Line Idle: HIGH
↓
Start Bit (0) → [D0 D1 D2 D3 D4 D5 D6 D7] → Stop Bit (1)</code></pre><p>During idle periods (no transmission), the line remains at logic high.</p><h4 id="baud-rate-and-timing-constraints"><strong>Baud Rate and Timing Constraints</strong></h4><p>Since UART is asynchronous, both ends must know the<strong>exact baud rate</strong>—for example, 9600, 115200, or even up to a few Mbps depending on hardware. A mismatch in baud rate beyond ~2-3% can lead to framing errors.</p><p>For example, at 9600 baud:</p><ul><li>Each bit lasts ~104.17 microseconds.</li><li>A full 10-bit frame (start + 8 data + stop) takes ~1.04 ms.</li></ul><p>UART receivers usually<strong>oversample</strong> the incoming data line (commonly at 16× the baud rate) to detect the start bit and sample data bits at the correct time.</p><h4 id="error-detection-and-robustness"><strong>Error Detection and Robustness</strong></h4><p>UART includes minimal error handling:</p><ul><li><strong>Parity Bit</strong> (optional): Basic check for single-bit error detection.</li><li><strong>Framing Error</strong>: If the stop bit isn&rsquo;t logic high at the expected time.</li><li><strong>Overrun Error</strong>: If the receiver buffer isn’t read fast enough and gets overwritten.</li><li><strong>Break Condition</strong>: If the line is held low for longer than a full frame—used to signal an intentional interruption.</li></ul><p>Due to the lack of built-in CRC or acknowledgment schemes, higher-layer protocols (like Modbus, NMEA, or custom ones) often wrap UART transmissions with additional error-checking logic.</p><h4 id="flow-control-mechanisms"><strong>Flow Control Mechanisms</strong></h4><p>When sending variable-sized or fast streams of data, there&rsquo;s a risk of<strong>buffer overflow</strong>. To mitigate this:</p><ul><li><strong>Software Flow Control</strong>: Special characters like XON (0x11) and XOFF (0x13) are sent to pause/resume transmission.</li><li><strong>Hardware Flow Control</strong>: Uses additional lines like RTS (Request to Send) and CTS (Clear to Send) for handshake.</li></ul><p>These features are not part of the UART standard itself but are often implemented by UART peripherals or bridges (e.g., USB-to-UART chips).</p><h4 id="electrical-characteristics"><strong>Electrical Characteristics</strong></h4><p>UART is purely a signaling protocol—it doesn’t define voltage levels. Typical implementations use:</p><ul><li><strong>TTL logic levels</strong>: 0V (low), 5V or 3.3V (high)</li><li><strong>RS-232</strong>: ±12V for signaling (used in PCs, legacy serial ports)</li></ul><p>Make sure voltage levels match between devices or use level shifters to avoid damage.</p><h4 id="topology-and-limitations"><strong>Topology and Limitations</strong></h4><p>UART supports<strong>only point-to-point communication</strong>. You cannot have more than two devices on the same TX/RX lines without a multiplexer or external logic.</p><p>This makes UART unsuitable for multi-device networks unless augmented with switches, hubs, or protocol conversion (e.g., UART-to-I2C/SPI bridges or USB).</p><h4 id="buffering-and-interrupts"><strong>Buffering and Interrupts</strong></h4><p>Most modern microcontrollers include a UART peripheral with internal<strong>FIFO buffers</strong> (commonly 16, 32, or 64 bytes). This allows temporary storage of incoming/outgoing bytes to decouple hardware timing from software response.</p><p>Reception can be handled via:</p><ul><li><strong>Polling</strong> – CPU actively checks status register</li><li><strong>Interrupts</strong> – ISR is triggered when data is received</li><li><strong>DMA (Direct Memory Access)</strong> – High-speed, CPU-independent transfer</li></ul><img title="" loading="lazy" decoding="async" class="img  " width="" height="" src="/images/post/protocols/uart.gif" alt="comp" onerror="this.onerror='null';this.src=''"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="applications-and-use-cases"><strong>Applications and Use Cases</strong></h4><p>UART is used everywhere, especially in scenarios where:</p><ul><li><p>Only two devices need to communicate</p></li><li><p>Simple, low-speed data exchange is sufficient</p></li><li><p>Debugging via serial terminals (e.g.,<code>printf</code> over UART)</p></li><li><p>Communication with modules like:</p><ul><li>GPS receivers</li><li>GSM modems</li><li>Bluetooth (e.g., HC-05)</li><li>Serial LCDs or displays</li><li>USB-to-serial bridges (e.g., FT232, CH340)</li></ul></li></ul><h4 id="typical-baud-rates-and-limitations"><strong>Typical Baud Rates and Limitations</strong></h4><table><thead><tr><th>Common Baud Rates</th><th>Notes</th></tr></thead><tbody><tr><td>9600</td><td>Very common, reliable</td></tr><tr><td>38400</td><td>Used in some industrial devices</td></tr><tr><td>115200</td><td>Common for debugging/logging</td></tr><tr><td>1 Mbps+</td><td>Achievable on high-performance MCUs</td></tr></tbody></table><p>The upper limit depends on:</p><ul><li>Clock accuracy</li><li>Signal integrity (cable length, crosstalk)</li><li>Peripheral and driver capability</li></ul><h4 id="debugging-uart"><strong>Debugging UART</strong></h4><p>Troubleshooting UART issues often involves:</p><ul><li>Checking baud rate configuration (both sides must match)</li><li>Monitoring line using an oscilloscope or logic analyzer</li><li>Using tools like PuTTY, minicom, or serial monitor in IDEs</li><li>Verifying no framing or parity errors</li><li>Ensuring buffers aren’t overflowing (especially on RX)</li></ul><h4 id="conclusion"><strong>Conclusion</strong></h4><p>UART is simple, efficient, and nearly universal. Its asynchronous nature makes it easy to use with just two wires, but that simplicity comes at the cost of scalability and robustness. While not ideal for high-speed or multi-device communication, it remains indispensable for low-complexity, point-to-point data exchange.</p><p>Whether you&rsquo;re printing debug logs or interfacing with legacy peripherals, understanding UART deeply is foundational for any embedded system designer.</p>
]]></content:encoded></item><item><title>Demystifying UART, SPI, and I2C: Communication Between Chips</title><link>https://mummanajagadeesh.github.io/blog/communication-between-chips/</link><pubDate>Mon, 24 Mar 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/communication-between-chips/</guid><description>&lt;![CDATA[<p>In both VLSI design and embedded systems, no chip operates in isolation. Whether it&rsquo;s a microcontroller interfacing with sensors, a processor communicating with memory modules, or multiple peripherals synchronizing data,<strong>inter-chip communication</strong> is fundamental to building reliable and scalable hardware systems.</p>]]></description><content:encoded>&lt;![CDATA[<p>In both VLSI design and embedded systems, no chip operates in isolation. Whether it&rsquo;s a microcontroller interfacing with sensors, a processor communicating with memory modules, or multiple peripherals synchronizing data,<strong>inter-chip communication</strong> is fundamental to building reliable and scalable hardware systems.</p><p>As systems grow in complexity, so does the demand for<strong>structured, efficient, and purpose-fit communication protocols</strong>. Direct parallel connections are rarely feasible due to board space, pin limitations, and synchronization challenges. Instead, designers turn to well-established<strong>serial communication standards</strong> that enable devices to exchange data with minimal wiring and clear electrical and timing definitions.</p><p>Three of the most widely used protocols for such tasks are:</p><ul><li><strong>UART (Universal Asynchronous Receiver/Transmitter)</strong></li><li><strong>SPI (Serial Peripheral Interface)</strong></li><li><strong>I²C (Inter-Integrated Circuit)</strong></li></ul><p>Each of these protocols is optimized for different trade-offs—speed, simplicity, scalability, and wiring complexity—making them suited for specific use cases in VLSI blocks, SoCs, microcontroller boards, and embedded devices.</p><hr><h4 id="brief-overview-of-the-protocols"><strong>Brief Overview of the Protocols</strong></h4><h5 id="uart--universal-asynchronous-receivertransmitter"><strong>UART – Universal Asynchronous Receiver/Transmitter</strong></h5><p>UART is a<strong>point-to-point, asynchronous</strong> serial protocol used to transmit data without needing a clock line. Instead, both devices agree on a<strong>predefined baud rate</strong>. Communication occurs over two lines:<strong>TX (transmit)</strong> and<strong>RX (receive)</strong>.</p><p>It&rsquo;s widely used for<strong>debugging, console communication, and bootloaders</strong>, especially when simplicity and human-readable interfaces (e.g., serial terminals) are priorities. Since it doesn&rsquo;t support addressing or multiple devices, it&rsquo;s typically used for direct, one-to-one communication.</p><h5 id="spi--serial-peripheral-interface"><strong>SPI – Serial Peripheral Interface</strong></h5><p>SPI is a<strong>synchronous, full-duplex</strong> protocol that uses<strong>four wires</strong> in its standard configuration:<strong>MOSI, MISO, SCLK</strong>, and<strong>CS (Chip Select)</strong>. Data is clocked simultaneously in both directions, allowing high-speed transfers.</p><p>SPI is ideal when<strong>speed and performance</strong> matter—common in display drivers, flash memory, ADCs/DACs, and high-throughput sensors. It supports multiple slaves but requires a separate chip-select line for each, which can limit scalability.</p><h5 id="ic--inter-integrated-circuit"><strong>I²C – Inter-Integrated Circuit</strong></h5><p>I²C is a<strong>synchronous, half-duplex</strong> protocol that operates on just<strong>two wires</strong>:<strong>SDA (data)</strong> and<strong>SCL (clock)</strong>. It allows for<strong>multi-master and multi-slave</strong> communication, where each device has a unique address.</p><p>I²C is favored for<strong>connecting multiple low-speed peripherals</strong>, such as sensors, EEPROMs, and configuration ICs, particularly when board space and wiring simplicity are critical. Its slower speeds and shared bus make it less ideal for high-volume data transfer but excellent for control applications.</p><hr><h4 id="protocol-comparison-at-a-glance"><strong>Protocol Comparison at a Glance</strong></h4><table><thead><tr><th>Feature</th><th>UART</th><th>SPI</th><th>I²C</th></tr></thead><tbody><tr><td>Communication Type</td><td>Asynchronous, full-duplex</td><td>Synchronous, full-duplex</td><td>Synchronous, half-duplex</td></tr><tr><td>Wires Required</td><td>2 (TX, RX)</td><td>4 (MOSI, MISO, SCLK, CS)</td><td>2 (SDA, SCL)</td></tr><tr><td>Multi-Device Support</td><td>No</td><td>Yes (via multiple CS lines)</td><td>Yes (via addressing)</td></tr><tr><td>Speed</td><td>Moderate (depends on baud rate)</td><td>Very High (10s of MHz)</td><td>Low to Moderate (up to ~3.4 MHz)</td></tr><tr><td>Complexity</td><td>Low</td><td>Medium</td><td>Medium-High (due to addressing and arbitration)</td></tr><tr><td>Best For</td><td>Debugging, serial logging</td><td>High-speed sensors, memory</td><td>Low-speed sensors, config ICs</td></tr><tr><td>Flow Control</td><td>Optional (hardware/software)</td><td>Master controlled</td><td>Clock stretching by slave</td></tr><tr><td>Hardware Requirement</td><td>UART peripheral</td><td>SPI controller</td><td>I²C controller with open-drain pins</td></tr></tbody></table><hr><img title="" loading="lazy" decoding="async" class="img  " width="" height="" src="/images/post/protocols/comp.gif" alt="comp" onerror="this.onerror='null';this.src=''"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><hr><h4 id="which-one-should-you-use"><strong>Which One Should You Use?</strong></h4><p>The choice of protocol depends on system constraints:</p><ul><li>Use<strong>UART</strong> when you need<strong>simple, direct communication</strong>, especially for console output or single peripheral interfaces.</li><li>Use<strong>SPI</strong> for<strong>high-speed communication</strong> with a<strong>small number of peripherals</strong> that demand fast response or large data transfer volumes.</li><li>Use<strong>I²C</strong> when you need to connect<strong>multiple peripherals</strong> with minimal wiring and<strong>address-based access</strong>, especially in sensor arrays and configuration-heavy devices.</li></ul><hr><blockquote><p>In the sections that follow, we’ll explore each protocol in<strong>technical depth</strong>—from electrical characteristics and signal timing to addressing, framing, and typical use cases. The goal is to not just describe them, but to understand<strong>why</strong> each behaves the way it does, and<strong>how</strong> to integrate them correctly into real-world systems.</p></blockquote><p>Stay tuned for the deep dives on<strong>UART</strong>,<strong>SPI</strong>, and<strong>I²C</strong>.</p><hr>
]]></content:encoded></item><item><title>Kociemba’s Algorithm – The Two-Phase Breakthrough #PID1.5</title><link>https://mummanajagadeesh.github.io/blog/kociembas-alg-the-2-phase-breakthrough/</link><pubDate>Tue, 18 Mar 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/kociembas-alg-the-2-phase-breakthrough/</guid><description>&lt;![CDATA[<p>Kociemba’s algorithm revolutionizes Rubik’s Cube solving by efficiently navigating the immense complexity of the cube’s state space using advanced mathematical tools from<strong>group theory</strong> and<strong>heuristic search</strong>. This two-phase method strikes a balance between<strong>tractability</strong> and<strong>optimality</strong>, making it a cornerstone of computational puzzle solving.</p>]]></description><content:encoded>&lt;![CDATA[<p>Kociemba’s algorithm revolutionizes Rubik’s Cube solving by efficiently navigating the immense complexity of the cube’s state space using advanced mathematical tools from<strong>group theory</strong> and<strong>heuristic search</strong>. This two-phase method strikes a balance between<strong>tractability</strong> and<strong>optimality</strong>, making it a cornerstone of computational puzzle solving.</p><h4 id="the-mathematical-setup-group-theory-and-cosets">The Mathematical Setup: Group Theory and Cosets</h4><p>Recall that the Rubik’s Cube group (G) consists of all legal cube states under composition of moves. Kociemba’s method strategically divides (G) into<strong>cosets</strong> of a carefully chosen subgroup (H \subseteq G):</p><p>$$
G = \bigcup_{g \in G/H} gH
$$</p><p>Here, (H) is the subgroup of cube states where all edges and corners are<strong>oriented correctly</strong> and all middle slice edges are located within the middle layer. This subgroup is sometimes called the<strong>&ldquo;half-turn metric group&rdquo;</strong>, since allowed moves in (H) correspond to half-turns of certain faces.</p><p>By reducing the problem to first finding the coset representative (g) that brings the cube into (H) (Phase 1), and then solving within (H) (Phase 2), the algorithm exploits the<strong>quotient structure</strong> (G/H) to manage complexity.</p><h4 id="phase-1-reducing-to-the-subgroup-h">Phase 1: Reducing to the Subgroup (H)</h4><p>Phase 1’s goal is to transform any scrambled cube state (s \in G) into a state (s&rsquo; \in H) . Formally, find a sequence of moves (m_1) such that:</p><p>$$
s&rsquo; = m_1 \cdot s \in H
$$</p><p>Where (m_1) is a product of face turns (quarter or half turns).</p><ul><li><strong>Edge orientation:</strong> Each edge can be in two states — oriented or flipped — giving a binary invariant. There are (2^{12} = 4096) possible edge orientation states.</li><li><strong>Corner orientation:</strong> Each corner can be oriented in 3 ways, so (3^8 = 6561) corner orientations.</li><li><strong>Middle slice edges:</strong> The position of the four middle-layer edges is constrained.</li></ul><p>All these constraints define (H) , which contains approximately (10^{10}) states.</p><p>Phase 1’s problem reduces to finding a minimal-length (m_1) to reach (H) , which is a<strong>constrained subgroup problem</strong> in the Rubik’s cube group.</p><h4 id="phase-2-solving-within-h">Phase 2: Solving within (H)</h4><p>Once the cube is in (H) , Phase 2 searches for a move sequence (m_2) restricted to moves within (H) such that:</p><p>$$
m_2 \cdot s&rsquo; = I
$$</p><p>where (I) is the solved state.</p><p>Since moves in (H) preserve edge and corner orientation and slice position, the search space is drastically smaller than the full (G) .</p><h4 id="heuristics-and-pattern-databases-guiding-the-search">Heuristics and Pattern Databases: Guiding the Search</h4><p>Direct brute-force search over (G) or even (H) is impossible due to the astronomical number of states. To tackle this, Kociemba’s algorithm employs<strong>heuristic search algorithms</strong> — specifically,<strong>Iterative Deepening A* (IDA*)</strong> — powered by<strong>pattern databases</strong> (PDBs).</p><h5 id="what-are-pattern-databases">What are Pattern Databases?</h5><p>PDBs are<strong>precomputed lookup tables</strong> storing the exact minimal number of moves required to solve specific cube features, such as edge orientation or corner permutation, ignoring other features.</p><p>For example, one PDB might store the minimal moves to solve edge orientation, regardless of corner orientation or permutation.</p><p>Since these databases cover<strong>disjoint subsets of the cube’s state</strong>, their heuristic values can be combined by taking the<strong>maximum</strong> to ensure admissibility (never overestimating).</p><p>This maximum value guides IDA* to explore only states promising to be close to the solution, pruning vast regions of the search space.</p><h5 id="ida-search-algorithm">IDA* Search Algorithm</h5><p>IDA* is a memory-efficient variant of A* that performs depth-first searches with increasing cost thresholds.</p><p>At each iteration:</p><ul><li><p>The search depth limit is set by the heuristic cost (f = g + h) , where:</p><ul><li>(g) = cost from start to current node (number of moves so far)</li><li>(h) = heuristic estimate of moves to goal (from PDB)</li></ul></li><li><p>The algorithm explores all nodes with (f \leq) threshold.</p></li><li><p>If no solution found, threshold increases, and search repeats.</p></li></ul><p>IDA*’s use in Kociemba’s algorithm ensures that:</p><ul><li>The first solution found is<strong>guaranteed to be minimal</strong> within the move restrictions.</li><li>Memory overhead remains manageable, even for large state spaces.</li></ul><h4 id="formalizing-the-heuristic-function">Formalizing the Heuristic Function</h4><p>If we define heuristic functions:</p><ul><li>(h_{EO}(s)): minimal moves to solve edge orientation in state (s)</li><li>(h_{CO}(s)): minimal moves to solve corner orientation</li><li>(h_{EP}(s)): minimal moves to place edges in their correct slices</li><li>(h_{CP}(s)): minimal moves to permute corners correctly</li></ul><p>Then the combined heuristic (h(s)) guiding the search is:</p><p>$$
h(s) = \max { h_{EO}(s), h_{CO}(s), h_{EP}(s), h_{CP}(s) }
$$</p><p>This ensures the search never expands nodes that cannot lead to an optimal solution.</p><h4 id="summary-of-the-mathematical-power">Summary of the Mathematical Power</h4><p>Kociemba’s algorithm elegantly balances:</p><ul><li><strong>Algebraic structure</strong>: Using subgroup and coset decompositions to reduce complexity</li><li><strong>Heuristic efficiency</strong>: Pattern databases provide admissible heuristics guiding the search</li><li><strong>Search algorithm</strong>: IDA* ensures optimal paths under given constraints</li></ul><p>This synergy enables the solver to consistently find solutions averaging around 20 moves (half the move length of Thistlethwaite’s original algorithm) in milliseconds on modern computers — a feat that would be impossible without this deep mathematical foundation.</p><h3 id="other-algorithms-a-brief-overview-and-comparison">Other Algorithms: A Brief Overview and Comparison</h3><p>While Kociemba’s algorithm is among the most widely used for computational Rubik’s Cube solving due to its efficiency and near-optimal solutions, it is part of a broader landscape of methods, each with its own mathematical basis, advantages, and limitations.</p><h4 id="thistlethwaites-algorithm-revisited">Thistlethwaite’s Algorithm Revisited</h4><p>As discussed earlier, Thistlethwaite’s algorithm partitions the cube group into a sequence of four nested subgroups:</p><p>$$
G = G_0 \supset G_1 \supset G_2 \supset G_3 \supset G_4 = { I }
$$</p><p>By solving the cube progressively through these subgroups, it guarantees a solution in at most 52 moves (in half-turn metric). While theoretically elegant, the multiple phases and larger intermediate state spaces make it computationally heavier compared to Kociemba’s two-phase approach.</p><h4 id="gods-algorithm">God&rsquo;s Algorithm</h4><p><strong>God’s Algorithm</strong> is the theoretical ideal that always finds the<strong>shortest possible solution</strong> for any cube position. It relies on exhaustive search of the entire state space ((\approx 4.3 \times 10^{19}) states) using massive computational resources and precomputed tables, such as the famous<strong>Table of 20 moves or less</strong> (God’s Number = 20).</p><p>While this guarantees the absolute shortest solution, it is impractical for general use due to storage and computation demands. Kociemba’s algorithm often approximates God’s Algorithm efficiently by using heuristics and subgroup constraints.</p><h4 id="cfop-fridrich-method">CFOP (Fridrich Method)</h4><p>On the practical speedcubing side,<strong>CFOP (Cross, F2L, OLL, PLL)</strong> is a human method rather than a computer algorithm. It relies on heuristic algorithms and pattern recognition rather than exhaustive search or mathematical group theory. While CFOP solves the cube very fast for humans, its move counts tend to be longer and less optimized compared to computational methods like Kociemba’s.</p><h4 id="other-computational-approaches">Other Computational Approaches</h4><ul><li><strong>Korf’s Algorithm:</strong> Utilizes IDA* with large pattern databases for optimal solutions but is computationally expensive.</li><li><strong>Macro-Operators and Pruning Tables:</strong> Many solvers employ precomputed tables for specific cube configurations or use machine learning to predict move sequences.</li><li><strong>Genetic Algorithms and AI:</strong> Recent work explores reinforcement learning and evolutionary strategies to solve cubes without explicit group theory, focusing on policy learning and move prediction.</li></ul><h4 id="comparison-summary">Comparison Summary</h4><table><thead><tr><th>Algorithm</th><th>Move Optimality</th><th>Computational Complexity</th><th>Use Case</th></tr></thead><tbody><tr><td>God’s Algorithm</td><td>Guaranteed minimal</td><td>Very high</td><td>Theoretical, research</td></tr><tr><td>Kociemba’s Algorithm</td><td>Near-optimal (~20 moves)</td><td>Moderate</td><td>Fast, practical solvers</td></tr><tr><td>Thistlethwaite’s</td><td>Moderate (~52 moves max)</td><td>Higher</td><td>Theoretical, educational</td></tr><tr><td>CFOP</td><td>Longer (~50+ moves)</td><td>Low</td><td>Human speedcubing</td></tr><tr><td>Korf’s Algorithm</td><td>Optimal</td><td>Very high</td><td>Small subsets or specific puzzles</td></tr></tbody></table><h4 id="final-thoughts">Final Thoughts</h4><p>The mathematical sophistication of Rubik’s Cube algorithms reveals how computers transform the art of puzzle-solving. From the elegant subgroup decompositions of Thistlethwaite and Kociemba to heuristic-guided searches, computers convert what once was a purely human trial-and-error activity into a rigorous, near-optimal science.</p><p>Understanding these algorithms highlights the power of:</p><ul><li><strong>Algebraic abstractions</strong> (groups, cosets) to simplify complex states</li><li><strong>Heuristic functions</strong> to efficiently guide searches</li><li><strong>Iterative search algorithms</strong> that balance time and space constraints</li></ul><p>In the next post, we will delve deeper into practical implementations of Kociemba’s algorithm and how modern solvers leverage these concepts to provide instant solutions.</p>
]]></content:encoded></item><item><title>How Do Computers Come into the Art of Solving Puzzles? #PID1.4</title><link>https://mummanajagadeesh.github.io/blog/computers-in-the-art-of-solving-puzzles/</link><pubDate>Fri, 07 Mar 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/computers-in-the-art-of-solving-puzzles/</guid><description>&lt;![CDATA[<p>Throughout history, puzzles have intrigued the human mind, not merely for entertainment but for the challenge they pose to logic, creativity, and persistence. From ancient labyrinths to Sudoku and the Rubik’s Cube, solving a puzzle often feels like an art — but beneath that art lies a surprising amount of structure. And where there is structure, computers can often outperform intuition.</p>]]></description><content:encoded>&lt;![CDATA[<p>Throughout history, puzzles have intrigued the human mind, not merely for entertainment but for the challenge they pose to logic, creativity, and persistence. From ancient labyrinths to Sudoku and the Rubik’s Cube, solving a puzzle often feels like an art — but beneath that art lies a surprising amount of structure. And where there is structure, computers can often outperform intuition.</p><p>At their core, puzzles are<strong>problems with constraints</strong>, and solving them requires a systematic approach to navigating possibilities. This is precisely the realm where computers shine. Unlike humans, computers are not limited by short-term memory, fatigue, or bias. They can execute algorithms tirelessly, evaluate vast search spaces, and spot patterns at a scale impossible for the human brain. As a result, computers don’t just mimic human puzzle-solving — they fundamentally transform it.</p><h6 id="why-the-rubiks-cube">Why the Rubik’s Cube?</h6><p>Among all puzzles, the<strong>Rubik’s Cube</strong> has emerged as a particularly fascinating object of study in computer science, mathematics, and algorithm design. Invented in 1974 by Ernő Rubik, it has over<strong>43 quintillion</strong> unique configurations (43,252,003,274,489,856,000 to be exact). That’s more than the number of grains of sand on Earth or seconds since the Big Bang. And yet, with the right approach, any configuration can be solved in<strong>20 moves or fewer</strong> — a result known as<em>God’s Number</em>.</p><p>But how does one go from a jumbled cube to the solution in such a short number of moves, especially when the total number of configurations is so massive?</p><p>This is where the<strong>mathematical beauty of the cube</strong> comes into play.</p><h6 id="the-mathematics-behind-the-cube">The Mathematics Behind the Cube</h6><p>To a computer scientist or a mathematician, the Rubik’s Cube is more than just a toy — it&rsquo;s a<strong>group</strong>. In group theory (a branch of abstract algebra), we define a group as a set with an operation that satisfies certain axioms: closure, associativity, identity, and inverses. Each move you make on a Rubik’s Cube — whether it’s a quarter-turn of a face or a full rotation — corresponds to an operation in this group.</p><p>The entire set of all possible cube states forms a<strong>permutation group</strong>. More specifically, it&rsquo;s a subgroup of the<strong>symmetric group</strong> on the cube’s stickers, where each legal operation is a permutation of the cube’s pieces. The solved state is the group’s identity element, and solving the cube is equivalent to finding the<strong>inverse sequence of moves</strong> that returns any configuration to this identity.</p><p>From a computational perspective, this means that solving the cube becomes a<strong>path-finding problem in a highly structured space</strong>. The “nodes” are the cube states, and the “edges” are the moves that transform one state into another.</p><p>But this graph of states is unimaginably vast — far too large for brute force to be practical. Even if a computer could check a billion configurations per second, it would still take centuries to exhaustively search all 43 quintillion. Clearly, we need something smarter.</p><h4 id="why-brute-force-fails--and-algorithms-succeed">Why Brute Force Fails — and Algorithms Succeed</h4><p>Imagine trying to solve the cube purely by random moves — it would be virtually impossible to land on the solved state, even in a lifetime. Even a depth-limited brute-force search, where the computer tries all sequences up to, say, 20 moves, quickly becomes intractable. At 18 legal face turns per move and 20 moves deep, that’s 18²⁰ ≈ 10²⁵ possibilities — still far beyond what any computer can handle.</p><p>That’s why we need<strong>algorithms</strong>. Algorithms introduce structure, allowing us to<strong>prune</strong> the search space intelligently. They leverage mathematical symmetries, identify key cube properties (like orientation, permutation, and parity), and break the problem into smaller, tractable sub-problems.</p><p>Rather than treating all configurations as equal, a good algorithm guides the computer through the space more like a mountaineer scaling peaks via well-worn trails rather than hacking blindly through a jungle.</p><h4 id="what-computers-bring-to-puzzle-solving">What Computers Bring to Puzzle Solving</h4><p>So why are computers particularly well-suited to this domain?</p><ul><li><strong>Speed</strong>: Computers can simulate millions of cube manipulations per second.</li><li><strong>Memory</strong>: They can store large lookup tables — precomputed solutions to subproblems.</li><li><strong>Exhaustiveness</strong>: They don’t get bored or distracted; they follow through every branch of a search tree.</li><li><strong>Precision</strong>: No errors, no forgetfulness. Every move is logical, every decision traceable.</li></ul><p>These strengths allow computers not only to solve the Rubik’s Cube but to solve it optimally — finding the shortest or most efficient solution using<strong>algorithmic planning</strong>.</p><h4 id="from-human-intuition-to-mathematical-algorithms">From Human Intuition to Mathematical Algorithms</h4><p>Before computers entered the scene, cube-solving was based largely on<strong>heuristics</strong> — trial-and-error, memorized sequences, and intuition. Speedcubers developed methods that worked well in practice but didn’t guarantee minimal solutions. It was the introduction of<strong>mathematical algorithms</strong> that changed the landscape.</p><p>The first major breakthrough came in the form of<strong>Thistlethwaite’s algorithm</strong> in the 1980s. It introduced the idea of reducing the cube&rsquo;s complexity gradually by defining nested subgroups. From there, even more optimized approaches like<strong>Kociemba’s algorithm</strong> emerged, leveraging symmetries and lookup tables to reduce average solutions to around 20 moves.</p><p>Each of these algorithms doesn’t just find<em>a</em> solution — they exploit the cube’s algebraic structure to find<strong>efficient, systematic</strong> paths through its vast configuration space.</p><h3 id="thistlethwaites-algorithm--from-chaos-to-structure">Thistlethwaite’s Algorithm – From Chaos to Structure</h3><p>By the early 1980s, the Rubik’s Cube had become a global phenomenon — and a challenge that captivated not only hobbyists but also mathematicians. One such mind was<strong>Morwen Thistlethwaite</strong>, a mathematician who, in 1981, proposed one of the first major algorithmic breakthroughs in cube solving. His approach laid the foundation for many of the advanced solvers used today — not by brute force, but by applying the elegant machinery of<strong>group theory</strong>.</p><p>At its core, Thistlethwaite’s method turns the Rubik’s Cube into a layered mathematical structure — reducing the problem not in one step, but through a sequence of increasingly constrained subproblems. Each stage progressively shrinks the space of possible cube states, leveraging<strong>nested subgroups</strong> to transform an otherwise intractable problem into one that can be solved efficiently.</p><h4 id="modeling-the-cube-as-a-group">Modeling the Cube as a Group</h4><p>To understand Thistlethwaite’s insight, we first need to recognize how the cube operates in algebraic terms.</p><p>Every legal move on a Rubik’s Cube can be considered a<strong>group generator</strong> — a function that permutes the pieces of the cube. The entire collection of these permutations forms a<strong>group G</strong> under function composition. This group is known as the<strong>Rubik&rsquo;s Cube group</strong>, and it contains all 43 quintillion possible cube states.</p><p>Mathematically, a group (G) can be described by a<strong>presentation</strong> — a set of generators (moves) and relations (how these moves interact). In the cube&rsquo;s case, common generators might include:</p><ul><li>(U): rotate the upper face 90° clockwise</li><li>(R): rotate the right face 90° clockwise</li><li>(F): front face, and so on</li></ul><p>From just these generators and their inverses, all cube states can be reached.</p><h4 id="the-key-insight-subgroup-reduction">The Key Insight: Subgroup Reduction</h4><p>Thistlethwaite’s key insight was to<strong>partition the problem</strong> of solving the cube into a<strong>sequence of four nested subgroups</strong>:</p><p>$$
G_0 \supset G_1 \supset G_2 \supset G_3 \supset G_4 = { I }
$$</p><p>Where:</p><ul><li>(G_0): the full cube group (all states)</li><li>(G_1): subgroup where edge orientations are correct</li><li>(G_2): subgroup where corners are also oriented</li><li>(G_3): subgroup where all pieces are in correct slice layers</li><li>(G_4): the identity group — the solved state</li></ul><p>Each subgroup (G_{i+1}) is a<strong>proper subgroup</strong> of (G_i), meaning it contains fewer states, but is still closed under certain restricted moves.</p><p>For example:</p><ul><li>To move from (G_0)to (G_1), we only use moves that don&rsquo;t disturb solved edge orientations.</li><li>From (G_1) to (G_2), we constrain the move set further to preserve both edge and corner orientations.</li></ul><p>By progressing through these subgroups, the algorithm ensures that with each phase, the cube becomes increasingly constrained — gradually forcing it into a state where the solution becomes trivial.</p><h4 id="phase-by-phase-breakdown">Phase-by-Phase Breakdown</h4><p>Let’s briefly outline the four phases of Thistlethwaite’s algorithm:</p><h6 id="phase-1-reduction-to-g_1">Phase 1: Reduction to (G_1)</h6><p>Objective: Correct the<strong>orientation of all 12 edges</strong>.</p><ul><li>Move set allowed: all face turns</li><li>Edge orientation is a<strong>binary invariant</strong> (flipped or not)</li><li>The space of states reduces from ~(4.3 \times 10^{19}) to about (10^9)</li></ul><h6 id="phase-2-reduction-to-g_2">Phase 2: Reduction to (G_2)</h6><p>Objective: Correct the<strong>orientation of corners</strong> and place all edges in their<strong>correct slice layers</strong> (middle or outer).</p><ul><li>Move set restricted to half-turns on some faces (e.g., only U, D, R2, L2, F2, B2)</li><li>Corner orientation: 3 values per corner (0°, 120°, 240°)</li><li>State space drops to ~(10^7)</li></ul><h6 id="phase-3-reduction-to-g_3">Phase 3: Reduction to (G_3)</h6><p>Objective: Place all pieces (edges and corners) in their correct<strong>orbits</strong> (positions relative to centers).</p><ul><li>Only even permutations are allowed</li><li>Reduction to ~(10^5) possible states</li></ul><h6 id="phase-4-solve-the-cube-from-g_3-to-identity">Phase 4: Solve the cube (from (G_3) to identity)</h6><p>Objective: Use only the remaining allowed moves to reach the solved state.</p><p>At each stage, Thistlethwaite’s method restricts the<strong>move set</strong>, guiding the cube closer to a structured state while simultaneously reducing the number of legal transformations — and therefore the size of the search space.</p><h4 id="why-it-works-mathematics-meets-efficiency">Why It Works: Mathematics Meets Efficiency</h4><p>This hierarchical decomposition is more than a clever trick. It relies on<strong>coset decomposition</strong> from group theory. If we think of the Rubik’s Cube group (G) as a forest of interconnected trees, Thistlethwaite’s method picks one “layer” of branches at a time, cutting off all but the ones that eventually lead to the root (solved state). This avoids wandering aimlessly through the forest and allows for<strong>guided, phase-wise convergence</strong>.</p><p>Another advantage is<strong>modularity</strong>. Since each phase has a much smaller state space, it becomes feasible to precompute<strong>lookup tables</strong> (called pruning tables) for each subgroup. These tables store the shortest number of moves needed to reach the next subgroup from any configuration in the current one — dramatically reducing computation time during solving.</p><h4 id="conclusion">Conclusion</h4><p>Although Thistlethwaite’s algorithm does not always find the absolute shortest solution (i.e., not always “God’s Algorithm”), it typically solves any scrambled cube in<strong>45 to 52 moves</strong> — a remarkable feat considering the cube’s astronomical complexity.</p><p>Thistlethwaite’s algorithm laid the groundwork for efficient Rubik’s Cube solving by breaking down the problem into manageable phases — next, we’ll explore how Kociemba’s algorithm builds on this foundation to achieve even faster and shorter solutions.</p>
]]></content:encoded></item><item><title>Getting Started with Hugo: A Step-by-Step Guide</title><link>https://mummanajagadeesh.github.io/blog/getting-started-with-hugo/</link><pubDate>Sat, 01 Mar 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/getting-started-with-hugo/</guid><description>&lt;![CDATA[<p>Hugo is a fast, flexible, and open-source static site generator that allows you to build websites with ease. Originally popular for blogging, Hugo’s versatility makes it ideal for creating a wide range of sites — from personal portfolios and academic project showcases to documentation hubs and even e-commerce sites. Whether you’re building a professional portfolio, a research site to share your academic work, or a personal blog, Hugo has you covered.</p>]]></description><content:encoded>&lt;![CDATA[<p>Hugo is a fast, flexible, and open-source static site generator that allows you to build websites with ease. Originally popular for blogging, Hugo’s versatility makes it ideal for creating a wide range of sites — from personal portfolios and academic project showcases to documentation hubs and even e-commerce sites. Whether you’re building a professional portfolio, a research site to share your academic work, or a personal blog, Hugo has you covered.</p><p>This guide will take you through the entire process of building a website using Hugo, from installation to deployment, with practical tips to make your site look professional and unique.</p><h5 id="install-hugo"><strong>Install Hugo</strong></h5><h6 id="macos-using-homebrew"><strong>macOS (using Homebrew)</strong></h6><p>If you&rsquo;re on macOS and have Homebrew installed, this is the easiest way to install Hugo:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install hugo</span></span></code></pre></div><h6 id="windows-using-chocolatey"><strong>Windows (using Chocolatey)</strong></h6><p>For Windows, use the Chocolatey package manager:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>choco install hugo -confirm</span></span></code></pre></div><h6 id="linux-debianubuntu"><strong>Linux (Debian/Ubuntu)</strong></h6><p>If you&rsquo;re on Linux, use the following commands to install Hugo:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get update</span></span><span style="display:flex;"><span>sudo apt-get install hugo</span></span></code></pre></div><p>Alternatively, you can download a precompiled binary for your platform from the<a href="https://github.com/gohugoio/hugo/releases" target="_blank">Hugo releases page</a> and extract it manually.</p><h6 id="verifying-installation"><strong>Verifying Installation</strong></h6><p>Once installed, verify the installation by running:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hugo version</span></span></code></pre></div><p>This will show the version of Hugo you have installed, confirming that it is ready to go.</p><hr><h5 id="create-a-new-hugo-site"><strong>Create a New Hugo Site</strong></h5><p>After Hugo is installed, you can create a new site with a simple command. Open a terminal (or command prompt on Windows) and run the following:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hugo new site &lt;your-site-name></span></span></code></pre></div><p>This creates a new directory (<code>&lt;your-site-name></code>) with the basic structure of a Hugo site. You’ll see directories like<code>content/</code>,<code>layouts/</code>, and<code>themes/</code>.</p><h5 id="choose-and-install-a-theme"><strong>Choose and Install a Theme</strong></h5><p>Hugo uses themes to determine how your website looks. To browse available themes, head to the<a href="https://themes.gohugo.io/" target="_blank">Hugo Themes website</a>. There are hundreds of free and open-source themes to choose from.</p><p>Once you&rsquo;ve chosen a theme, you can add it to your site by following these steps:</p><h6 id="using-git-submodule-recommended"><strong>Using Git Submodule (Recommended)</strong></h6><ol><li><p>Inside your Hugo site directory, initialize a Git repository (if it isn’t already initialized):</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git init</span></span></code></pre></div></li><li><p>Add the theme as a submodule:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git submodule add &lt;theme-repository-url> themes/&lt;theme-name></span></span><span style="display:flex;"><span>git submodule update --init --recursive</span></span></code></pre></div></li><li><p>Configure your site to use the new theme. Open<code>config.toml</code> (or<code>config.yaml</code> or<code>config.json</code>, depending on your configuration format) and set the theme:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-toml" data-lang="toml"><span style="display:flex;"><span><span style="color:#a6e22e">theme</span> =<span style="color:#e6db74">"&lt;theme-name>"</span></span></span></code></pre></div></li></ol><p>Alternatively, you can download the theme manually, but using Git submodules is more efficient for managing updates.</p><hr><h5 id="understanding-hugos-directory-structure"><strong>Understanding Hugo’s Directory Structure</strong></h5><p>Hugo uses a specific directory structure to organize your website’s content, assets, and configuration. Here&rsquo;s a breakdown of the most important directories and files:</p><ul><li><strong><code>content/</code></strong>: Where your content lives. This is where you will add markdown files for posts, pages, and other content types.</li><li><strong><code>themes/</code></strong>: Contains the themes you use in your site. Each theme will have a<code>layouts/</code> directory, which contains the theme’s templates.</li><li><strong><code>static/</code></strong>: This directory holds static assets like images, CSS, JavaScript files, etc. Files here are copied directly to the root of the<code>public/</code> directory when Hugo generates the site.</li><li><strong><code>layouts/</code></strong>: This folder is used for your custom templates. You can override theme templates or create your own templates for specific types of content.</li><li><strong><code>config.toml</code> (or<code>config.yaml</code>,<code>config.json</code>)</strong>: This is your site’s configuration file, where you set global parameters like the site’s title, base URL, language, theme, and more.</li></ul><hr><h5 id="create-and-organize-content"><strong>Create and Organize Content</strong></h5><p>Now it’s time to add content to your website. You can create content types like blog posts, pages, or custom content.</p><h6 id="creating-a-new-page-or-post"><strong>Creating a New Page or Post</strong></h6><p>To create a new page or post, run the following command:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hugo new &lt;content-type>/&lt;page-name>.md</span></span></code></pre></div><p>For example, to create a blog post:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hugo new posts/my-first-post.md</span></span></code></pre></div><p>This will create a markdown file in<code>content/posts/my-first-post.md</code>.</p><h6 id="markdown-syntax-for-content"><strong>Markdown Syntax for Content</strong></h6><p>In the generated<code>.md</code> file, you&rsquo;ll see frontmatter and markdown content:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span>---</span></span><span style="display:flex;"><span>title: "My First Post"</span></span><span style="display:flex;"><span>date: 2025-04-02</span></span><span style="display:flex;"><span>draft: true</span></span><span style="display:flex;"><span>---</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span># Welcome to my blog!</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>This is a simple markdown file to demonstrate Hugo.</span></span></code></pre></div><ul><li>The<strong>frontmatter</strong> (between the<code>---</code> lines) contains metadata for your content. You can set fields like<code>title</code>,<code>date</code>,<code>draft</code>, and custom parameters like<code>tags</code> or<code>author</code>.</li><li>The<strong>content</strong> section uses standard markdown syntax. You can write paragraphs, lists, headings, links, images, and much more.</li></ul><h6 id="publishing-content"><strong>Publishing Content</strong></h6><p>Once you’re ready to publish, you can set<code>draft: false</code> in the frontmatter and run<code>hugo server</code> to preview the site.</p><hr><h5 id="start-the-development-server"><strong>Start the Development Server</strong></h5><p>To see your site in action, you can run a local development server:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hugo server</span></span></code></pre></div><p>By default, this will run a server on<a href="http://localhost:1313" target="_blank">http://localhost:1313</a>. As you modify content or templates, Hugo will automatically regenerate the site and refresh the page.</p><hr><h5 id="building-the-site-for-production"><strong>Building the Site for Production</strong></h5><p>When you&rsquo;re satisfied with your site, you can build it for production. Run the following command:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>hugo</span></span></code></pre></div><p>This will generate the static website in the<code>public/</code> directory. The<code>public/</code> directory will contain all the HTML files, assets, and other content required to host your site.</p><hr><h5 id="deploying-the-site"><strong>Deploying the Site</strong></h5><p>Once your site is built, you can deploy it to a variety of hosting platforms. Hugo sites are static, so they can be deployed on platforms like:</p><ul><li><strong>GitHub Pages</strong>: You can push the contents of the<code>public/</code> directory to a GitHub repository and serve it using GitHub Pages.</li><li><strong>Netlify</strong>: A popular static site hosting platform. Just link your GitHub repository to Netlify, and it will automatically build and deploy your site.</li><li><strong>Vercel</strong>: Another static site hosting platform similar to Netlify.</li><li><strong>Your Own Server</strong>: If you have a hosting provider or VPS, you can upload the files in the<code>public/</code> directory to your web server.</li></ul><p>Each hosting platform will have specific instructions for deploying Hugo sites, but most of them integrate easily with Git-based workflows.</p><hr><h5 id="customizing-your-site"><strong>Customizing Your Site</strong></h5><h6 id="creating-custom-layouts"><strong>Creating Custom Layouts</strong></h6><p>To modify the look and feel of your site, you can create custom templates in the<code>layouts/</code> directory. You can override default templates from the theme by placing your custom templates here.</p><p>For example, to modify the homepage layout, you can create<code>layouts/index.html</code> or<code>layouts/_default/baseof.html</code> to adjust the base layout structure.</p><h6 id="adding-shortcodes"><strong>Adding Shortcodes</strong></h6><p>Hugo supports shortcodes, which are snippets of reusable content. You can use shortcodes to easily insert dynamic elements like galleries, videos, or calls to action. Here’s an example of using a shortcode to embed a YouTube video:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allowfullscreen=/></div></div></span></span></code></pre></div><p>Shortcodes can be defined in the<code>layouts/shortcodes/</code> directory.</p><hr><h5 id="additional-tips"><strong>Additional Tips</strong></h5><ul><li><p><strong>Taxonomies</strong>: You can organize content using taxonomies like categories or tags. Add this configuration in<code>config.toml</code>:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-toml" data-lang="toml"><span style="display:flex;"><span>[<span style="color:#a6e22e">taxonomies</span>]</span></span><span style="display:flex;"><span><span style="color:#a6e22e">category</span> =<span style="color:#e6db74">"categories"</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">tag</span> =<span style="color:#e6db74">"tags"</span></span></span></code></pre></div></li><li><p><strong>Multilingual Sites</strong>: Hugo supports multilingual sites. You can define different content for different languages in the<code>content/</code> folder, such as<code>content/en/</code> and<code>content/es/</code>.</p></li><li><p><strong>Hugo Modules</strong>: Hugo also supports modules, which allow you to manage external dependencies in your site, such as themes or libraries.</p></li><li><p><strong>GitHub Actions</strong>: You can automate your Hugo build and deployment process using GitHub Actions for continuous deployment.</p></li></ul><hr><h5 id="conclusion">Conclusion</h5><p>Hugo is a powerful tool for building fast, static websites. With this guide, you should now be able to create, customize, and deploy your own Hugo-powered site. Whether you&rsquo;re building a blog, portfolio, or documentation site, Hugo&rsquo;s flexibility and speed make it a fantastic choice for modern static websites.</p><p>Happy building!</p><blockquote><p>Quick Note:
The site you’re reading this from is also built using Hugo — but with a ton of tweaks to make it uniquely mine! I started with the Geeky-Hugo theme as the base and added a bunch of customizations, including:</p></blockquote><ul><li><p>Custom Layouts: Modified to fit my style and content structure.</p></li><li><p>Shortcodes: Added some handy ones for embedding interactive elements.</p></li><li><p>Custom CSS: To give it a personal touch and make it look just right.</p></li><li><p>LaTeX Support: For displaying complex mathematical equations seamlessly.</p></li><li><p>Extended Pages: Not just limited to blogs — I’ve got project showcases, technical documentation, and more.</p></li></ul><p>It’s proof that Hugo isn’t just about simple blogs — with some effort, you can turn it into a full-fledged portfolio or academic site!</p>
]]></content:encoded></item><item><title>Setting Up Icarus Verilog on Google Colab</title><link>https://mummanajagadeesh.github.io/blog/setting-up-icarus-verilog-on-google-colab/</link><pubDate>Mon, 24 Feb 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/setting-up-icarus-verilog-on-google-colab/</guid><description>&lt;![CDATA[<p>Google Colab is a cloud-based platform that allows you to run code in a Jupyter Notebook environment. While it&rsquo;s primarily designed for Python, it can also be adapted to run Verilog simulations using Icarus Verilog. This guide walks you through setting up Icarus Verilog on Colab, writing and compiling Verilog code, running simulations, and generating waveform files for debugging—all in the cloud.</p>]]></description><content:encoded>&lt;![CDATA[<p>Google Colab is a cloud-based platform that allows you to run code in a Jupyter Notebook environment. While it&rsquo;s primarily designed for Python, it can also be adapted to run Verilog simulations using Icarus Verilog. This guide walks you through setting up Icarus Verilog on Colab, writing and compiling Verilog code, running simulations, and generating waveform files for debugging—all in the cloud.</p><p>You might wonder why we’d even consider simulating Verilog code on Colab when there are many industry-grade tools available that offer synthesis, timing analysis, and complete hardware design capabilities. The answer lies in accessibility. Icarus Verilog is an open-source, lightweight alternative that remains incredibly relevant—especially for students, educators, and hobbyists. It’s perfect for academic projects, quick prototyping, and learning digital design fundamentals without the overhead of licensed tools or heavy installations.</p><p>One major advantage of using Colab is its seamless integration with the web—allowing you to import datasets or files directly from URLs or cloud storage. This becomes particularly useful for projects where Verilog testbenches need structured data, such as input vectors, weights, or test cases. With Python handling the preprocessing and formatting, you can easily generate files that your Verilog code can read, enabling a smooth and flexible software-hardware co-design workflow.</p><p>My own journey into this setup began with a somewhat unconventional idea: training a neural network in Verilog. It was a fun and technically challenging experiment that led me to build this workflow on Colab. If you&rsquo;re curious to see how that turned out, feel free to check out my project<a href="https://mummanajagadeesh.github.io/projects/improve/never/" target="_blank">here</a>.</p><h4 id="why-use-icarus-verilog-on-google-colab">Why Use Icarus Verilog on Google Colab?</h4><p>Icarus Verilog is an open-source Verilog simulation and synthesis tool that supports a wide range of Verilog constructs. Running it on Google Colab offers several advantages:</p><ul><li>No need to install software on your local machine.</li><li>Easy collaboration and sharing through Colab notebooks.</li><li>Accessible from any device with an internet connection.</li><li>Free computational resources provided by Google.</li></ul><p>Now, let&rsquo;s get started with setting up Icarus Verilog on Google Colab.</p><h4 id="installing-icarus-verilog">Installing Icarus Verilog</h4><p>Before you can run Verilog simulations, you need to install Icarus Verilog on your Colab environment. To do this, execute the following commands:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>sudo apt<span style="color:#f92672">-</span>get update</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>sudo apt<span style="color:#f92672">-</span>get install<span style="color:#f92672">-</span>y iverilog</span></span></code></pre></div><p>Once installed, verify the installation by checking the version:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>iverilog<span style="color:#f92672">-</span>v</span></span></code></pre></div><p>If the installation is successful, you will see the version information displayed in the output.</p><h4 id="writing-and-running-a-simple-verilog-program">Writing and Running a Simple Verilog Program</h4><p>To test if Icarus Verilog is working correctly, let&rsquo;s write a simple Verilog program that prints a message. In Colab, you can use the<code>%%writefile</code> magic command to create and save Verilog files:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">%%</span>writefile test<span style="color:#f92672">.</span>v</span></span><span style="display:flex;"><span>module hello;</span></span><span style="display:flex;"><span> initial begin</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span>display(<span style="color:#e6db74">"Hello, Icarus Verilog on Colab!"</span>);</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span>finish;</span></span><span style="display:flex;"><span> end</span></span><span style="display:flex;"><span>endmodule</span></span></code></pre></div><h5 id="compiling-and-running-the-verilog-code">Compiling and Running the Verilog Code</h5><p>Once the Verilog file is created, compile it using<code>iverilog</code>:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>iverilog<span style="color:#f92672">-</span>o test<span style="color:#f92672">.</span>out test<span style="color:#f92672">.</span>v</span></span></code></pre></div><p>Now, run the compiled Verilog file using<code>vvp</code>:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>vvp test<span style="color:#f92672">.</span>out</span></span></code></pre></div><p>If everything is working correctly, you should see the message &ldquo;Hello, Icarus Verilog on Colab!&rdquo; printed in the output.</p><h4 id="generating-and-viewing-waveform-files">Generating and Viewing Waveform Files</h4><p>In addition to printing messages, you can also generate waveform files to analyze signal behavior. This is particularly useful for debugging digital designs.</p><p>To generate a VCD (Value Change Dump) file, modify your Verilog code to include the necessary<code>$dumpfile</code> and<code>$dumpvars</code> commands:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">%%</span>writefile wave<span style="color:#f92672">.</span>v</span></span><span style="display:flex;"><span>module wave;</span></span><span style="display:flex;"><span> initial begin</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span>dumpfile(<span style="color:#e6db74">"wave.vcd"</span>);</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span>dumpvars(<span style="color:#ae81ff">0</span>, wave);</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span>display(<span style="color:#e6db74">"Generating wave.vcd..."</span>);</span></span><span style="display:flex;"><span><span style="color:#75715e">#10;</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span>finish;</span></span><span style="display:flex;"><span> end</span></span><span style="display:flex;"><span>endmodule</span></span></code></pre></div><h5 id="compiling-and-simulating">Compiling and Simulating</h5><p>Compile and simulate the modified Verilog file using the following commands:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>iverilog<span style="color:#f92672">-</span>o wave<span style="color:#f92672">.</span>out wave<span style="color:#f92672">.</span>v</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>vvp wave<span style="color:#f92672">.</span>out</span></span></code></pre></div><p>You should see a message confirming that<code>wave.vcd</code> has been generated.</p><h5 id="downloading-and-viewing-the-waveform-file">Downloading and Viewing the Waveform File</h5><p>Once the<code>wave.vcd</code> file is created, you can download it to your local machine for analysis using GTKWave, a popular waveform viewer. Use the following command to download the file:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> google.colab<span style="color:#f92672">import</span> files</span></span><span style="display:flex;"><span>files<span style="color:#f92672">.</span>download(<span style="color:#e6db74">"wave.vcd"</span>)</span></span></code></pre></div><p>After downloading, open the file in GTKWave and inspect the signal transitions.</p><h4 id="download-the-notebook">Download the Notebook</h4><p>You can download the Jupyter Notebook containing all the above steps from the following link:</p><p><a href="https://gist.github.com/Mummanajagadeesh/f62286b296e2e98182e8291ee2f5b6aa#file-icarus-verilog-setup-google-colab-ipynb" target="_blank">Download the Jupyter Notebook</a></p><h4 id="conclusion">Conclusion</h4><p>Using Google Colab for Icarus Verilog simulations provides a simple and convenient way to write, compile, and debug Verilog code without requiring any local installations. Whether you&rsquo;re a beginner learning Verilog or an experienced engineer testing small designs, this setup allows you to quickly prototype and verify your digital circuits.</p><p>By following the steps outlined in this guide, you can:</p><ul><li>Install Icarus Verilog in Google Colab.</li><li>Write and execute Verilog programs.</li><li>Generate and analyze waveform files.</li></ul><blockquote><p>What&rsquo;s more—Colab isn&rsquo;t just limited to Verilog. With a bit of setup, you can manage a range of open-source tools like Yosys, Graywolf, and many components from the OpenROAD flow, with GUIs disabled. This opens the door to enabling a full end-to-end digital design workflow—all within the cloud.</p></blockquote><p>This setup is especially useful for students, researchers, and hobbyists looking for a hassle-free environment to explore digital design, without worrying about system configurations or heavy installations.</p><p>Happy coding!</p>
]]></content:encoded></item><item><title>The Mathematics Behind the Rubik&amp;#39;s Cube #PID1.3</title><link>https://mummanajagadeesh.github.io/blog/mathematics-behind-rubiks-cube/</link><pubDate>Fri, 14 Feb 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/mathematics-behind-rubiks-cube/</guid><description>&lt;![CDATA[<p>The Rubik’s Cube is not just a puzzle; it’s a deep mathematical object grounded in group theory, combinatorics, and geometry. Understanding the math behind it allows us to grasp why it has 43 quintillion possible states, how we categorize moves, and why some solutions are more efficient than others.</p>]]></description><content:encoded>&lt;![CDATA[<p>The Rubik’s Cube is not just a puzzle; it’s a deep mathematical object grounded in group theory, combinatorics, and geometry. Understanding the math behind it allows us to grasp why it has 43 quintillion possible states, how we categorize moves, and why some solutions are more efficient than others.</p><h4 id="group-theory-and-the-rubiks-cube"><strong>Group Theory and the Rubik’s Cube</strong></h4><p>Group theory is a branch of mathematics that studies sets with operations that follow specific rules. The Rubik’s Cube can be seen as a mathematical group where:</p><ul><li>Each state of the cube is an element of the group.</li><li>Each valid move (rotating a face) is a group operation.</li><li>The identity element is the solved state of the cube.</li><li>Moves have inverses (e.g., turning the right face clockwise can be undone by turning it counterclockwise).</li></ul><p>The Rubik’s Cube belongs to a finite group since it has a limited number of positions. The set of all possible cube configurations, with the operation of applying a sequence of moves, forms a non-abelian group (meaning that order matters—doing move A then B is not the same as doing move B then A).</p><p>Here’s the updated version incorporating center orientation in the usual order for 3×3 scales:</p><h4 id="order-of-an-element-in-the-rubiks-cube-group"><strong>Order of an Element in the Rubik’s Cube Group</strong></h4><p>In group theory, the order of an element is the number of times it must be applied to return to the identity (solved state). In the Rubik’s Cube, certain moves or sequences have different orders:</p><ul><li>A single quarter-turn of a face has order 4 (doing it four times returns the cube to the original state).</li><li>A 180-degree turn has order 2.</li><li>Certain complex sequences have higher orders, meaning they take more repetitions to cycle back to the starting position.</li><li>On a standard 3×3 Rubik’s Cube, center pieces do not change position, but their orientation can matter in some cases, such as in supercube variants where sticker orientation is tracked. In such cases, center rotations may introduce elements of order 2 or 4, depending on the move sequence.</li></ul><p>Understanding the order of moves, including center orientation, helps in designing efficient solving algorithms.</p><h4 id="counting-the-43-quintillion-permutations"><strong>Counting the 43 Quintillion Permutations</strong></h4><p>To compute the number of possible Rubik’s Cube states, we analyze the degrees of freedom:</p><ul><li>There are 8 corner pieces, each of which can be arranged in (8!) ways.</li><li>Each corner has three orientations, giving (3^7) possibilities (the last one is determined by the others).</li><li>There are 12 edge pieces, which can be arranged in (12!) ways.</li><li>Each edge has two orientations, giving (2^{11}) possibilities (the last one is determined by the others).</li><li>However, only even permutations of corners and edges are possible, so we divide by 2.</li></ul><p>Thus, the total number of possible Rubik’s Cube states is:</p><p>$$
\frac{8! \times 3^7 \times 12! \times 2^{11}}{2} = 43,252,003,274,489,856,000
$$</p><p>which is approximately<strong>43 quintillion</strong>.</p><p>For the<strong>2×2×2 Rubik’s Cube</strong>, we use a similar method but without considering edges:</p><ul><li>The 8 corner pieces can be arranged in (8!) ways.</li><li>Each has 3 orientations, giving (3^7) (since the last one is determined).</li><li>Only even permutations are possible, so we divide by 2.</li></ul><p>Thus, the number of possible 2×2×2 states is:</p><p>$$
\frac{8! \times 3^7}{2} = 3,674,160
$$</p><p>which is significantly smaller than the 3×3×3 but still quite large.</p><h4 id="gods-number-and-move-metrics"><strong>God’s Number and Move Metrics</strong></h4><p>God’s Number is the maximum number of moves required to solve the worst-case scenario of a Rubik’s Cube optimally. In 2010, researchers proved that God’s Number for a standard 3×3×3 Rubik’s Cube is<strong>20 moves</strong> in the<strong>quarter-turn metric</strong> (where each 90-degree face turn counts as one move).</p><h5 id="move-metrics">Move Metrics</h5><ul><li><strong>Quarter-Turn Metric (QTM)</strong>: Every 90-degree turn is counted as one move. This is the standard used in the 20-move God’s Number proof.</li><li><strong>Half-Turn Metric (HTM)</strong>: Both 90-degree and 180-degree turns count as one move. In this metric, God’s Number is<strong>18 moves</strong>.</li><li><strong>Face-Turn Metric (FTM)</strong>: Any rotation of a face, whether 90, 180, or 270 degrees, is counted as one move.</li></ul><p>Different solving methods optimize for different metrics. For example, speedcubers prioritize<strong>fewer moves in practice</strong> rather than the theoretical minimum number of moves.</p><h4 id="euclidean-and-quaternion-mathematics-in-the-rubiks-cube"><strong>Euclidean and Quaternion Mathematics in the Rubik’s Cube</strong></h4><h5 id="euclidean-geometry-and-the-rubiks-cube"><strong>Euclidean Geometry and the Rubik’s Cube</strong></h5><p>The Rubik’s Cube exists in three-dimensional Euclidean space, meaning its transformations can be represented using classical geometric tools such as matrices and vector operations.</p><ul><li><p><strong>Rotation Matrices:</strong> Each face rotation can be described using a 3×3 rotation matrix. A 90-degree clockwise rotation about the x, y, or z-axis can be represented as:</p><p>$$
R_x(90^\circ) = \begin{bmatrix} 1 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; -1 \ 0 &amp; 1 &amp; 0 \end{bmatrix},
$$</p><p>$$
R_y(90^\circ) = \begin{bmatrix} 0 &amp; 0 &amp; 1 \ 0 &amp; 1 &amp; 0 \ -1 &amp; 0 &amp; 0 \end{bmatrix},
$$</p><p>$$
R_z(90^\circ) = \begin{bmatrix} 0 &amp; -1 &amp; 0 \ 1 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; 1 \end{bmatrix}.
$$</p></li><li><p><strong>Vector Representation:</strong> Each cubie (small cube piece) has a position vector ( v ), and applying a rotation matrix transforms it to a new position:
$$
v&rsquo; = R v.
$$
Using these transformations, all possible moves on the cube can be described mathematically.</p></li></ul><h5 id="quaternion-representation-and-the-rubiks-cube"><strong>Quaternion Representation and the Rubik’s Cube</strong></h5><p>Quaternions offer an alternative way to describe rotations in 3D space. A quaternion is defined as:
$$
q = a + bi + cj + dk,
$$
where ( a, b, c, d ) are real numbers, and ( i, j, k ) are imaginary unit vectors satisfying specific multiplication rules.</p><ul><li><p><strong>Rotation Using Quaternions:</strong> Any 3D rotation can be represented as:
$$
q = \cos\left(\frac{\theta}{2}\right) + \sin\left(\frac{\theta}{2}\right)(xi + yj + zk),
$$
where ( \theta ) is the rotation angle, and ( (x, y, z) ) is the rotation axis.</p></li><li><p><strong>Applying a Rotation:</strong> Given a point represented by a quaternion ( p ), the rotated point ( p&rsquo; ) is obtained as:
$$
p&rsquo; = q p q^{-1}.
$$</p></li></ul><p>Using quaternions avoids issues like gimbal lock and allows smooth, efficient calculations, making them useful in robotic cube solvers and computer simulations.</p><h5 id="comparison-of-euclidean-and-quaternion-methods"><strong>Comparison of Euclidean and Quaternion Methods</strong></h5><table><thead><tr><th>Method</th><th>Advantages</th><th>Use Case in Rubik’s Cube</th></tr></thead><tbody><tr><td><strong>Rotation Matrices</strong></td><td>Simple, easy to compute</td><td>Manual cube manipulation, algebraic solving</td></tr><tr><td><strong>Quaternions</strong></td><td>No gimbal lock, computationally efficient</td><td>Robotics, computer simulations</td></tr></tbody></table><p>While human solvers primarily use group-theoretic approaches, understanding Euclidean and quaternion mathematics is valuable for computational methods and AI-driven solutions.</p><h4 id="advanced-mathematics-behind-the-rubiks-cube">Advanced Mathematics Behind the Rubik’s Cube</h4><h4 id="graph-theory-and-the-rubiks-cube"><strong>Graph Theory and the Rubik’s Cube</strong></h4><p>The entire state space of the Rubik’s Cube can be visualized as a<strong>graph</strong>, where:</p><ul><li>Each<strong>node</strong> represents a unique cube configuration.</li><li>Each<strong>edge</strong> represents a valid move between two configurations.</li></ul><p>This allows us to analyze cube solving as a<strong>shortest path problem</strong> (like in Dijkstra’s algorithm). The challenge is that this graph is<strong>huge</strong>, containing about<strong>43 quintillion nodes</strong>! Researchers have used<strong>Breadth-First Search (BFS)</strong> to explore how quickly the cube can be solved from any state, leading to the proof of<strong>God’s Number</strong> (20 in QTM).</p><h4 id="markov-chains-and-random-scrambles"><strong>Markov Chains and Random Scrambles</strong></h4><p>If you randomly twist a Rubik’s Cube, how many moves does it take before it is &ldquo;fully scrambled&rdquo;? This is a classic<strong>Markov Chain</strong> problem, where each move represents a<strong>random transition</strong> between states. Studies suggest that after about<strong>19-20 random moves</strong>, the cube is statistically close to a uniformly random state. This insight is used in competitive cubing to ensure fairness in official scramble generation.</p><h4 id="group-structure-conjugacy-classes-and-commutators"><strong>Group Structure: Conjugacy Classes and Commutators</strong></h4><p>The Rubik’s Cube group has special elements called<strong>commutators</strong> and<strong>conjugates</strong>, which are fundamental to advanced solving techniques:</p><ul><li><strong>Commutator</strong>: ([A, B] = A B A^{-1} B^{-1}) – used in many algorithms to isolate cube pieces.</li><li><strong>Conjugate</strong>: (X A X^{-1}) – applies a transformation in a different context.</li></ul><p>These concepts allow cube solvers to move a small set of pieces without disrupting the rest, forming the basis for algorithms like<strong>CFOP, Roux, and ZZ methods</strong>.</p><h4 id="why-is-solving-the-cube-hard-computational-complexity"><strong>Why Is Solving the Cube Hard? Computational Complexity</strong></h4><p>Solving an<strong>arbitrary</strong> cube position optimally (in the least moves) is an<strong>NP-hard problem</strong>. That means there is no known efficient algorithm that can solve every case optimally in polynomial time. This is why human solvers use heuristic-based approaches like<strong>CFOP, Petrus, and Roux</strong>, rather than brute force computation.</p><h4 id="whats-next-computers-and-efficient-cube-solving"><strong>What’s Next? Computers and Efficient Cube Solving</strong></h4><p>In our next post, we will explore how<strong>computers</strong> approach solving the Rubik’s Cube, including AI techniques, heuristics, and optimal solvers like<strong>Kociemba’s Algorithm and DeepCubeA</strong>.</p>
]]></content:encoded></item><item><title>Solving The Rubiks Cube #PID1.2</title><link>https://mummanajagadeesh.github.io/blog/solving-the-rubiks-cube/</link><pubDate>Fri, 07 Feb 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/solving-the-rubiks-cube/</guid><description>&lt;![CDATA[<p>Solving a Rubik’s Cube isn’t just about memorizing algorithms — it’s about understanding how moves affect the pieces. There are several solving methods, each with its own approach. Some prioritize speed, some focus on efficiency or fewer rotations.</p>]]></description><content:encoded>&lt;![CDATA[<p>Solving a Rubik’s Cube isn’t just about memorizing algorithms — it’s about understanding how moves affect the pieces. There are several solving methods, each with its own approach. Some prioritize speed, some focus on efficiency or fewer rotations.</p><p>Here&rsquo;s a breakdown of the main ones:</p><hr><h4 id="cfop-the-classic-speedcubing-approach">CFOP: The Classic Speedcubing Approach</h4><p>CFOP (Cross – First Two Layers – Orientation of Last Layer – Permutation of Last Layer), also known as the Fridrich Method, is the most widely used method among speedcubers. It breaks the solve into four logical steps, enabling high efficiency and minimal pause between sequences.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="360" src="/images/post/solverubcub/cfop_hu7945380640516140194.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/cfop_hu7604892347410183553.jpg'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h5 id="the-cross">The Cross</h5><p>The first step is solving a cross on one face of the cube, typically white. The aim is to position the four edge pieces correctly while minimizing moves. Advanced solvers focus on efficiency, ensuring that each edge is inserted optimally without unnecessary cube rotations. Many speedcubers practice solving the cross in eight moves or fewer to optimize their solving time.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/cross_hu8167784418912384101.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/cross_hu8167784418912384101.webp'"/><h5 id="first-two-layers-f2l">First Two Layers (F2L)</h5><p>Rather than solving corners and edges separately, F2L pairs them up before inserting them into their respective slots. This is a crucial speed improvement over beginner methods, reducing move count significantly. F2L can be learned intuitively, but advanced cubers memorize key cases and algorithms for increased efficiency.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/f2l_hu8826165599237415008.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/f2l_hu8826165599237415008.webp'"/><h5 id="orientation-of-the-last-layer-oll">Orientation of the Last Layer (OLL)</h5><p>Once the first two layers are completed, the next step is orienting all pieces on the top layer so that the face becomes a uniform color. There are 57 possible cases, but beginners can use a two-step OLL approach with just ten algorithms.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/oll_hu17659736153421577177.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/oll_hu17659736153421577177.webp'"/><h5 id="permutation-of-the-last-layer-pll">Permutation of the Last Layer (PLL)</h5><p>The final step is to permute the last layer pieces into their correct positions. This step requires knowledge of 21 algorithms in the full PLL method or just six in the two-look PLL approach. Mastering PLL allows for faster transition times and optimized finger tricks to reduce execution delays.</p><p>CFOP is the go-to method for many speedcubers because of its structured approach and ability to handle high turn-per-second (TPS) solves with ease. Even I use CFOP for solving the cube now—I do an intuitive cross and F2L, then use 2-look OLL and 1-look PLL.</p><p>For 2x2, I use the CLL (Corners Last Layer) method. You can check out my times here:<a href="https://events.cubelelo.com/profile/24CLMUM001" target="_blank">Cubelelo Profile</a> (it&rsquo;s unofficial, but yeah!).</p><hr><h4 id="roux-the-efficient-block-building-method">Roux: The Efficient Block-Building Method</h4><p>Roux, developed by Gilles Roux in 2003, takes a vastly different approach from CFOP. It focuses on reducing move count and minimizing cube rotations, making it ideal for one-handed solving. Unlike CFOP, Roux relies heavily on intuitive solving techniques and block-building rather than strict algorithm memorization.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/roux_hu17826746158529360042.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/roux_hu17826746158529360042.webp'"/><h5 id="first-block">First Block</h5><p>The solve begins by constructing a 1x2x3 block on one side of the cube. This is done by strategically placing the edge and corner pieces in the correct positions without disrupting already solved parts.</p><h5 id="second-block">Second Block</h5><p>A second 1x2x3 block is then built on the opposite side of the cube. At this point, the left and right blocks are complete, leaving only the middle slice and top layer unsolved.</p><h5 id="cmll-corner-orientation--permutation">CMLL (Corner Orientation &amp; Permutation)</h5><p>Instead of solving the last layer in steps like OLL and PLL, Roux addresses all four corners at once using CMLL (Corners of the Last Layer). This step requires only 42 algorithms but can be broken into smaller subsets for easier learning.</p><h5 id="lse-last-six-edges">LSE (Last Six Edges)</h5><p>The final stage focuses on solving the remaining six edges using M and U moves exclusively. This step is what makes Roux unique, as it avoids rotations and allows for smooth, fast execution.</p><p>The strength of Roux lies in its efficiency—solves often require fewer moves than CFOP, and its reliance on intuitive solving makes it an excellent alternative for those who prefer a different approach.</p><hr><h4 id="zz-the-method-designed-for-ergonomics">ZZ: The Method Designed for Ergonomics</h4><p>The ZZ method, named after its creator Zbigniew Zborowski, aims to balance efficiency and turning ergonomics. It pre-orients edges early in the solve, allowing the rest of the cube to be solved with only R, U, and L moves, eliminating cube rotations and awkward finger placements.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/post/solverubcub/zz_hu17756769075213033669.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/solverubcub\/zz_hu17756769075213033669.webp'"/><h5 id="eoline-edge-orientation--line">EOLine (Edge Orientation &amp; Line)</h5><p>The solve begins by orienting all edges while placing two key edges along the bottom. This setup ensures that later steps can be executed smoothly without disrupting edge orientation.</p><h5 id="first-two-layers-f2l-1">First Two Layers (F2L)</h5><p>Unlike CFOP, which requires cube rotations for F2L, the ZZ method allows for rotationless F2L execution. Because edge orientation was handled in EOLine, all remaining F2L pairs can be inserted using only R, U, and L moves.</p><h5 id="last-layer">Last Layer</h5><p>Since all edges are already oriented, solving the last layer can be approached using CFOP-style algorithms or ZZ-specific techniques. The most advanced ZZ solvers use ZBLL (Zborowski-Bruchem Last Layer), which solves the entire last layer in one step, requiring knowledge of over 400 algorithms.</p><p>ZZ is an excellent choice for solvers who want to improve ergonomics while maintaining low move counts. However, EOLine can be challenging to master, making it slightly more difficult for beginners compared to CFOP.</p><hr><h4 id="layer-by-layer-lbl-the-beginner-friendly-method">Layer-by-Layer (LBL): The Beginner-Friendly Method</h4><p>The Layer-by-Layer (LBL) method is the most common beginner method. It involves solving the cube in three distinct layers:</p><ol><li>Solve the<strong>first layer</strong> by completing a cross and inserting corners.</li><li>Solve the<strong>second layer</strong> by inserting edge pieces into their correct slots.</li><li>Solve the<strong>last layer</strong> using algorithms to orient and permute the pieces.</li></ol><p>This method is easy to learn and provides a solid foundation for more advanced techniques like CFOP.</p><hr><h4 id="petrus-method-the-block-building-alternative">Petrus Method: The Block-Building Alternative</h4><p>The Petrus Method, developed by Lars Petrus, is a block-building approach that reduces move count and improves efficiency:</p><ol><li>Solve a<strong>2x2x2 block</strong> anywhere on the cube.</li><li>Expand it to a<strong>2x2x3 block</strong>.</li><li><strong>Orient the edges</strong> early to make solving easier.</li><li>Solve the<strong>remaining pieces</strong> with minimal moves.</li></ol><p>This method is useful for those who want an alternative to CFOP and prefer a more flexible solving approach.</p><hr><h4 id="choosing-the-right-method">Choosing the Right Method</h4><p>Each method has its strengths, and the best one depends on your goals:</p><ul><li><strong>CFOP</strong> is the best choice for speedcubers aiming for high TPS and efficiency.</li><li><strong>Roux</strong> is ideal for solvers who prefer intuitive solving and minimal rotations.</li><li><strong>ZZ</strong> is suited for those who want ergonomic solves with fewer rotations.</li><li><strong>LBL</strong> is great for beginners starting with the cube.</li><li><strong>Petrus</strong> is perfect for those who enjoy a block-building approach.</li></ul><p>No matter which method you choose, improving your lookahead, finger tricks, and efficiency will always be key to becoming a faster solver. Try out different approaches and see what works best for you!</p><p>Happy cubing!</p>
]]></content:encoded></item><item><title>Mechanics of Rubiks Cube #PID1.1</title><link>https://mummanajagadeesh.github.io/blog/mechanics-of-rubiks-cube/</link><pubDate>Fri, 31 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/mechanics-of-rubiks-cube/</guid><description>&lt;![CDATA[<p>The Rubik’s Cube is a 3D combination puzzle that has fascinated minds for decades. Invented in<strong>1974 by Ernő Rubik</strong>, a Hungarian architect and professor, it was originally called the &ldquo;Magic Cube.&rdquo; Designed as a teaching tool to explain 3D movement, it quickly became a global sensation. The challenge? Scramble it, then restore each face to a single color—sounds simple, but millions have struggled (and succeeded) at it since!</p>]]></description><content:encoded>&lt;![CDATA[<p>The Rubik’s Cube is a 3D combination puzzle that has fascinated minds for decades. Invented in<strong>1974 by Ernő Rubik</strong>, a Hungarian architect and professor, it was originally called the &ldquo;Magic Cube.&rdquo; Designed as a teaching tool to explain 3D movement, it quickly became a global sensation. The challenge? Scramble it, then restore each face to a single color—sounds simple, but millions have struggled (and succeeded) at it since!</p><blockquote><p>If you are curious, you&rsquo;ll find the puzzles around you. If you are determined, you will solve them
-<strong>Erno Rubik</strong></p></blockquote><h4 id="how-a-rubiks-cube-is-structured"><strong>How a Rubik’s Cube is Structured</strong></h4><p>At first glance, the Rubik’s Cube appears to be just 27 smaller cubes arranged in a 3x3 grid, but its internal mechanics are far more sophisticated. The core mechanism allows for smooth rotations, holding everything together while letting the outer pieces move freely.</p><p>The cube consists of three main types of pieces:</p><ul><li><strong>Core:</strong> The core holds the entire structure intact. It consists of six fixed center pieces that never move relative to each other.</li><li><strong>Edges:</strong> The cube has<strong>12 edge pieces</strong>, each with two colors, positioned between the centers.</li><li><strong>Corners:</strong> There are<strong>8 corner pieces</strong>, each with three colors, which determine the cube’s orientation.</li></ul><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="743" src="/images/post/rubcubemech/image_hu9050823026402286148.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/rubcubemech\/image_hu9077097627081541973.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><p>Each of these pieces interlocks in a way that allows rotation without disassembling the puzzle. When twisted, the cube rearranges itself by moving these smaller components around the core, yet the entire structure remains stable.</p><h4 id="how-it-rotates-and-functions"><strong>How It Rotates and Functions</strong></h4><p>Despite its scrambled look, a Rubik’s Cube follows a well-structured mechanical system:</p><ul><li><strong>Each face rotates independently</strong>, thanks to the internal core mechanism.</li><li>The<strong>center pieces remain static</strong>, acting as reference points for solving.</li><li><strong>Edge and corner pieces move around freely</strong>, rearranging their positions to create new patterns with every turn.</li></ul><p>Each move you make affects multiple pieces at once, creating complex shifts that can be solved using known algorithms. The key is to understand how these pieces interact with each turn to work towards a solution.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="649" src="/images/post/rubcubemech/moves_hu7891343800563514831.webp" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src='\/images\/post\/rubcubemech\/moves_hu4604621624726201818.jpg'"/><h4 id="rubiks-cube-notation-3x3-standard-moves"><strong>Rubik’s Cube Notation (3x3 Standard Moves)</strong></h4><p>To communicate Rubik’s Cube solutions, we use standard notation:</p><ul><li><p><strong>Face Turns:</strong></p><ul><li><strong>R</strong> (Right) – Rotate the right face 90° clockwise</li><li><strong>R&rsquo;</strong> (Right Prime) – Rotate the right face 90° counterclockwise</li><li><strong>L</strong> (Left) – Rotate the left face 90° clockwise</li><li><strong>L&rsquo;</strong> (Left Prime) – Rotate the left face 90° counterclockwise</li><li><strong>U</strong> (Up) – Rotate the top face 90° clockwise</li><li><strong>U&rsquo;</strong> (Up Prime) – Rotate the top face 90° counterclockwise</li><li><strong>D</strong> (Down) – Rotate the bottom face 90° clockwise</li><li><strong>D&rsquo;</strong> (Down Prime) – Rotate the bottom face 90° counterclockwise</li><li><strong>F</strong> (Front) – Rotate the front face 90° clockwise</li><li><strong>F&rsquo;</strong> (Front Prime) – Rotate the front face 90° counterclockwise</li><li><strong>B</strong> (Back) – Rotate the back face 90° clockwise</li><li><strong>B&rsquo;</strong> (Back Prime) – Rotate the back face 90° counterclockwise</li></ul></li><li><p><strong>Double Turns:</strong></p><ul><li>Moves followed by<strong>2</strong> (e.g., R2, U2) indicate a 180° turn in either direction.</li></ul></li></ul><p>This notation is used universally among cubers, making it easier to follow solving guides and algorithms.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="" src="/images/post/rubcubemech/cube_notation.gif" alt="pieces-of-rubiks-cube" onerror="this.onerror='null';this.src=''"/><h4 id="color-schemes-and-face-orientation"><strong>Color Schemes and Face Orientation</strong></h4><p>Most official Rubik’s Cubes follow a standardized<strong>color arrangement</strong>, which helps speedcubers recognize patterns quickly. The opposite face pairs are usually:</p><ul><li><strong>White ↔ Yellow</strong></li><li><strong>Blue ↔ Green</strong></li><li><strong>Red ↔ Orange</strong></li></ul><p>This scheme remains consistent across most cubes, ensuring uniformity in solving strategies. Recognizing the relationship between opposite faces is crucial when learning solving techniques, as many algorithms rely on the cube’s color orientation.</p><h4 id="different-types-of-rubiks-cubes-and-modifications"><strong>Different Types of Rubik’s Cubes and Modifications</strong></h4><p>The classic 3x3 is just the beginning! There are countless variations, each adding its own twist to the challenge:</p><h5 id="nxn-cubes-larger-and-smaller-variants"><strong>NxN Cubes (Larger and Smaller Variants)</strong></h5><ul><li><strong>2x2 (Mini Cube)</strong> – A simpler version, great for beginners.</li><li><strong>3x3 (Standard Cube)</strong> – The original and most popular.</li><li><strong>4x4 (Rubik’s Revenge)</strong> – Extra layers mean extra complexity.</li><li><strong>5x5 (Professor’s Cube)</strong> – More layers, more challenge.</li><li>Even larger cubes like<strong>6x6, 7x7, and beyond</strong> exist for advanced solvers.</li></ul><h5 id="shape-modifications"><strong>Shape Modifications</strong></h5><ul><li><strong>Fisher Cube</strong> – A 3x3 shape mod that appears to shift its center axis, making it visually deceptive.</li><li><strong>Windmill Cube</strong> – Features diagonal cuts, making rotations feel unpredictable.</li><li><strong>Axis Cube</strong> – Turns into a bizarre, asymmetric mess when scrambled.</li><li><strong>Mirror Cube</strong> – Solved by shape instead of color, adding an extra challenge.</li></ul><h5 id="other-unique-cubes"><strong>Other Unique Cubes</strong></h5><ul><li><strong>Pyraminx</strong> – A triangular-based twisty puzzle with simpler movement mechanics.</li><li><strong>Megaminx</strong> – A 12-sided dodecahedron cube with an extra layer of complexity.</li><li><strong>Ghost Cube</strong> – A shape-shifting cube that must be solved by aligning irregularly shaped pieces rather than colors.</li></ul><p>Each of these variations presents a unique solving challenge, keeping cubers engaged for years!</p><h4 id="final-thoughts"><strong>Final Thoughts</strong></h4><p>The Rubik’s Cube is more than just a toy—it’s a<strong>mechanical marvel, a brain workout, and an endless source of fun</strong>. Whether you’re solving a classic 3x3 or diving into the wild world of modded cubes, the principles remain the same:<strong>patterns, patience, and persistence</strong>. Solving a Rubik’s Cube can enhance cognitive skills like problem-solving, pattern recognition, and spatial awareness, making it a fantastic hobby for all ages.</p><p>So, grab a cube, start twisting, and embrace the puzzle madness! 🔄✨</p>
]]></content:encoded></item><item><title>Why Should You Start Solving Puzzles? #PID1.0</title><link>https://mummanajagadeesh.github.io/blog/why-should-you-start-solving-puzzles/</link><pubDate>Fri, 24 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/why-should-you-start-solving-puzzles/</guid><description>&lt;![CDATA[<p>Whether it&rsquo;s a crossword, Sudoku, or a complex jigsaw, puzzles have a unique way of capturing our attention. But what makes solving them feel so rewarding? Beyond the entertainment, puzzles play a significant role in enhancing cognitive abilities, improving problem-solving skills, and offering a tangible sense of accomplishment.</p>]]></description><content:encoded>&lt;![CDATA[<p>Whether it&rsquo;s a crossword, Sudoku, or a complex jigsaw, puzzles have a unique way of capturing our attention. But what makes solving them feel so rewarding? Beyond the entertainment, puzzles play a significant role in enhancing cognitive abilities, improving problem-solving skills, and offering a tangible sense of accomplishment.</p><p>At their essence, puzzles present structured challenges. They prompt us to ask,<em>“How do I figure this out?”</em>—a question that resonates well beyond recreational activities. In many ways, life itself can be viewed as a series of puzzles, each requiring thoughtful decisions, strategic approaches, and adaptability. Developing puzzle-solving skills can equip us to handle larger, more complex challenges with confidence.</p><h3 id="why-solve-puzzles">Why Solve Puzzles?</h3><p>Engaging with puzzles is comparable to exercising the brain. They support memory retention, concentration, and cognitive flexibility. Additionally, puzzles foster patience, persistence, and creative thinking—skills applicable in fields ranging from software development to everyday problem-solving.</p><p>Completing a puzzle also stimulates a dopamine release in the brain, providing a sense of reward. This combination of mental exercise and positive reinforcement contributes to their enduring appeal.</p><h3 id="coding-a-digital-puzzle">Coding: A Digital Puzzle</h3><p>Programming is often described as one of the most intellectually satisfying forms of problem-solving. Every feature implemented or bug resolved represents a mini-puzzle—requiring logic, creativity, and precision.</p><p>Those familiar with debugging or optimizing code know that programming is both an evolving challenge and a continual learning process. As tools and requirements shift, so do the problems—and the satisfaction of building functional, elegant solutions remains consistent.</p><h3 id="physical-puzzles-engaging-both-mind-and-body">Physical Puzzles: Engaging Both Mind and Body</h3><p>Physical puzzles, such as the Rubik’s Cube, engage both mental and physical faculties. These types of challenges activate logical reasoning while also enhancing spatial awareness and fine motor skills. The process of manipulating a physical object while working through a solution engages multiple regions of the brain, offering a holistic cognitive workout.</p><p>Solving physical puzzles often requires a combination of strategy, precision, and patience—attributes that extend to a wide range of disciplines and tasks.</p><h3 id="the-rubiks-cube-a-learning-experience">The Rubik’s Cube: A Learning Experience</h3><p>The Rubik’s Cube is a timeless example of a puzzle that combines logic, memory, and pattern recognition. Like many, my initial attempts were far from successful. But through practice—and a few tutorials—I was able to understand the underlying logic and eventually solve it.</p><p>Solving the Rubik’s Cube helps develop a structured approach to problem-solving. It encourages thinking several steps ahead, recognizing patterns, and maintaining focus under pressure.</p><h3 id="rubiks-cube-solver-a-project-overview">Rubik’s Cube Solver: A Project Overview</h3><p>The<strong>Rubik’s Cube Solver</strong> series merges physical problem-solving with technical implementation. The goal is to design a system that can autonomously solve a Rubik’s Cube—integrating mechanical understanding with algorithmic efficiency.</p><p>The project involves simulating the cube’s mechanics, writing solution algorithms, and eventually building a hardware prototype. While the implementation is still in progress, the process offers opportunities for exploration, optimization, and iterative learning.</p><blockquote><p><em>Note</em>: The project is currently in its simulation phase. Hardware integration and performance improvements are ongoing. The series documents this development journey step by step.</p></blockquote><h3 id="introducing-the-pid-series">Introducing the PID Series</h3><p>The Rubik’s Cube Solver is the first in the<strong>PID: Project IN Detail</strong> series—a collection that provides insight into technical projects, including design processes, problem-solving methods, and key takeaways.</p><p>Upcoming posts will cover foundational Rubik’s Cube solving techniques before transitioning into how algorithms and computer vision can automate and optimize the process.</p><h3 id="getting-started">Getting Started</h3><p>Puzzles offer a valuable framework for developing critical thinking and adaptive problem-solving. Whether you’re a programmer, a puzzle enthusiast, or simply curious, this series is designed to offer something for everyone.</p><p>With that, let’s begin the journey into the world of puzzles—step by step, and twist by twist.</p>
]]></content:encoded></item><item><title>My RosConIN&amp;#39;24 (+GNOME Asia Summit) Experience</title><link>https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/</link><pubDate>Fri, 17 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/</guid><description>&lt;![CDATA[<p>Last year, I missed ROSCon India due to exams and, honestly, had no idea what I was missing out on. This year, though, I made it, and it turned out to be more than I ever imagined. The two days I spent at ROSConIN'24 were nothing short of transformative, and this blog itself is a result of the inspiration I drew from the event.</p>]]></description><content:encoded>&lt;![CDATA[<p>Last year, I missed ROSCon India due to exams and, honestly, had no idea what I was missing out on. This year, though, I made it, and it turned out to be more than I ever imagined. The two days I spent at ROSConIN'24 were nothing short of transformative, and this blog itself is a result of the inspiration I drew from the event.</p><h4 id="setting-the-stage">Setting the Stage</h4><p>The second edition of ROSCon India, following the overwhelming success of last year’s event with 750+ attendees, was hosted by ARTPARK at the Indian Institute of Science (IISc), Bangalore. This event brought together developers, hobbyists, researchers, and industry professionals to share, learn, and network over all things ROS (Robot Operating System).</p><p>What makes ROSCon India special is its resemblance to the international ROSCon, with a local flavor that emphasizes India’s growing influence in robotics and automation. It was heartwarming to see support from Open Robotics and the enthusiastic efforts of Acceleration Robotics, RigBetel Labs, and ARTPARK in organizing such an impactful gathering.</p><h4 id="day-0-workshops-galore">Day 0: Workshops Galore</h4><p>The event kicked off with Workshop Day on December 4th. We could choose one out of three workshops, and I opted for the third one:</p><ol><li><p><strong>Workshop 1: Next-Gen Robotics Development with NVIDIA ISAAC, GenAI, and ROS</strong> – Organized by NVIDIA, this workshop offered a comprehensive dive into cutting-edge robotics development. Though I couldn’t attend it, the buzz from the attendees made it clear how enriching it was.</p></li><li><p><strong>Workshop 2: Leveraging Zenoh as a ROS 2 Middleware Layer</strong> – Conducted by Zettascale Technology, this session explored Zenoh as an innovative middleware layer for ROS 2. It intrigued many participants and opened up discussions on its potential.</p></li><li><p><strong>Workshop 3: ROS 2 Controls, Navigation, and Advanced Communication Study</strong> – Organized by ARTPARK, this was my pick! A deep dive into ROS 2 controls, navigation, and communication felt perfectly aligned with my interests. The hands-on experience and insights I gained were invaluable.</p></li></ol><h4 id="day-1-a-conference-to-remember">Day 1: A Conference to Remember</h4><p>December 5th began with registrations and a warm welcome address by the organizers, setting an enthusiastic tone. Some highlights from the day included:</p><ul><li><strong>Keynotes</strong>: Geoffrey Biggs (CTO, Open Robotics) and Yadunund Vijay (Intrinsic) discussed the state of Open Robotics in 2024, followed by Jigar Halani from NVIDIA sharing insights on robotics development.</li><li><strong>Inspiring Talks</strong>: From Yuvraj Mehta’s session on RoboGPT to Sarvesh Kumar Malladi’s insights on Universal Robots’ ROS2 features, each talk added depth to the learning experience.</li><li><strong>Industry Focus</strong>: Anish Dalvi from TCS delved into automotive protocols, while Somdeb Saha highlighted retail automation with ROS. Both sessions demonstrated the vast industrial applications of ROS.</li><li><strong>Panel Discussion</strong>: The day ended with an engaging panel on cracking the product-market fit in robotics, featuring founders and investors sharing valuable insights.</li></ul><h4 id="day-2-deep-dives-and-future-directions">Day 2: Deep Dives and Future Directions</h4><p>December 6th brought more enlightening sessions, including:</p><ul><li><strong>Keynote by Angelo Corsaro (ZettaScale Technology)</strong>: An in-depth look at Zenoh as an alternative middleware layer for ROS 2.</li><li><strong>Technical Sessions</strong>: From Ajay Sethi and Prateek Nagras introducing the Robotics Application Stack to Nidhi Choudhary’s integration of physics-based neural networks with Gazebo, the variety of topics covered was astounding.</li><li><strong>Fireside Chat</strong>: The event concluded with a thought-provoking discussion on the future of ROS, featuring Geoffrey Biggs, Yadunund Vijay, and Angelo Corsaro.</li></ul><h4 id="networking-and-personal-highlights">Networking and Personal Highlights</h4><p>One of the most fulfilling aspects of ROSConIN’24 was the chance to meet incredible people. I connected with alumni from my college, including Aryan Jaguste and Jatin Vera, whose experience in robotics left me inspired. I also met many other professionals who have been in this field for years, generously sharing their knowledge and encouraging me to keep learning and experimenting.</p><p>It was this vibrant exchange of ideas and stories that inspired me to start this blog. ROSConIN’24 wasn’t just a conference; it was a catalyst for my growth in the robotics domain.</p><h4 id="a-big-shoutout">A Big Shoutout</h4><p>A massive thanks to all the companies and individuals who made this event possible, including Acceleration Robotics, RigBetel Labs, ARTPARK, NVIDIA, Zettascale Technology, Tata Consultancy Services, Universal Robots, and many others like Autodiscovery, Botsoverkill, Bullwork, Golain, I-Hub Jodhpur, IISc, Kikobot, Nawe, Neuralzome, Thundroids, Vicharak, Virya, and xTerra.</p><p>I recently shared a post on LinkedIn about a bunch of interesting startups I came across — not a promotion, just something I felt like doing for the community. These were all booths or projects I ran into during the event, and I wanted to highlight them for the sheer variety and effort behind them.</p><p>Among all, Vicharak stood out the most to me.</p><p>They’re building:</p><p>Vaaman – an FPGA-based board that’s capable of running AI/ML workloads. That’s not something you see every day in the Indian embedded space.</p><p>Axon – a single-board edge computer, built for compact high-performance tasks at the edge.</p><p>Their work hits that sweet spot between hardware and intelligence — definitely something to keep an eye on.</p><p>If you&rsquo;re into edge compute, FPGAs, or just curious about what’s brewing in the local hardware scene, check them out:<a href="https://vicharak.in/" target="_blank">vicharak.in</a></p><h4 id="closing-thoughts">Closing Thoughts</h4><p>Attending ROSConIN’24 was a valuable experience that offered more than just technical insights. It provided a sense of community and highlighted the shared interest in robotics and automation among participants. For anyone interested in these fields, the event presents a great opportunity to learn, connect, and engage with others who share similar interests.</p><p>The following day, I attended the GNOME Asia Summit in Bangalore. This event offered another perspective—bringing together open-source contributors and Linux enthusiasts. It was a great chance to learn from the broader open-source ecosystem and understand its ongoing contributions and challenges.</p><p>Navigating Bangalore came with its own set of challenges, especially when it came to traffic. However, the energy of the city and its role as a major tech hub made the overall experience worthwhile. Attending two major conferences back-to-back proved to be both intensive and rewarding, offering a condensed but enriching exposure to various communities.</p><p>Interactions at both events further encouraged me to explore robotics and open source more deeply. It was during ROSConIN’24 that the idea of starting this blog took shape—as a way to document and share ongoing learning and projects in a more structured format.</p><p>Interestingly, I was one of the few people there who received an ID with a handwritten name instead of a printed one. A few people were even unsure if it was genuine—which honestly just added to the uniqueness of the experience.</p><img title="" loading="lazy" decoding="async" class="img  " width="300" height="425" src="/images/post/roscon/roscon_hu8436160124482068298.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/post\/roscon\/roscon_hu6823818486217947842.jpeg'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script>
]]></content:encoded></item><item><title>Why Blog in 2025? (And How to Get Started)</title><link>https://mummanajagadeesh.github.io/blog/why-blog-in-2025/</link><pubDate>Fri, 10 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/why-blog-in-2025/</guid><description>&lt;![CDATA[<p>In 2025, with the internet brimming with TikToks, reels, and AI-generated articles, you might wonder—<strong>is blogging still worth it?</strong><br>
The answer is a resounding<strong>YES</strong>, and here’s why.</p>]]></description><content:encoded>&lt;![CDATA[<p>In 2025, with the internet brimming with TikToks, reels, and AI-generated articles, you might wonder—<strong>is blogging still worth it?</strong><br>
The answer is a resounding<strong>YES</strong>, and here’s why.</p><hr><h5 id="why-blog-in-2025"><strong>Why Blog in 2025?</strong></h5><h6 id="share-your-unique-perspective"><strong>Share Your Unique Perspective</strong></h6><p>In a world of AI-generated content,<strong>your personal voice matters more than ever</strong>. AI might generate the basics, but<strong>stories, experiences, and personal insights</strong> are uniquely human. Whether you’re building your first robot, sharing parenting tips, or learning a new language, your journey can inspire others.</p><blockquote><p>Think about it: How many times have you Googled a problem, stumbled upon a blog, and found exactly what you needed? That could be you helping someone else.</p></blockquote><hr><h6 id="build-your-digital-legacy"><strong>Build Your Digital Legacy</strong></h6><p>Your blog is<strong>your corner of the internet</strong>—a space to leave your mark. Unlike fleeting social media posts, blogs are evergreen, searchable, and<strong>build a record of your growth</strong>. For developers, it can be a portfolio of your work; for creatives, it’s a gallery of your creations.</p><blockquote><p>I started my blog to document my tech projects, but I realized it’s also helping me keep track of my ideas, progress, and experiments. Plus, I’ve already met people who share the same passions—thanks to this little space!</p></blockquote><hr><h6 id="learn-as-you-share"><strong>Learn as You Share</strong></h6><p>Writing is an incredible teacher. To explain something clearly, you need to truly understand it yourself.</p><ul><li>Developers often blog about solutions to bugs or coding techniques, which not only helps others but reinforces their own knowledge.</li><li>For non-tech folks, writing about personal projects—whether it’s DIY, cooking, or fitness—gives clarity and keeps you motivated.</li></ul><blockquote><p><strong>Pro Tip:</strong> Blogging can make you a better problem-solver. Breaking down problems into digestible steps is the essence of both writing and coding.</p></blockquote><hr><h6 id="build-connections-and-opportunities"><strong>Build Connections and Opportunities</strong></h6><p>Blogging isn’t just about putting your thoughts into words; it’s about<strong>starting conversations</strong>. Your blog can:</p><ul><li>Attract collaborators who resonate with your ideas.</li><li>Impress potential employers or clients by showcasing your expertise.</li><li>Connect you with a like-minded community.</li></ul><blockquote><p>Think of it as networking without the awkward handshakes.</p></blockquote><hr><h6 id="stay-relevant-in-the-ai-era"><strong>Stay Relevant in the AI Era</strong></h6><p>AI is great for automating tasks, but<strong>creativity, originality, and storytelling</strong>? That’s all you. A blog lets you flex those creative muscles and prove you’re not just keeping up with the times—you’re shaping them.</p><hr><h6 id="why-students-should-start-blogging-"><strong>Why Students Should Start Blogging</strong> 🎓</h6><p>As a student, blogging can be a game-changer for your personal and professional growth. Here’s why:</p><ol><li><p><strong>Showcase Your Skills</strong>:<br>
Your blog can act as a dynamic portfolio. Whether it’s coding projects, research papers, or even creative writing, it’s a platform to demonstrate your expertise and passion. Employers and professors love seeing initiative.</p></li><li><p><strong>Document Your Learning</strong>:<br>
Writing about what you’re learning—whether it’s a tough algorithm, a robotics project, or study hacks—helps reinforce your understanding and creates a resource for others.</p></li><li><p><strong>Stand Out</strong>:<br>
In a competitive world, a well-maintained blog sets you apart. It shows that you’re not just a passive learner but someone who actively contributes to the community.</p></li><li><p><strong>Build Connections</strong>:<br>
Blogging opens doors to collaborations, internships, and mentorships. Sharing your work publicly can attract like-minded peers, professors, or even recruiters.</p></li></ol><blockquote><p><strong>Pro Tip for Students</strong>: Start small. Write about a project or concept you recently worked on in class—it’s a great way to begin!</p></blockquote><hr><h5 id="how-to-start-blogging-in-2025"><strong>How to Start Blogging in 2025</strong></h5><p>If all this has convinced you, let’s talk about how to get started! Whether you’re a dev documenting code or someone sharing life hacks, blogging has never been easier.</p><hr><h6 id="choose-your-purpose"><strong>Choose Your Purpose</strong></h6><p>Ask yourself:<strong>Why do I want to blog?</strong></p><ul><li>Is it to document your journey (like me)?</li><li>Share your expertise?</li><li>Build a personal brand?</li><li>Just for fun?</li></ul><blockquote><p>Defining your purpose will help you stay motivated and give your blog a clear focus.</p></blockquote><hr><h6 id="pick-the-right-platform"><strong>Pick the Right Platform</strong></h6><p>Here are a few options to suit different needs:</p><ul><li><strong>Techies</strong>: Use GitHub Pages for free hosting or platforms like Jekyll/Hugo for custom setups.</li><li><strong>Beginners</strong>: Try WordPress or Ghost—they’re user-friendly and have tons of templates.</li><li><strong>Minimalists</strong>: Substack or Medium are great for simple, distraction-free writing.</li></ul><blockquote><p><strong>What I Use</strong>: I opted for GitHub Pages because I love having full control over my blog’s look and feel.</p></blockquote><hr><h6 id="write-what-you-know-and-love"><strong>Write What You Know (And Love)</strong></h6><p>Find your niche. You don’t need to be an expert—just share your journey as you learn.</p><ul><li>Devs: Write about side projects, tutorials, or debugging solutions.</li><li>Non-devs: Document hobbies, productivity hacks, or personal experiences.</li></ul><blockquote><p>Remember: What’s obvious to you might be groundbreaking to someone else.</p></blockquote><hr><h6 id="keep-it-simple-at-first"><strong>Keep It Simple (At First)</strong></h6><p>Don’t overcomplicate it. Your first post can be:</p><ul><li>An introduction to who you are.</li><li>A story about a project you worked on.</li><li>A simple “lesson learned” post.</li></ul><blockquote><p>It’s okay if your first post isn’t perfect—it’s better to start and improve as you go.</p></blockquote><hr><h6 id="leverage-ai-to-help-you"><strong>Leverage AI to Help You</strong></h6><p>In 2025, AI tools can make blogging easier:</p><ul><li>Use<strong>ChatGPT</strong> for brainstorming post ideas.</li><li><strong>Grammarly</strong> can polish your grammar.</li><li>Tools like<strong>Jasper AI</strong> can even generate draft content.</li></ul><p>But remember:<strong>your voice is the star.</strong> AI can assist, but authenticity is irreplaceable.</p><hr><h6 id="promote-your-blog"><strong>Promote Your Blog</strong></h6><p>Once your blog is live, share it!</p><ul><li>Post about it on LinkedIn, Instagram, or Twitter.</li><li>Join communities (Reddit, Discord, forums) related to your niche.</li><li>Collaborate with others by guest-posting or linking to their work.</li></ul><blockquote><p>If you’re consistent, people will notice.</p></blockquote><hr><h6 id="embrace-the-process"><strong>Embrace the Process</strong></h6><p>Blogging is a journey. Don’t stress about being perfect—just keep writing, experimenting, and learning. Tools like<strong>Google Analytics</strong> can show you what’s working and help you refine your style.</p><hr><h5 id="final-thoughts"><strong>Final Thoughts</strong></h5><p>Blogging in 2025 is about more than just writing—it’s about<strong>sharing your voice, building connections, and leaving a legacy</strong>. Whether you’re a coder, a hobbyist, or someone with a passion to share, there’s never been a better time to start.</p><blockquote><p><strong>Your Blog, Your Rules:</strong> It doesn’t have to be fancy. It just has to be<strong>you.</strong></p></blockquote><hr><h5 id="whats-next"><strong>What’s Next?</strong></h5><p>If you’re thinking of starting a blog, go for it! Your ideas are worth sharing. Feel free to reach out if you need help setting things up or brainstorming ideas—I’d love to hear from you.</p><p>Ready to take the plunge? Hit that<strong>&ldquo;New Blog&rdquo;</strong> button and let the world hear your voice!</p><hr>
]]></content:encoded></item><item><title>Hello World!! (A MUST READ)</title><link>https://mummanajagadeesh.github.io/blog/hello-world/</link><pubDate>Fri, 03 Jan 2025 05:30:00 +0000</pubDate><guid>https://mummanajagadeesh.github.io/blog/hello-world/</guid><description>&lt;![CDATA[<p>Hello, and thank you for visiting. My name is<strong>Jagadeesh</strong>, and this blog is a personal and professional record of my journey through college, projects, and the experiences that continue to shape my interests and aspirations.</p>]]></description><content:encoded>&lt;![CDATA[<p>Hello, and thank you for visiting. My name is<strong>Jagadeesh</strong>, and this blog is a personal and professional record of my journey through college, projects, and the experiences that continue to shape my interests and aspirations.</p><p>Currently, I am pursuing my undergraduate studies at<strong>NIT Calicut</strong>, where I am learning, building, and continuously exploring new ideas across engineering, technology, and beyond.<br>
This space reflects not only my technical pursuits but also my broader experiences—from milestones and challenges to reflections on the people and places that have influenced my path.</p><p>I know no one would care to read this, even I sound like someone who thinks they do&hellip; :( but anyways.</p><p>Through this blog, I aim to document my work thoughtfully, share insights, and connect with others who are equally passionate about learning and creating.</p><hr><h5 id="purpose-of-this-blog">Purpose of This Blog</h5><p>The main purpose of this blog is to<strong>organize and document</strong> my projects, ideas, and experiences in a structured way.</p><p>Over time, I realized that many of my projects ended up scattered across private repositories or forgotten folders. This space is simply an effort to gather them in one place, with a bit more context and thoughtfulness.
While most of the projects here are small or experimental, documenting them helps me reflect and learn. If anyone else happens to find something useful along the way, that would just be a nice bonus.</p><p>The content here includes technical notes, project write-ups, tutorials, and personal reflections from different experiences.</p><hr><h5 id="about-me">About Me</h5><p>I am<strong>Jagadeesh Mummana</strong>, a<strong>sophomore at NIT Calicut</strong>, majoring in<strong>Electronics and Communication Engineering</strong> with a minor in<strong>Robotics and Automation</strong>.</p><p>My focus is on<strong>electronics</strong> and<strong>hardware design</strong>, particularly in<strong>VLSI systems</strong>, and how these can be used to optimize hardware for<strong>AI applications</strong>. I’m interested in improving hardware performance to support the intensive computational needs of AI models. I also enjoy the hands-on process of building<strong>real-world robots</strong> from scratch, where integrating hardware and software effectively is essential to their operation.</p><p>I enjoy taking the time to understand systems; building them, exploring how they work, and trying to make small improvements through trial and error.</p><p>Outside of academics, I spend time on personal projects, club activities, and technical experiments, as well as trying to slowly build both technical and creative skills.</p><hr><h5 id="about-this-site">About This Site</h5><p>This site originally began as a portfolio project for my final submission in the<strong>CS50x 2024 Course</strong>.<br>
The initial version remains accessible<a href="https://jagadeesh-mummana.vercel.app/" target="_blank">here</a> or through the navigation bar.</p><p>Since then, it has grown into a broader personal and technical blog.<br>
The site is built with<strong>Hugo</strong>, using the<a href="https://github.com/statichunt/geeky-hugo" target="_blank">Geeky-Hugo theme</a> as a foundation, which I have<strong>extensively customized</strong> to better meet my evolving requirements. It is hosted via<strong>GitHub Pages</strong>.</p><p>The inspiration to start a formal blog came during my visit to<strong>ROSCon India 2024 (IISc Banglore)</strong>.<br>
At the event, I had the opportunity to interact with peers and seniors from several institutions, many of whom were doing exceptional work across different technical domains. I was struck by their clarity when explaining their projects, yet I noticed that structured documentation and public presentation of their work were often lacking.</p><p>Through conversations, it became apparent that this was not due to a lack of ability but rather due to documentation being a lower priority amidst academic and project commitments. This realization stayed with me and motivated me to establish a platform where I could not only share the technical details but also convey the motivations, processes, challenges, and insights behind each project.</p><p>It is my belief that even a<strong>basic</strong> project, when fully understood and properly documented, holds more educational and developmental value than a<strong>great</strong> one with only a surface-level understanding.<br>
Taking the time to work through each part of a project helps me learn more and feel more connected to the work.</p><p>You can find more about this inspiration and my reflections on the event in<a href="https://mummanajagadeesh.github.io/blog/my-rosconin24-experience/" target="_blank">this post</a>.</p><hr><h5 id="why-i-built-this-blog">Why I Built This Blog</h5><p>This site serves as a<strong>central platform</strong> to organize, document, and share my technical work and experiments.</p><p>Since many of my<strong>GitHub repositories are private</strong>, this blog acts as an open and structured window into the projects I am pursuing, providing detailed insights, learnings, and future directions.</p><p>Some of the projects are actively maintained, others are works in progress, and a few have reached functional milestones but are continually refined as my understanding evolves.</p><blockquote><p>All projects featured here are either<strong>independently developed</strong> or<strong>draw upon external inspirations</strong>, in which case appropriate credits are acknowledged.</p></blockquote><hr><h5 id="for-industry-professionalsrecruiters">For Industry Professionals/Recruiters</h5><p>If you are an industry professional or recruiter visiting this site, I encourage you to explore the &ldquo;<a href="https://mummanajagadeesh.github.io/projects/" target="_blank">Projects</a>&rdquo; and &ldquo;<a href="https://mummanajagadeesh.github.io/about/" target="_blank">About</a>&rdquo; sections for a clearer perspective on my work, interests, and approach.</p><p>I am currently seeking internship opportunities in areas such as<strong>digital and mixed-signal VLSI design</strong>, particularly those that intersect with<strong>robotics</strong> and<strong>AI-enhanced systems</strong>.</p><p>I am always eager to learn and explore new challenges, and I would love the opportunity to contribute to innovative projects in these areas. If you&rsquo;d like to explore any of my private repositories or discuss a project in more detail, I&rsquo;d be happy to share them upon request.</p><p>Thank you for considering my work.</p><hr><h5 id="for-peers-friends-and-fellow-explorers">For Peers, Friends, and Fellow Explorers</h5><p>If you are a peer, a friend, or simply an interested visitor, I warmly welcome discussions, collaborations, and exchange of ideas.</p><p>I believe that collaboration enriches learning for all parties involved, providing diverse perspectives and new ways of thinking.<br>
If you have an idea to discuss, a project to collaborate on, or simply wish to connect, please feel free to reach out through the<a href="https://mummanajagadeesh.github.io/contact/" target="_blank">Contact Page</a> or via direct messages on the platforms listed below.</p><p>While I am active across multiple channels, my activity on Instagram is currently limited.</p><hr><h5 id="why-i-focus-on-projects">Why I Focus on Projects</h5><p>For those wondering why there is an emphasis on building and documenting projects, the reason is simple:<strong>I believe true learning comes through hands-on experience</strong>.</p><p>Academic projects often serve their purpose within fixed timelines, but rarely do they encourage continuous exploration beyond submission. When I initiate and manage a project entirely—starting from its original motivation through to real-world deployment—I develop a deeper sense of ownership and a stronger commitment to refine and improve it over time.</p><p>Many of my projects span across disciplines, and this intersectional nature drives me to think critically and holistically. I am always open to collaborations that allow for exploration across varied fields.</p><p>In my view, engaging actively with projects provides a form of learning that cannot be replaced by passive consumption, whether through videos or multiple online courses.<br>
While these resources are important, I believe that their true value is realized when they are used as stepping stones to build something original and substantial.</p><hr><h5 id="connect-with-me">Connect With Me</h5><ul><li>🌐<strong>Portfolio</strong>:<a href="https://mummanajagadeesh.github.io" target="_blank">mummanajagadeesh.github.io</a></li><li>💼<strong>LinkedIn</strong>:<a href="https://www.linkedin.com/in/jagadeesh-mummana" target="_blank">Jagadeesh Mummana</a></li><li>🔧<strong>GitHub</strong>:<a href="https://github.com/Mummanajagadeesh" target="_blank">Mummanajagadeesh</a></li><li>📸<strong>Instagram</strong>:<a href="https://www.instagram.com/jagadeesh__97__" target="_blank">@jagadeesh__97__</a></li></ul><p>For additional social links and informal contact options, please visit the<a href="https://mummanajagadeesh.github.io/contact/" target="_blank">Contact Page</a>.</p><hr><p>Thank you for your time and interest. I look forward to continuing this journey of learning, building, and sharing, and I hope you find something here that resonates with you.</p>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/gpbot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/</guid><description>&lt;![CDATA[<h2 id="gpbot---basic-sensor-based-general-purpose-amrhttpsgithubcommummanajagadeeshgpbot-w"><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOT - Basic Sensor based General Purpose AMR</a></h2><h5 id="do-checkout-">Do checkout :</h5><h5 id="basic-line-following-robothttpsmummanajagadeeshgithubioprojectsgpbotlfr"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/lfr" target="_blank">Basic Line Following Robot</a></strong></h5><h5 id="obstacle-avoidance-robothttpsmummanajagadeeshgithubioprojectsgpbotobstacle"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/obstacle" target="_blank">Obstacle Avoidance Robot</a></strong></h5><h5 id="wall-follower-robothttpsmummanajagadeeshgithubioprojectsgpbotwallfollow"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/wallfollow" target="_blank">Wall Follower Robot</a></strong></h5><h5 id="differential-drive-robothttpsmummanajagadeeshgithubioprojectsgpbotdiffdrive"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/diffdrive" target="_blank">Differential Drive Robot</a></strong></h5><table><thead><tr><th><strong>Name</strong></th><th>GPBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This 4-wheeled robot is equipped with GPS, IMU, LiDAR, Distance Sensors, and a 2-DOF camera (using linear and rotary actuators). It detects objects using computer vision, avoids obstacles, and navigates autonomously.</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOT🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><h3 id="overview">Overview</h3><p>The robot is equipped with<strong>GPS, IMU, LiDAR, and a 2-DOF camera</strong>, enabling it to detect objects using computer vision, avoid obstacles, and navigate autonomously.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="gpbot---basic-sensor-based-general-purpose-amrhttpsgithubcommummanajagadeeshgpbot-w"><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOT - Basic Sensor based General Purpose AMR</a></h2><h5 id="do-checkout-">Do checkout :</h5><h5 id="basic-line-following-robothttpsmummanajagadeeshgithubioprojectsgpbotlfr"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/lfr" target="_blank">Basic Line Following Robot</a></strong></h5><h5 id="obstacle-avoidance-robothttpsmummanajagadeeshgithubioprojectsgpbotobstacle"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/obstacle" target="_blank">Obstacle Avoidance Robot</a></strong></h5><h5 id="wall-follower-robothttpsmummanajagadeeshgithubioprojectsgpbotwallfollow"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/wallfollow" target="_blank">Wall Follower Robot</a></strong></h5><h5 id="differential-drive-robothttpsmummanajagadeeshgithubioprojectsgpbotdiffdrive"><strong><a href="https://mummanajagadeesh.github.io/projects/gpbot/diffdrive" target="_blank">Differential Drive Robot</a></strong></h5><table><thead><tr><th><strong>Name</strong></th><th>GPBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This 4-wheeled robot is equipped with GPS, IMU, LiDAR, Distance Sensors, and a 2-DOF camera (using linear and rotary actuators). It detects objects using computer vision, avoids obstacles, and navigates autonomously.</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/gpbot-w" target="_blank">GPBOT🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><h3 id="overview">Overview</h3><p>The robot is equipped with<strong>GPS, IMU, LiDAR, and a 2-DOF camera</strong>, enabling it to detect objects using computer vision, avoid obstacles, and navigate autonomously.</p><h4 id="live-interaction">Live Interaction</h4><p>Interact with the robot in real-time via the following link:</p><p><a href="https://webots.cloud/ScKiz83?upload=webots" target="_blank">CLOUD INTERACTION_WEBOTS</a></p><h3 id="demo-videos">Demo Videos</h3><p>Explore the robot’s functionalities through these demo videos:</p><table><thead><tr><th>Camera Test</th><th>Object Detection</th><th>LiDAR in Action</th></tr></thead><tbody><tr><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/rqTKV85uOz4" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/wl0mYWiO184" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/9qBLSOo2feE" frameborder="0" allowfullscreen=/></div></div></td></tr></tbody></table><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="576" src="/images/projects/gpbot/gpbot_hu16267225310171384651.webp" alt="GPBOT" onerror="this.onerror='null';this.src='\/images\/projects\/gpbot\/gpbot_hu17654837491023740790.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h3 id="robot-overview">Robot Overview</h3><h4 id="features">Features:</h4><ul><li><strong>4-Wheeled Mobility:</strong> Designed for efficient movement in diverse environments.</li><li><strong>Sensor Suite:</strong><ul><li><strong>GPS:</strong> Provides global positioning and navigation.</li><li><strong>IMU:</strong> Tracks orientation and movement.</li><li><strong>LiDAR:</strong> Maps the surroundings and detects obstacles.</li><li><strong>2-DOF Camera:</strong> Offers flexible vision capabilities with linear and rotary actuation.</li></ul></li><li><strong>Autonomous Operation:</strong> The robot navigates without relying on complex algorithms, utilizing basic control mechanisms.</li></ul><h3 id="controls">Controls</h3><p>The following key mappings define the robot’s movement and camera operations:</p><h4 id="movement-controls">Movement Controls</h4><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>↑</td><td>Move forward</td></tr><tr><td>↓</td><td>Move backward</td></tr><tr><td>←</td><td>Turn left</td></tr><tr><td>→</td><td>Turn right</td></tr></tbody></table><h4 id="camera-controls">Camera Controls</h4><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>W</td><td>Move camera up</td></tr><tr><td>S</td><td>Move camera down</td></tr><tr><td>A</td><td>Rotate camera left (ACW)</td></tr><tr><td>D</td><td>Rotate camera right (CW)</td></tr></tbody></table><h4 id="control-visualization">Control Visualization</h4><h5 id="movement">Movement</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span> ┌───┐┌───┐┌───┐</span></span><span style="display:flex;"><span> │ ← ││ ↑ ││ → │</span></span><span style="display:flex;"><span> │ ← │└───┘│ → │</span></span><span style="display:flex;"><span> │ ← │┌───┐│ → │</span></span><span style="display:flex;"><span> │ ← ││ ↓ ││ → │</span></span><span style="display:flex;"><span> └───┘└───┘└───┘</span></span></code></pre></div><h5 id="camera">Camera</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span> ┌───┐</span></span><span style="display:flex;"><span> │ W │</span></span><span style="display:flex;"><span> └───┘</span></span><span style="display:flex;"><span> ┌───┐┌───┐┌───┐</span></span><span style="display:flex;"><span> │ A ││ S ││ D │</span></span><span style="display:flex;"><span> └───┘└───┘└───┘</span></span></code></pre></div><h3 id="implementation-details">Implementation Details</h3><p>The robot has been built from scratch, integrating multiple sensors to enhance its navigation and detection abilities.</p><ul><li><strong>Camera Functionality:</strong> The 2-DOF camera captures images and analyzes the environment for object recognition.</li><li><strong>Object Detection:</strong> Using computer vision, the robot identifies and reacts to obstacles in its path.</li></ul><h3 id="installation-and-usage">Installation and Usage</h3><h4 id="requirements">Requirements</h4><ul><li><strong>Webots:</strong> Download and install Webots from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li></ul><h4 id="setup-instructions">Setup Instructions</h4><ol><li>Clone the repository:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/gpbot-w.git</span></span><span style="display:flex;"><span>cd gpbot-w</span></span></code></pre></div></li><li>Open Webots and load the robot’s world file.</li><li>Start the simulation to test the robot’s capabilities.</li></ol><h3 id="future-enhancements">Future Enhancements</h3><ul><li><strong>Algorithm Integration:</strong> Implement advanced path planning and control algorithms.</li><li><strong>Enhanced Object Recognition:</strong> Utilize AI-based models for improved object detection.</li><li><strong>Multi-Robot Coordination:</strong> Develop cooperative strategies for multiple robots in a shared space.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/gpbot/diffdrive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/diffdrive/</guid><description>&lt;![CDATA[<h2 id="differential-drive-robot-simulationhttpsgithubcommummanajagadeeshdifferential-drive-robot-w"><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">Differential Drive Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Differential Drive Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A custom-built robot featuring a differential drive system that calculates its position and movement based on wheel rotations</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">DDR🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This repository contains the simulation of a<strong>Differential Drive Robot</strong>, built from scratch, which uses basic odometry to track its position. The robot is equipped with motors and position sensors to calculate its movement and orientation while navigating the environment.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="differential-drive-robot-simulationhttpsgithubcommummanajagadeeshdifferential-drive-robot-w"><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">Differential Drive Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Differential Drive Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A custom-built robot featuring a differential drive system that calculates its position and movement based on wheel rotations</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/differential-drive-robot-w" target="_blank">DDR🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This repository contains the simulation of a<strong>Differential Drive Robot</strong>, built from scratch, which uses basic odometry to track its position. The robot is equipped with motors and position sensors to calculate its movement and orientation while navigating the environment.</p><h4 id="demo-video"><strong>Demo Video</strong></h4><p>Click the image below to watch a demo of the robot in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/FwafE7gGxxY" frameborder="0" allowfullscreen=/></div></div><hr><h4 id="how-it-works"><strong>How It Works</strong></h4><h5 id="robot-design"><strong>Robot Design</strong></h5><p>The robot moves using<strong>two independent motors</strong> and tracks its position using<strong>two position sensors</strong>.</p><ul><li><strong>Motors</strong>: The left and right wheels have separate motors, allowing the robot to move forward, turn, or rotate in place.</li><li><strong>Position Sensors</strong>: These track how much each wheel has moved, which is used for odometry (position tracking).</li></ul><h5 id="odometry-calculation"><strong>Odometry Calculation</strong></h5><p>The robot calculates its position based on:</p><ul><li><strong>Wheel Movement</strong>: It reads the sensor values to determine how far each wheel has traveled.</li><li><strong>Position Updates</strong>: Using this data, the robot calculates its new<code>(x, y, θ)</code> coordinates.</li><li><strong>Velocity Computation</strong>: The robot computes both<strong>linear speed (v)</strong> and<strong>angular speed (w)</strong> to track its movement.</li></ul><p>The position updates continuously as the robot moves in the simulation.</p><hr><h4 id="code-explanation"><strong>Code Explanation</strong></h4><h5 id="1-odometry-calculation-tracking-the-robots-position"><strong>1. Odometry Calculation (Tracking the Robot’s Position)</strong></h5><ul><li>Reads values from the<strong>position sensors</strong> to determine how far the wheels have moved.</li><li>Converts sensor readings into<strong>distance traveled</strong>.</li><li>Updates the<strong>robot’s position and orientation</strong> using trigonometric calculations.</li><li>Continuously prints the<strong>current position (x, y, θ)</strong> of the robot.</li></ul><h5 id="2-robot-motion-control-making-the-robot-move"><strong>2. Robot Motion Control (Making the Robot Move)</strong></h5><ul><li>Sets<strong>both wheels at full speed</strong> to move forward.</li><li>Adjusts<strong>wheel speeds differently</strong> to turn:<ul><li>Turns<strong>right</strong> when needed.</li><li>Moves<strong>straight</strong> otherwise.</li></ul></li></ul><h5 id="3-square-path-movement"><strong>3. Square Path Movement</strong></h5><ul><li>The robot moves in a<strong>square pattern</strong> by following a sequence:<ul><li><strong>Moves forward for a fixed distance</strong>.</li><li><strong>Rotates 90 degrees</strong>.</li><li><strong>Repeats</strong> until a full square is completed.</li></ul></li><li>The<strong>timing of movements and turns</strong> is pre-calculated to ensure accuracy.</li></ul><hr><h4 id="installation-and-usage"><strong>Installation and Usage</strong></h4><h5 id="requirements"><strong>Requirements</strong></h5><ul><li><strong>Webots</strong>: Download and install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure Python is installed for running the controller code.</li></ul><h5 id="steps-to-run"><strong>Steps to Run</strong></h5><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/differential-drive-robot-w.git</span></span><span style="display:flex;"><span>cd differential-drive-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>differential_drive_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation to observe the robot’s movement and odometry in action.</li></ol><hr><h4 id="future-enhancements"><strong>Future Enhancements</strong></h4><ul><li><strong>Path Following</strong>: Implement algorithms for following predefined paths.</li><li><strong>Advanced Sensors</strong>: Add ultrasonic sensors for obstacle detection.</li><li><strong>Improved Control</strong>: Implement PID controllers for smoother movement.</li></ul><hr>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/gpbot/lfr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/lfr/</guid><description>&lt;![CDATA[<h2 id="line-follower-robothttpsgithubcommummanajagadeeshline-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">Line Follower Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>LFRBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This project features a robot that follows a line using basic sensors. It detects the line on the ground and adjusts its movement to stay on track. The robot can navigate turns and intersections without needing complex algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">LFRBOT🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="line-follower-robothttpsgithubcommummanajagadeeshline-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">Line Follower Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>LFRBOT</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>This project features a robot that follows a line using basic sensors. It detects the line on the ground and adjusts its movement to stay on track. The robot can navigate turns and intersections without needing complex algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/line-follower-robot-w" target="_blank">LFRBOT🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p><h3 id="features">Features</h3><ul><li>Simulation of a simple line-following robot using two infrared (IR) sensors placed on either side of the robot.</li><li>Black track designed in Tinkercad, exported and used in the Webots simulation.</li><li>Simple control logic based on IR sensor values to adjust the robot&rsquo;s movement.</li><li>No PID controller is used; instead, the robot makes decisions using basic conditional statements to steer left or right based on sensor readings.</li></ul><h3 id="demo-video">Demo Video</h3><p>Click the image below to watch a demo of the simulation in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/rejXYcaX9NQ" frameborder="0" allowfullscreen=/></div></div><h3 id="how-it-works">How It Works</h3><h4 id="robot-design">Robot Design</h4><p>The robot used in this simulation is the<strong>e-puck</strong>, a simple differential drive robot with two IR sensors positioned on the left and right sides. These sensors detect the black line against the background, and based on their readings, the robot adjusts its movement.</p><ul><li><strong>Left IR Sensor (<code>ir0</code>)</strong>: Detects the black line on the left side.</li><li><strong>Right IR Sensor (<code>ir1</code>)</strong>: Detects the black line on the right side.</li><li><strong>Wheels</strong>: Two differential drive motors control the movement of the robot (left and right wheels).</li></ul><h4 id="track-design">Track Design</h4><p>The black track was created in<strong>Tinkercad</strong> and exported into the simulation environment. You can find the track mesh file in the<strong>meshes</strong> folder.</p><h4 id="control-logic">Control Logic</h4><p>The robot&rsquo;s movement is controlled by checking the values of the left and right IR sensors and adjusting the wheel velocities accordingly:</p><ul><li><strong>Straight Movement</strong>: If both sensors detect similar values, the robot moves forward.</li><li><strong>Turning</strong>:<ul><li>If the left IR sensor detects the black line (i.e., its value increases), the robot turns<strong>left</strong> by reducing the left motor&rsquo;s speed and potentially reversing it.</li><li>If the right IR sensor detects the black line, the robot turns<strong>right</strong> by reducing the right motor&rsquo;s speed.</li></ul></li></ul><p>The control logic does not involve a<strong>PID controller</strong>. Instead, basic threshold-based conditions are used to decide the robot’s steering direction.</p><h4 id="code-explanation">Code Explanation</h4><h6 id="key-points">Key Points:</h6><ul><li><strong>Timestep</strong>: The simulation steps are updated every 32ms.</li><li><strong>Max Speed</strong>: The maximum angular velocity for the motors is set to 25% of the full motor speed (6.28 rad/s).</li><li><strong>IR Sensor Values</strong>: The values of the IR sensors are used to detect the black line. A value between 6 and 15 indicates the robot is over the line, and the respective motor is slowed or reversed to turn the robot.</li><li><strong>Motor Control</strong>: The motors are set to velocity mode, and their speed is adjusted based on the sensor inputs. When one sensor detects a stronger signal, the robot turns in that direction.</li></ul><h3 id="installation-and-usage">Installation and Usage</h3><h4 id="requirements">Requirements</h4><ul><li><strong>Webots</strong>: Install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure that you have Python installed to run the robot controller.</li></ul><h4 id="steps-to-run">Steps to Run</h4><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/line-follower-robot-w.git</span></span><span style="display:flex;"><span>cd line-follower-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>line_follower_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation and observe the robot following the line on the black track.</li></ol><h4 id="meshes">Meshes</h4><p>The<strong>meshes</strong> folder contains the black track design exported from<strong>Tinkercad</strong>. This is used in the Webots simulation for the robot to follow.</p><h3 id="future-enhancements">Future Enhancements</h3><ul><li><strong>PID Control</strong>: Although the current implementation uses basic threshold logic, PID control can be added for smoother and more accurate line following.</li><li><strong>Speed Optimization</strong>: The robot speed can be adjusted dynamically based on how sharply it needs to turn.</li><li><strong>Additional Sensors</strong>: Adding more IR sensors could improve the robot’s accuracy when following complex curves or intersections in the track.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/gpbot/obstacle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/obstacle/</guid><description>&lt;![CDATA[<h2 id="obstacle-avoidance-robothttpsgithubcommummanajagadeeshobstacle-avoidance-robot-w"><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">Obstacle Avoidance Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Obstacle Avoidance Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A robot equipped with basic sensors that detects obstacles and changes direction to avoid collisions without using advanced algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">OAR🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="obstacle-avoidance-robothttpsgithubcommummanajagadeeshobstacle-avoidance-robot-w"><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">Obstacle Avoidance Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Obstacle Avoidance Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A robot equipped with basic sensors that detects obstacles and changes direction to avoid collisions without using advanced algorithms</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/obstacle-avoidance-robot-w" target="_blank">OAR🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project simulates a line-following robot using the<strong>Webots</strong> robotics simulator. The robot, based on the<strong>e-puck</strong> model, follows a black track created in<strong>Tinkercad</strong> using two IR sensors.</p><h3 id="features">Features</h3><ul><li>Simulation of a simple line-following robot using two infrared (IR) sensors placed on either side of the robot.</li><li>Black track designed in Tinkercad, exported and used in the Webots simulation.</li><li>Simple control logic based on IR sensor values to adjust the robot&rsquo;s movement.</li><li>No PID controller is used; instead, the robot makes decisions using basic conditional statements to steer left or right based on sensor readings.</li></ul><h3 id="demo-video">Demo Video</h3><p>Click the image below to watch a demo of the simulation in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/rejXYcaX9NQ" frameborder="0" allowfullscreen=/></div></div><h3 id="how-it-works">How It Works</h3><h4 id="robot-design">Robot Design</h4><p>The robot used in this simulation is the<strong>e-puck</strong>, a simple differential drive robot with two IR sensors positioned on the left and right sides. These sensors detect the black line against the background, and based on their readings, the robot adjusts its movement.</p><ul><li><strong>Left IR Sensor (<code>ir0</code>)</strong>: Detects the black line on the left side.</li><li><strong>Right IR Sensor (<code>ir1</code>)</strong>: Detects the black line on the right side.</li><li><strong>Wheels</strong>: Two differential drive motors control the movement of the robot (left and right wheels).</li></ul><h4 id="track-design">Track Design</h4><p>The black track was created in<strong>Tinkercad</strong> and exported into the simulation environment. You can find the track mesh file in the<strong>meshes</strong> folder.</p><h4 id="control-logic">Control Logic</h4><p>The robot&rsquo;s movement is controlled by checking the values of the left and right IR sensors and adjusting the wheel velocities accordingly:</p><ul><li><strong>Straight Movement</strong>: If both sensors detect similar values, the robot moves forward.</li><li><strong>Turning</strong>:<ul><li>If the left IR sensor detects the black line (i.e., its value increases), the robot turns<strong>left</strong> by reducing the left motor&rsquo;s speed and potentially reversing it.</li><li>If the right IR sensor detects the black line, the robot turns<strong>right</strong> by reducing the right motor&rsquo;s speed.</li></ul></li></ul><p>The control logic does not involve a<strong>PID controller</strong>. Instead, basic threshold-based conditions are used to decide the robot’s steering direction.</p><h4 id="code-explanation">Code Explanation</h4><h6 id="key-points">Key Points:</h6><ul><li><strong>Timestep</strong>: The simulation steps are updated every 32ms.</li><li><strong>Max Speed</strong>: The maximum angular velocity for the motors is set to 25% of the full motor speed (6.28 rad/s).</li><li><strong>IR Sensor Values</strong>: The values of the IR sensors are used to detect the black line. A value between 6 and 15 indicates the robot is over the line, and the respective motor is slowed or reversed to turn the robot.</li><li><strong>Motor Control</strong>: The motors are set to velocity mode, and their speed is adjusted based on the sensor inputs. When one sensor detects a stronger signal, the robot turns in that direction.</li></ul><h3 id="installation-and-usage">Installation and Usage</h3><h4 id="requirements">Requirements</h4><ul><li><strong>Webots</strong>: Install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure that you have Python installed to run the robot controller.</li></ul><h4 id="steps-to-run">Steps to Run</h4><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/line-follower-robot-w.git</span></span><span style="display:flex;"><span>cd line-follower-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>line_follower_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation and observe the robot following the line on the black track.</li></ol><h4 id="meshes">Meshes</h4><p>The<strong>meshes</strong> folder contains the black track design exported from<strong>Tinkercad</strong>. This is used in the Webots simulation for the robot to follow.</p><h3 id="future-enhancements">Future Enhancements</h3><ul><li><strong>PID Control</strong>: Although the current implementation uses basic threshold logic, PID control can be added for smoother and more accurate line following.</li><li><strong>Speed Optimization</strong>: The robot speed can be adjusted dynamically based on how sharply it needs to turn.</li><li><strong>Additional Sensors</strong>: Adding more IR sensors could improve the robot’s accuracy when following complex curves or intersections in the track.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/gpbot/wallfollow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/wallfollow/</guid><description>&lt;![CDATA[<h2 id="wall-follower-robot-simulationhttpsgithubcommummanajagadeeshwall-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">Wall Follower Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Wall Follower Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The wall-following robot travels along walls in a maze. It uses basic sensors to detect the distance to the wall and adjusts its path to stay close. The robot explores all possible paths to find its destination without relying on algorithms, simply following the wall as it moves</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">WFR🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project contains the<strong>Wall Follower Robot</strong> simulation, which utilizes an<strong>e-puck</strong> model to navigate a maze using proximity sensors. The robot follows walls and explores paths randomly until it reaches its destination. This implementation does not use pathfinding algorithms or PID controllers; instead, it relies on basic logic to avoid obstacles and move along the walls.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="wall-follower-robot-simulationhttpsgithubcommummanajagadeeshwall-follower-robot-w"><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">Wall Follower Robot Simulation</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Wall Follower Robot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The wall-following robot travels along walls in a maze. It uses basic sensors to detect the distance to the wall and adjusts its path to stay close. The robot explores all possible paths to find its destination without relying on algorithms, simply following the wall as it moves</td></tr><tr><td><strong>Start</strong></td><td>June 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/wall-follower-robot-w" target="_blank">WFR🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, Python</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project contains the<strong>Wall Follower Robot</strong> simulation, which utilizes an<strong>e-puck</strong> model to navigate a maze using proximity sensors. The robot follows walls and explores paths randomly until it reaches its destination. This implementation does not use pathfinding algorithms or PID controllers; instead, it relies on basic logic to avoid obstacles and move along the walls.</p><h4 id="maze">Maze</h4><p>The robot navigates through a structured maze, as shown below:</p><p>[<img src="https://github.com/Mummanajagadeesh/wall-follower-robot/blob/main/maze_reference.jpg" alt="Maze">]</p><h4 id="demo-video">Demo Video</h4><p>Click the image below to watch a demo of the simulation in action:</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/aZBT_TVdFZY" frameborder="0" allowfullscreen=/></div></div><h4 id="how-it-works">How It Works</h4><h5 id="robot-design">Robot Design</h5><p>The<strong>e-puck</strong> robot is equipped with multiple proximity sensors positioned around its body. These sensors allow the robot to detect nearby walls and navigate through the maze by adjusting its movement. The robot makes decisions based on sensor readings to move forward or turn as needed.</p><ul><li><strong>Proximity Sensors</strong>: The robot has eight proximity sensors (<code>ps0</code> to<code>ps7</code>) that detect walls and obstacles on all sides.</li><li><strong>Motors</strong>: Independent left and right wheel motors control the robot’s movement, enabling it to move forward, turn in place, or steer based on sensor inputs.</li></ul><h5 id="maze-exploration-strategy">Maze Exploration Strategy</h5><ul><li>The robot starts at a predefined position within the maze.</li><li>It explores the maze by following walls and avoiding obstacles until it reaches the target area.</li><li>The robot does not attempt to find the shortest path but instead explores all possible routes until it reaches the destination.</li></ul><h5 id="control-logic">Control Logic</h5><ul><li>The robot detects walls using its proximity sensors and adjusts its movement accordingly.</li><li>If there is a wall directly in front, it turns right.</li><li>If there is a wall on the left but none in front, it moves forward along the wall.</li><li>If no walls are detected, the robot makes a right turn.</li><li>The robot stops when it reaches the designated target region within the maze.</li></ul><hr><h4 id="installation-and-usage">Installation and Usage</h4><h5 id="requirements">Requirements</h5><ul><li><strong>Webots</strong>: Install the Webots robotics simulator from<a href="https://cyberbotics.com/" target="_blank">here</a>.</li><li><strong>Python</strong>: Ensure Python is installed to run the robot controller.</li></ul><h5 id="steps-to-run">Steps to Run</h5><ol><li>Clone this repository to your local machine:<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/wall-follower-robot-w.git</span></span><span style="display:flex;"><span>cd wall-follower-robot-w</span></span></code></pre></div></li><li>Open Webots and load the<strong>wall_follower_robot.wbt</strong> world file in the simulation folder.</li><li>Run the simulation and observe the robot navigating through the maze.</li></ol><hr><h4 id="future-enhancements">Future Enhancements</h4><ul><li><strong>Optimized Pathfinding</strong>: Implementing algorithms like DFS, BFS, or A* to find the shortest path.</li><li><strong>PID Controller</strong>: Enhancing the robot’s movement with a PID controller for smoother turns and wall-following.</li><li><strong>Increased Maze Complexity</strong>: Introducing more challenging mazes with multiple solutions and dead-ends.</li></ul><hr>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/improve/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/improve/</guid><description>&lt;![CDATA[<h2 id="improve-image-processing-using-veriloghttpsgithubcommummanajagadeeshimprove"><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe: IMage PROcessing using VErilog</a></h2><h5 id="do-checkout--neural-network-in-veriloghttpmummanajagadeeshgithubioprojectsimprovenever">Do checkout :<strong><a href="http://mummanajagadeesh.github.io/projects/improve/never/" target="_blank">NEural NEtwork in VERilog</a></strong></h5><table><thead><tr><th><strong>Name</strong></th><th>ImProVe</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>ImProVe (Image Processing using Verilog) is a project focused on implementing image processing techniques using Verilog. It involves building image processing logic from the ground up, exploring various algorithms and approaches within HDL</td></tr><tr><td><strong>Start</strong></td><td>27 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Image Processing, HDL, Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, SystemVerilog, Icarus, Xilinx, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Active)</td></tr><tr><td><strong>Progress</strong></td><td>- Implemented edge detection algorithms: Prewitt, Sobel, Canny, Moravec corner detection, and Emboss.<br> - Applied blurring filters: Gaussian, Median, Box, and Bilateral.<br> - Completed geometric operations: Rotation, Translation, Shearing, Cropping, Reflection, and Perspective Transform.<br> - Integrated thresholding techniques: Global Thresholding, Adaptive Thresholding, Otsu&rsquo;s Method, and Color Thresholding.<br> - Color effects: Grayscale, Sepia, Contrast, Brightness, Invert, Negative, Saturation, Gamma correction, and Sharpening.<br> - Developed subprojects: Label detection (Done), Document scanner (Ongoing), Stereo camera matching (Almost done), MNIST Digit Recognition and OCR [EMNIST] (In Working Condition).</td></tr><tr><td><strong>Next Steps</strong></td><td>- Develop a synthesizable module as a proof of concept (Almost Done)<br> - Implement morphological operations: Dilation, Closing, Opening.</td></tr></tbody></table><hr><table><thead><tr><th><strong>ImProVe Project Versions</strong></th><th><strong>Linked Projects</strong></th></tr></thead><tbody><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeR" target="_blank">ImProVeR: ImProVe Revised Version</a></strong><br> Revised version with improved documentation and structure for better clarity and usability</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">CoVer: CORDIC math modules in VERilog</a></strong><br> Replaces non-synthesizable math constructs by utilizing the CORDIC algorithm for more efficient hardware implementation</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeS" target="_blank">ImProVeS: ImProVe with Synthesizable Modules</a></strong><br> Focuses on making all modules synthesizable and aims for simulation on Xilinx Vivado</td><td><strong><a href="http://mummanajagadeesh.github.io/projects/improve/never/" target="_blank">NeVer: NEural NEtwork in VERilog</a></strong><br> Implements a neural network in Verilog for better hardware acceleration of image processing tasks</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeD" target="_blank">ImProVeD: ImProVe with Deep Learning</a></strong><br> Adds deep learning techniques to enhance image processing capabilities</td><td><strong><a href="https://github.com/Mummanajagadeesh/ProtoN" target="_blank">ProtoN: PROTOcol comparison in verilog</a></strong><br> Compares different communication protocols in Verilog for efficient high-speed data transfer, focusing on synthesizability and module communication</td></tr></tbody></table><hr><h4 id="project-overview"><strong>Project Overview</strong></h4><p>ImProVe is an initiative to implement core image processing algorithms using Verilog. It aims to achieve real-time performance for advanced applications in fields like robotics, medical imaging, and computer vision.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="improve-image-processing-using-veriloghttpsgithubcommummanajagadeeshimprove"><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe: IMage PROcessing using VErilog</a></h2><h5 id="do-checkout--neural-network-in-veriloghttpmummanajagadeeshgithubioprojectsimprovenever">Do checkout :<strong><a href="http://mummanajagadeesh.github.io/projects/improve/never/" target="_blank">NEural NEtwork in VERilog</a></strong></h5><table><thead><tr><th><strong>Name</strong></th><th>ImProVe</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>ImProVe (Image Processing using Verilog) is a project focused on implementing image processing techniques using Verilog. It involves building image processing logic from the ground up, exploring various algorithms and approaches within HDL</td></tr><tr><td><strong>Start</strong></td><td>27 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">ImProVe🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Image Processing, HDL, Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, SystemVerilog, Icarus, Xilinx, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Active)</td></tr><tr><td><strong>Progress</strong></td><td>- Implemented edge detection algorithms: Prewitt, Sobel, Canny, Moravec corner detection, and Emboss.<br> - Applied blurring filters: Gaussian, Median, Box, and Bilateral.<br> - Completed geometric operations: Rotation, Translation, Shearing, Cropping, Reflection, and Perspective Transform.<br> - Integrated thresholding techniques: Global Thresholding, Adaptive Thresholding, Otsu&rsquo;s Method, and Color Thresholding.<br> - Color effects: Grayscale, Sepia, Contrast, Brightness, Invert, Negative, Saturation, Gamma correction, and Sharpening.<br> - Developed subprojects: Label detection (Done), Document scanner (Ongoing), Stereo camera matching (Almost done), MNIST Digit Recognition and OCR [EMNIST] (In Working Condition).</td></tr><tr><td><strong>Next Steps</strong></td><td>- Develop a synthesizable module as a proof of concept (Almost Done)<br> - Implement morphological operations: Dilation, Closing, Opening.</td></tr></tbody></table><hr><table><thead><tr><th><strong>ImProVe Project Versions</strong></th><th><strong>Linked Projects</strong></th></tr></thead><tbody><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeR" target="_blank">ImProVeR: ImProVe Revised Version</a></strong><br> Revised version with improved documentation and structure for better clarity and usability</td><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVe" target="_blank">CoVer: CORDIC math modules in VERilog</a></strong><br> Replaces non-synthesizable math constructs by utilizing the CORDIC algorithm for more efficient hardware implementation</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeS" target="_blank">ImProVeS: ImProVe with Synthesizable Modules</a></strong><br> Focuses on making all modules synthesizable and aims for simulation on Xilinx Vivado</td><td><strong><a href="http://mummanajagadeesh.github.io/projects/improve/never/" target="_blank">NeVer: NEural NEtwork in VERilog</a></strong><br> Implements a neural network in Verilog for better hardware acceleration of image processing tasks</td></tr><tr><td><strong><a href="https://github.com/Mummanajagadeesh/ImProVeD" target="_blank">ImProVeD: ImProVe with Deep Learning</a></strong><br> Adds deep learning techniques to enhance image processing capabilities</td><td><strong><a href="https://github.com/Mummanajagadeesh/ProtoN" target="_blank">ProtoN: PROTOcol comparison in verilog</a></strong><br> Compares different communication protocols in Verilog for efficient high-speed data transfer, focusing on synthesizability and module communication</td></tr></tbody></table><hr><h4 id="project-overview"><strong>Project Overview</strong></h4><p>ImProVe is an initiative to implement core image processing algorithms using Verilog. It aims to achieve real-time performance for advanced applications in fields like robotics, medical imaging, and computer vision.</p><ul><li><p>The project uses ground-level mathematical optimization, sometimes trading off accuracy for performance, to suit hardware constraints.</p></li><li><p>This is being actively applied to practical, working applications such as label detection, document scanning, and neural network inference.</p></li></ul><hr><h4 id="motivation">Motivation</h4><blockquote><p>On November 26, 2024, while preparing for my Verilog elective exam, I needed to scan and rotate images of handwritten notes. That&rsquo;s when I thought:</p></blockquote><blockquote><p>&ldquo;Can image rotation be implemented using Verilog?&rdquo;</p></blockquote><p>This led me to experiment with basic transformations like rotation, cropping, translation, and shearing. As I explored further, I expanded the scope to include edge detection methods (Prewitt, Sobel, Kirsch Compass, Robinson Compass, and Canny) and noise reduction techniques (median, Gaussian, and box filters).</p><p>Initially, I wasn&rsquo;t familiar with the mathematical foundations of these techniques, so I learned them as I implemented each one. The project started as<strong>RoVer – Rotation using Verilog</strong>, focusing solely on image rotation. Over time, it evolved beyond simple transformations, leading to the creation of<strong>ImProVe – Image Processing Using Verilog</strong>.</p><h4 id="aim"><strong>Aim</strong></h4><p>The goal of this project is simple yet ambitious:<em>Build a set of foundational image processing blocks using Verilog that can be deployed on hardware for real-world applications.</em></p><p>These blocks will enable practical applications such as label detection, document scanning, object recognition, and more, making real-life automation and AI-driven vision tasks possible.</p><h6 id="the-challenge"><strong>THE Challenge</strong></h6><p><em>The project isn&rsquo;t just about implementing these techniques—it&rsquo;s about making them synthesizable for hardware. Currently, there are many simulation constructs that aren&rsquo;t FPGA-friendly. Fixing this is a big part of the journey.</em></p><hr><h4 id="features"><strong>Features</strong></h4><p>ImProVe supports a wide array of image processing functionalities categorized into multiple domains:</p><h6 id="edge-detection-and-feature-extractionhttpsgithubcommummanajagadeeshimprovetreemain1"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/1" target="_blank">Edge Detection and Feature Extraction</a></strong></h6><ul><li><strong>Sobel Operator</strong>: Detects edges by computing gradients in horizontal and vertical directions</li><li><strong>Prewitt Operator</strong>: Similar to Sobel but uses different kernel values</li><li><strong>Roberts Cross Operator</strong>: Uses a 2x2 kernel for edge detection</li><li><strong>Robinson Compass Operator</strong>: Uses eight directional masks to detect edges with specific orientation sensitivity</li><li><strong>Kirsch Compass Operator</strong>: Detects edges by applying a set of 3x3 masks to enhance edges in various directions</li><li><strong>Laplacian Operator</strong>: Captures edges by computing the second derivative of the image, highlighting regions of rapid intensity change</li><li><strong>Laplacian of Gaussian (LoG)</strong>: Combines edge detection with noise reduction</li><li><strong>Canny Edge Detection</strong>: Advanced edge detection using gradients, non-maximum suppression, and thresholding</li><li><strong>Emboss Filter</strong>: Applies a convolution kernel to highlight edges and create a 3D relief effect</li><li><strong>Moravec Corner Detection</strong>: Detects corners by evaluating changes in intensity in various directions using a 3x3 window</li></ul><h6 id="noise-reduction-and-smoothinghttpsgithubcommummanajagadeeshimprovetreemain2"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/2" target="_blank">Noise Reduction and Smoothing</a></strong></h6><ul><li><strong>Gaussian Blur</strong>: Smoothens and reduces noise using a Gaussian kernel</li><li><strong>Median Filter</strong>: Replaces each pixel with the median of its neighborhood to remove Noise</li><li><strong>Box Filter (Mean Filter)</strong>: Averages pixel values within a window for Smoothing</li><li><strong>Bilateral Filter</strong>: Preserves edges while reducing noise by combining spatial and intensity information</li></ul><h6 id="thresholding-and-binarizationhttpsgithubcommummanajagadeeshimprovetreemain3"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/3" target="_blank">Thresholding and Binarization</a></strong></h6><ul><li><strong>Global Thresholding</strong>: Converts grayscale images to binary using a fixed thresholding</li><li><strong>Adaptive Thresholding</strong>: Dynamically computes thresholds based on local Intensity</li><li><strong>Otsu&rsquo;s Method</strong>: Automatically finds the optimal threshold for binarization</li><li><strong>Color Thresholding</strong>: Applies thresholding on color spaces (e g , RGB, HSV, LAB) to segment specific color ranges</li></ul><h6 id="eometric-transformationshttpsgithubcommummanajagadeeshimprovetreemain6"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/6" target="_blank">eometric Transformations</a></strong></h6><ul><li><strong>Rotation</strong>: Rotates the image by a given angle</li><li><strong>Scaling</strong>: Resizes the image while preserving aspect ratio</li><li><strong>Translation</strong>: Shifts the image position</li><li><strong>Shearing</strong>: Distorts the image by shifting rows or columns</li><li><strong>Cropping</strong>: Extracts a rectangular region from the image</li><li><strong>Reflection</strong>: Flips the image across a specified axis (horizontal, vertical, or diagonal)</li><li><strong>3D Perspective Transformation</strong>: Applies a projective transformation that distorts the image to simulate depth</li></ul><h6 id="color-and-intensity-transformationshttpsgithubcommummanajagadeeshimprovetreemain9"><strong><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/9" target="_blank">Color and Intensity Transformations</a></strong></h6><ul><li><strong>Negative Transformation</strong>: Converts an image to its negative by replacing each pixel value ( R ) with ( 255 - R )</li><li><strong>Inversion</strong>: Converts an image to its negative by inverting pixel values</li><li><strong>Sepia Effect</strong>: Applies a warm brown tone to an image for a vintage look</li><li><strong>Brightness Adjustment</strong>: Modifies image brightness by increasing or decreasing pixel intensity</li><li><strong>Gamma Correction</strong>: Adjusts brightness using a gamma function</li><li><strong>Saturation Adjustment</strong>: Enhances or reduces color intensity using a scaling factor</li><li><strong>Sharpness Enhancement</strong>: Increases edge contrast to make the image appear clearer</li></ul><hr><h4 id="todo">TODO</h4><ul><li>Ensure the code is synthesizable by removing all non-synthesizable constructs.</li><li>Use CORDIC to eliminate functions like<code>$cos</code>,<code>$sin</code>,<code>$exp</code>,<code>$sqrt</code>, and other complex mathematical operations.</li><li>For constructs related to file I/O and read/write operations, use BRAM or RAM memory to store the input image in pixels.</li><li>The output image data for all three channels should be connected to a VGA display via a communication bus like PCIe or AXI.</li><li>Optimize the solution for performance and resource efficiency.</li></ul><p><strong>Currently working on CORDIC:</strong><a href="https://github.com/Mummanajagadeesh/cordic-algorithm-verilog" target="_blank">CORDIC Algorithm in Verilog</a></p><p><strong>Currently working on OCR using Verilog as well, building a neural network from scratch for MNIST number recognition</strong></p><hr><h4 id="tools-and-technologies"><strong>Tools and Technologies</strong></h4><ul><li><strong>Icarus Verilog 12 0</strong>: Core HDL used to implement all image processing algorithms</li><li><strong>Python 3 12 1</strong>: For preprocessing image data into a format compatible with verilog</li></ul><hr><h2 id="applications-irlhttpsgithubcommummanajagadeeshimprovetreemainapplications-irl"><a href="https://github.com/Mummanajagadeesh/ImProVe/tree/main/Applications-IRL" target="_blank">Applications IRL</a></h2><h4 id="label-detection"><strong>Label-Detection</strong></h4><ul><li><p>Label detection was implemented using the<strong>Prewitt operator</strong> for edge detection. The process begins by splitting the image into three separate RGB channels using Python. Next, the<strong>luminance formula (NTSC)</strong> is applied to obtain a grayscale image.</p></li><li><p>If the image is too noisy or requires preprocessing,<strong>Gaussian blur</strong> and<strong>morphological operations</strong> are applied to refine the grayscale image before edge detection.</p></li><li><p>Edge detection algorithms are then used to identify strong edges. From these edges, the<strong>flood-fill algorithm</strong> is applied to detect the<strong>largest possible contour</strong>. A bounding rectangle is drawn in the red channel to enclose this contour, which is then superimposed on the original image for clear label detection.</p></li><li><p>This entire process is executed in Verilog using text files for data handling. Python is then used for visualization to generate the final output.</p></li></ul><h6 id="for-more-detailsimagesprojectsimprovelabel-detection"><a href="images/projects/improve/label-detection/">*For more details</a></h6><table><thead><tr><th><strong>Original Image</strong></th><th><strong>After Vertical Prewitt</strong></th><th><strong>After Horizontal Prewitt</strong></th><th><strong>After Full Prewitt</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ocr_test_1_hu13919557627271502897.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ocr_test_1_hu10928806484486211239.jpeg'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ver_hu17196909480092732094.webp" alt="After Vertical Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ver_hu15462590427229067200.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/hor_hu6331698311391901480.webp" alt="After Horizontal Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/hor_hu16023435030311149684.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/sumapp_hu17447641439322402501.webp" alt="After Full Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/sumapp_hu996122263598467842.jpg'"/></td></tr></tbody></table><table><thead><tr><th><strong>Original Image</strong></th><th><strong>After Full Prewitt</strong></th><th><strong>Binary Box</strong></th><th><strong>Overlayed Image with Box</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ocr_test_1_hu13919557627271502897.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ocr_test_1_hu10928806484486211239.jpeg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/sumapp_hu17447641439322402501.webp" alt="After Full Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/sumapp_hu996122263598467842.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/output_image_hu10251344748718835422.webp" alt="Binary Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/output_image_hu487853684034261260.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/output_image_with_box_hu9308675594061094941.webp" alt="Overlayed Image with Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/output_image_with_box_hu6234429136873210945.jpg'"/></td></tr></tbody></table><table><thead><tr><th><strong>Original Image</strong></th><th><strong>After Full Prewitt</strong></th><th><strong>Binary Box</strong></th><th><strong>Overlayed Image with Box</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/ocr_test_2_hu10839364649639871445.webp" alt="Original Image 2" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/ocr_test_2_hu1439726894735991236.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/prewcomb2_hu13524774109780843041.webp" alt="After Full Prewitt" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/prewcomb2_hu5277213214539596495.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/binarybox2_hu11453858790861498169.webp" alt="Binary Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/binarybox2_hu12819195071595147379.jpg'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/label-detection/boxedlabel2_hu7046968599601609959.webp" alt="Overlayed Image with Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/label-detection\/boxedlabel2_hu1845987694398134625.jpg'"/></td></tr></tbody></table><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/IXgA1Ih9BAo" frameborder="0" allowfullscreen=/></div></div><h4 id="document-scanner"><strong>Document Scanner</strong></h4><ul><li><p>The initial steps of the document scanning process are similar to label detection, with<strong>Canny edge detection</strong> being the preferred method for stronger edge identification.</p></li><li><p>After detecting edges, instead of directly superimposing a bounding rectangle, the<strong>boundary-fill algorithm</strong> is used to fill the detected region with binary 1s (255). A<strong>Boolean operation</strong> is then applied to remove irrelevant parts of the image that do not contain the document.</p></li><li><p>Next, corner detection is performed using the<strong>Moravec operator</strong> (as<strong>Harris</strong> is computationally expensive). Once the corners are identified,<strong>Bresenham&rsquo;s algorithm</strong> is used to draw lines connecting them, forming a quadrilateral around the document.</p></li><li><p>This quadrilateral is then mapped to a rectangle using<strong>homogeneous perspective transformation</strong>, followed by<strong>shearing</strong> and<strong>scaling</strong> operations if needed to refine the final output.</p></li></ul><p>OTW [Stuck at Bresenham&rsquo;s algorithm implementation]</p><h4 id="stereo-vision"><strong>Stereo Vision</strong></h4><ul><li><p>The process begins by converting the input stereo image pair from RGB to grayscale. Using the camera parameters, a<strong>disparity map</strong> is computed to determine the pixel shifts between the left and right images. This disparity information is then used to generate a<strong>depth map</strong>, which represents the distance of objects in the scene.</p></li><li><p>Both the disparity and depth map calculations are implemented entirely in Verilog, using text files for intermediate data storage and processing. Once the depth information is obtained, Python is used to continue the 3D reconstruction process, where the depth map is converted into a point cloud or a<strong>3D mesh representation</strong> for visualization.</p></li></ul><p>OTW [Accuracy of disparity and depth maps is low]</p><h4 id="mnist-digit-detection-never--improved"><strong>MNIST Digit Detection [NeVer ∩ ImProVeD]</strong></h4><ul><li><p>I implemented a simple neural network from scratch in<strong>Google Colab</strong> without using<strong>TensorFlow</strong> or<strong>Keras</strong>, relying solely on<strong>NumPy</strong> for numerical computations,<strong>Pandas</strong> for data handling, and<strong>Matplotlib</strong> for visualization. The dataset used was<strong>sample_data/mnist_train_small.csv</strong>, containing handwritten digit images in a flattened<strong>784-pixel format</strong>. Data preprocessing involved<strong>normalizing pixel values</strong> (dividing by<strong>255</strong>) and splitting it into a<strong>training set</strong> and a<strong>development set</strong>, with the first<strong>1000 samples</strong> reserved for development and the rest for training. Labels (digits 0-9) were stored separately, and data was shuffled before training to ensure randomness.</p></li><li><p>The neural network consists of an<strong>input layer (784 neurons)</strong>, a<strong>hidden layer (128 neurons, ReLU activation)</strong>, and an<strong>output layer (10 neurons, softmax activation)</strong>. Model parameters (weights and biases) were initialized randomly and updated using<strong>gradient descent</strong> over<strong>500 iterations</strong> with a learning rate of<strong>0.1</strong>. Training involved<strong>forward propagation</strong> to compute activations and<strong>backpropagation</strong> to update parameters. Accuracy was printed every<strong>10 iterations</strong>. To make the trained model compatible with<strong>Verilog</strong>, weights and biases were<strong>scaled by 10,000</strong> and saved as<strong>integer values</strong> in text files (<code>W1.txt</code>,<code>b1.txt</code>, etc.), preventing<strong>floating-point multiplication</strong> in hardware. These parameters were later reloaded for predictions on new images, verifying model accuracy on the<strong>development set</strong> before deployment in Verilog for real-time digit classification.</p></li><li><p>The model, trained on<strong>sample_data/mnist_train_small.csv</strong>, achieved over<strong>90% accuracy</strong>. It generates<code>W1</code>,<code>W2</code>,<code>b1</code>, and<code>b2</code> text files containing shape information. The trained parameters are used in Verilog to predict digits from an input image stored in<code>input_vector.txt</code>, which consists of<strong>784 space-separated integers</strong>. The predicted output is displayed in the terminal using<code>$display</code>. The original CSV file was converted into a space-separated text format where each line contains a digit followed by<strong>784 pixel values (785 total)</strong>. During prediction, the first value (label) is removed to test if the model correctly classifies the input image.</p></li><li><p>The<strong>Verilog module</strong> implements a neural network to classify handwritten digits from the MNIST dataset. It comprises an<strong>input layer (784 neurons), hidden layer (128 neurons), and output layer (10 neurons)</strong>. The module reads<strong>pre-trained weights and biases</strong> from text files (<code>W1.txt</code>,<code>b1.txt</code>,<code>W2.txt</code>,<code>b2.txt</code>) along with an<strong>input vector</strong> from<code>input_vector.txt</code>. Input values are normalized by dividing by<strong>255.0</strong>, while weights and biases are scaled using a<strong>factor of 10,000</strong>. The hidden layer performs a fully connected transformation (<code>W1 * input + b1</code>) followed by<strong>ReLU activation</strong>. The output layer computes another weighted sum (<code>W2 * hidden + b2</code>) but does not apply softmax; instead, the predicted digit is determined by selecting the index of the highest output value.</p></li><li><p>The file reading process ensures proper loading of weights, biases, and input values before computation begins. Forward propagation occurs sequentially, with an initial delay for data loading. After computing activations in both layers, the module iterates through the output layer to identify the highest value, representing the predicted class. The classification result is then displayed. This hardware implementation streamlines neural network inference by<strong>eliminating complex activation functions</strong> like softmax while preserving classification accuracy through maximum output activation.</p></li><li><p>In newer versions of the code, the text files are converted into<strong>synthesizable memory blocks</strong> using Python scripts. These scripts store<strong>weights and biases</strong> in register modules, which are finally instantiated in the<strong>top-level module</strong>. The image data is also handled in a similar way.</p></li><li><p>Only the<code>$display</code> statement,<code>$finish</code>, and the<code>real</code> datatype in the final top-level module are non-synthesizable constructs. These can be eliminated by directing the predicted output to a seven-segment display using case statements [Moved these constructs to the testbench in later versions for a cleaner top module; currently working with<code>Q24.8</code> as a replacement for the real datatype].</p></li><li><p>I am currently working on replacing the<strong>training process</strong> with a Verilog-based implementation, aiming for a fully synthesizable neural network.</p></li></ul><blockquote><p>This approach can pave a new way for POC, where text files are converted into register modules using Python scripts to automate the process. A top-level module can then connect all the generated modules, and the testbench can include $fopen, etc., to write the output text files. The testbench instantiates the top-level module, ensuring that all files are synthesizable.</p></blockquote><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/QtkdWSq25zQ" frameborder="0" allowfullscreen=/></div></div><h4 id="ocr-optical-character-recognition"><strong>OCR: Optical Character Recognition</strong></h4><p>This model is trained on the<strong>EMNIST ByClass dataset</strong> (<a href="https://greg-cohen.com/datasets/emnist/" target="_blank">source</a>), which contains<strong>62 classes</strong> (digits<code>0-9</code>, uppercase letters<code>A-Z</code>, and lowercase letters<code>a-z</code>). The dataset is preprocessed by converting it into a CSV format, normalizing pixel values, reducing dimensions, and shuffling before training.</p><p>The neural network consists of multiple layers:</p><ul><li>Input layer:<strong>784 neurons</strong></li><li>First hidden layer:<strong>256 neurons</strong> (<code>W1: 256×784</code>,<code>b1: 256×1</code>)</li><li>Second hidden layer:<strong>128 neurons</strong> (<code>W2: 128×256</code>,<code>b2: 128×1</code>)</li><li>Output layer:<strong>62 neurons</strong> (<code>W3: 62×128</code>,<code>b3: 62×1</code>)</li></ul><p>Training is done using forward propagation, computing activations at each layer using matrix multiplications and ReLU activations for hidden layers. Backpropagation is used to update weights using the gradient of the loss function. The dataset is shuffled to improve generalization, and weights (<code>W1</code>,<code>W2</code>,<code>W3</code>) and biases (<code>b1</code>,<code>b2</code>,<code>b3</code>) are updated iteratively until convergence. The model is trained over multiple epochs using stochastic gradient descent (SGD) and Adam&rsquo;s Optimiser.</p><p>To make the trained model compatible with hardware, weights and biases are<strong>scaled by 10,000</strong> and stored as integers in text files (<code>W1.txt</code>,<code>b1.txt</code>, etc.), since Verilog does not support floating-point arithmetic.</p><p>Inference in Verilog follows a similar process but supports extra layers and classes. Input images are read from<code>input_vector.txt</code> and normalized. Weights and biases are loaded from text files. The computation follows:</p><ul><li><code>hidden1 = ReLU(W1 * input + b1)</code></li><li><code>hidden2 = ReLU(W2 * hidden1 + b2)</code></li><li><code>output = W3 * hidden2 + b3</code></li></ul><p>The index of the<strong>maximum output value</strong> determines the predicted character, which is mapped to<code>"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"</code> and displayed using<code>$display</code>.</p><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/7YccFUtydM0" frameborder="0" allowfullscreen=/></div></div><p>The video demonstrates that<code>draw.py</code> allows us to draw anything on a square canvas. At the end, it applies grayscale, inverts the image, compresses it to a 28×28 resolution, and saves it as<code>drawing.jpg</code>. Then,<code>img2bin.py</code> converts this image into a 2D array of pixels (a 28×28 matrix) and saves it in<code>mnist_single_no.txt</code>.</p><p>Next,<code>arr2row.py</code> flattens the 2D array into a 1D array (a row of 784 values) and stores it in<code>input_vector.txt</code>. This file is then used to create<code>image_memory.v</code> with<code>memloader_from_inp_vec.py</code>, which generates a memory module for storing the image.</p><p>Following this,<code>wtbs_loader.py</code> creates six different memory modules from<code>W1</code>,<code>W2</code>,<code>W3</code>,<code>b1</code>,<code>b2</code>, and<code>b3</code> text files, generating corresponding files such as<code>W1_memory.v</code>, and so on.</p><p>All these components are instantiated in the top module<code>emnist_with_tb.v</code>, along with a testbench (<code>emnist_nn_tb.v</code>). This setup ultimately predicts the drawn character. In the demo, I showcased the characters &ldquo;H,&rdquo; &ldquo;f,&rdquo; and &ldquo;7&rdquo;—each representing a different subclass from the 62 available classes (uppercase letters, lowercase letters, and numbers).</p><blockquote><p>Additionally, I developed a coarse-grained pipelined fully connected neural network using Finite State Machine (FSM) and integrated Softmax with a Taylor series approximation to improve computational efficiency</p></blockquote><hr><hr><h4 id="important-links-and-resources"><strong>Important Links and Resources</strong></h4><h6 id="digital-image-processing"><strong>Digital Image Processing</strong></h6><ul><li><a href="https://www.geeksforgeeks.org/digital-image-processing-tutorial" target="_blank"><strong>GeeksforGeeks: Digital Image Processing Tutorial</strong></a></li><li><a href="https://youtu.be/KuXjwB4LzSA" target="_blank"><strong>YouTube: Digital Image Processing Introduction</strong></a></li><li><a href="https://www.youtube.com/live/8rrHTtUzyZA" target="_blank"><strong>YouTube Live: Advanced Digital Image Processing Concepts</strong></a></li></ul><h6 id="mathematics-for-engineering-and-computing"><strong>Mathematics for Engineering and Computing</strong></h6><ul><li><a href="https://youtu.be/w8yWXqWQYmU" target="_blank"><strong>YouTube: Building a neural network FROM SCRATCH</strong></a></li><li><a href="https://youtu.be/cAkMcPfY_Ns" target="_blank"><strong>YouTube: I Built a Neural Network from Scratch</strong></a></li><li><a href="https://youtu.be/cAkMcPfY_Ns" target="_blank"><strong>YouTube: Linear Algebra – Essence of Linear Algebra (Playlist)</strong></a></li></ul><h6 id="verilog"><strong>Verilog</strong></h6><ul><li><a href="http://www.asic.co.in/Index_files/verilog_files/File_IO.htm" target="_blank"><strong>Guide to Verilog File I/O and File Handling</strong></a></li><li><a href="https://steveicarus.github.io/iverilog/" target="_blank"><strong>Official Icarus Verilog Documentation</strong></a></li><li><a href="https://www.youtube.com/playlist?list=PLJ5C_6qdAvBELELTSPgzYkQg3HgclQh-5" target="_blank"><strong>NPTEL Lectures</strong></a></li></ul><h6 id="cordic-algorithm-resources"><strong>CORDIC Algorithm Resources</strong></h6><ul><li><a href="https://ieeexplore.ieee.org/document/6808249" target="_blank"><strong>IEEE Xplore: Hardware Implementation of a Math Module Based on the CORDIC Algorithm Using FPGA</strong></a></li><li><a href="http://ethesis.nitrkl.ac.in/4258/1/CORDIC_Algorithm_and_it%E2%80%99s_Applications_in_DSP.pdf" target="_blank"><strong>CORDIC Algorithm and Its Applications in DSP (NITR Thesis)</strong></a></li><li><a href="https://www.eit.lth.se/fileadmin/eit/courses/eitf35/2017/CORDIC_For_Dummies.pdf" target="_blank"><strong>CORDIC for Dummies (Introductory Guide)</strong></a></li><li><a href="https://www.st.com/resource/en/application_note/an5325-how-to-use-the-cordic-to-perform-mathematical-functions-on-stm32-mcus-stmicroelectronics.pdf" target="_blank"><strong>STMicroelectronics: Using the CORDIC for Mathematical Functions on STM32 MCUs</strong></a></li><li><a href="https://projectf.io/posts/square-root-in-verilog/" target="_blank"><strong>Square Root Calculation Using CORDIC In System Verilog</strong></a></li></ul><h6 id="datasets"><strong>Datasets</strong></h6><ul><li><a href="https://www.kaggle.com/datasets/hojjatk/mnist-dataset" target="_blank"><strong>MNIST Dataset: 0-9 Handwritten Numbers</strong></a></li><li><a href="https://greg-cohen.com/datasets/emnist/" target="_blank"><strong>EMNIST Dataset: Extended MNIST with Alphabet Support</strong></a></li><li><a href="https://www.kaggle.com/datasets/preatcher/standard-ocr-dataset" target="_blank"><strong>Standard OCR Dataset: Various Images of Characters in Different Fonts</strong></a></li></ul><h4 id="contributors"><strong>Contributors</strong></h4><ul><li><strong><a href="https://github.com/Mummanajagadeesh" target="_blank">Jagadeesh</a></strong> mummanajagadeesh97@gmail com</li></ul><p>Feel free to contribute by submitting pull requests or feature suggestions!</p><p>If interested in working together, do drop a DM or mail 🙂</p><hr><h6 id="note">NOTE</h6><blockquote><p><strong>Missing Images</strong>:</p><ul><li>Some of the images may be missing due to unforeseen issues. If you notice any missing images, please inform me</li></ul><p><strong>Code Structure</strong>:</p><ul><li>Not all code snippets follow the same structural order. This is intentional, as some parts are specifically designed to handle their unique mathematical requirements
Priority was given to making each individual piece of code functional rather than ensuring the overall scalability of the project</li></ul><p><strong>AI Assistance</strong>:</p><ul><li>Fair use of AI (e.g., ChatGPT) was employed for syntax suggestions and debugging. Kudos to ChatGPT for its support!</li></ul><p><strong>Math Adaptations</strong>:</p><ul><li>Not every piece of code adheres strictly to its intended mathematical model. Verilog&rsquo;s limitations in computational math have necessitated ample adjustments, with liberties taken to ensure functionality.</li></ul><p><strong>Feedback &amp; Help</strong>:</p><ul><li>Please let me know if you have any suggestions or tips.</li><li>I am in desperate need of help and would greatly appreciate any assistance or advice.</li></ul><p>Thank you for your understanding and support!</p></blockquote><hr><h3 id="selected-image-processing-results">Selected Image Processing Results</h3><p>Below are some of the best results from my image processing work. While there are many more images, including all of them here without relevant explanations wouldn&rsquo;t be meaningful. For a detailed breakdown of the implementation and the mathematical concepts behind each operation, please refer to my repository.</p><h4 id="edge-detection--prewitt-operator">Edge Detection – Prewitt Operator</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="174" src="/images/projects/improve/prew_hu14485036167346296400.webp" alt="Edge Detection using Prewitt Operator" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/prew_hu3609621892283918472.png'"/><h4 id="corner-detection---moravec">Corner Detection - Moravec</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="173" src="/images/projects/improve/moravec_hu4426639061087632241.webp" alt="Corner Detection using Moravec Operator" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/moravec_hu13206110617131018639.png'"/><h4 id="noise-reduction--gaussian-blur">Noise Reduction – Gaussian Blur</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="410" src="/images/projects/improve/blur_hu13931810281779614461.webp" alt="Gaussian Blur for Noise Reduction" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/blur_hu16496045989595046987.png'"/><h4 id="thresholding--otsus-method">Thresholding – Otsu&rsquo;s Method</h4><p><img title="" loading="lazy" decoding="async" class="img  " width="900" height="492" src="/images/projects/improve/otsu_hu7621719573966248452.webp" alt="Otsu Thresholding" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/otsu_hu12720199206830679443.png'"/><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="308" src="/images/projects/improve/otsu-hist_hu13993907817821689128.webp" alt="Otsu Thresholding Histogram" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/otsu-hist_hu13165393985746506984.png'"/></p><h4 id="geometric-transformations">Geometric Transformations</h4><ul><li><strong>Rotation with Same Dimensions</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="201" src="/images/projects/improve/rotcut_hu12403607722010353627.webp" alt="Rotation with Same Dimensions" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/rotcut_hu9108364962968928806.png'"/></li><li><strong>Rotation with Diagonal Dimensions</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="386" src="/images/projects/improve/rotcutfull_hu17031735047347652399.webp" alt="Rotation with Diagonal Dimensions" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/rotcutfull_hu16877135504742872457.png'"/></li><li><strong>Scaling</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="323" src="/images/projects/improve/scale_hu11629296297124285949.webp" alt="Image Scaling" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/scale_hu6655431341958216477.png'"/></li><li><strong>Translation</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="326" src="/images/projects/improve/trans_hu17118263611395243036.webp" alt="Image Translation" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/trans_hu2658960167232227844.png'"/></li><li><strong>Shearing</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="288" src="/images/projects/improve/shear_hu808802054320107791.webp" alt="Image Shearing" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/shear_hu12479457589907686955.png'"/></li><li><strong>Cropping</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="322" src="/images/projects/improve/crop_hu1867138612663489322.webp" alt="Image Cropping" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/crop_hu12490494274397994217.png'"/></li><li><strong>Reflection (Both Axes)</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="328" src="/images/projects/improve/reflect_hu11148049716556324265.webp" alt="Reflection Across Both Axes" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/reflect_hu11740995939101131997.png'"/></li><li><strong>3D Homogeneous Perspective Transformation</strong><img title="" loading="lazy" decoding="async" class="img  " width="900" height="303" src="/images/projects/improve/perspective_hu11774544397983656204.webp" alt="Homogeneous Perspective Transformation" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/perspective_hu860997924819376058.png'"/></li></ul><h4 id="color-and-intensity-transformations">Color and Intensity Transformations</h4><ul><li><strong>Gamma Correction</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="251" src="/images/projects/improve/gamma_hu12647473034062461938.webp" alt="Gamma Correction" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/gamma_hu13031868251393833673.png'"/></li><li><strong>Image Inversion</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="387" src="/images/projects/improve/invert_hu11986350512840661324.webp" alt="Image Inversion" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/invert_hu18030242693197521912.png'"/></li><li><strong>Sepia Effect</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="364" src="/images/projects/improve/sepia_hu4492659394685576999.webp" alt="Sepia Effect" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/sepia_hu15684750827536297281.png'"/></li><li><strong>Negative Transformation</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="381" src="/images/projects/improve/negative_hu5983120251068387285.webp" alt="Negative Transformation" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/negative_hu7509850049545257268.png'"/></li><li><strong>Grayscale Conversion</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="374" src="/images/projects/improve/gray_hu16204671916920617266.webp" alt="Grayscale Conversion" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/gray_hu9130351653664285082.png'"/></li><li><strong>Contrast Adjustment</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="203" src="/images/projects/improve/contrast_hu14946102901654560277.webp" alt="Contrast Adjustment" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/contrast_hu16150499439149074672.png'"/></li><li><strong>Brightness Adjustment</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="373" src="/images/projects/improve/bright_hu3341463385452583707.webp" alt="Brightness Adjustment" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/bright_hu16692706153309742860.png'"/></li><li><strong>Saturation Adjustment</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="221" src="/images/projects/improve/saturation_hu581103770668551537.webp" alt="Saturation Adjustment" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/saturation_hu1114309998585183769.png'"/></li><li><strong>Sharpness Enhancement</strong><br><img title="" loading="lazy" decoding="async" class="img  " width="900" height="201" src="/images/projects/improve/sharpness_hu9178690489823450702.webp" alt="Sharpness Enhancement" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/sharpness_hu18410522331567221241.png'"/></li></ul><p>For more insights into the implementation, visit my repository, where I provide a comprehensive explanation of the mathematical foundations behind each operation.</p><hr><h3 id="proof-of-concept-proposal-fpga-implementation-of-improve"><strong>Proof of Concept Proposal: FPGA Implementation of ImProVe</strong></h3><p>The goal of this proof of concept is to transition<strong>ImProVe</strong> from a Verilog-based image processing simulation to a fully FPGA-compatible implementation. The current approach, while functional, relies heavily on software-based file I/O, lacks real-time processing capabilities, and does not take advantage of hardware acceleration. This proposal outlines a new FPGA-based workflow that optimizes performance, enables parallel processing, and integrates efficient mathematical computation techniques like<strong>CORDIC for trigonometric and square root calculations</strong>.</p><h4 id="current-workflow-and-its-limitations"><strong>Current Workflow and Its Limitations</strong></h4><p>The existing implementation is purely<strong>simulation-based</strong>, using<strong>Icarus Verilog</strong> without testbenches. Images are pre-processed using<strong>Python (NumPy)</strong>, converted into<strong>.hex or .txt</strong> files, and then read into Verilog through file I/O functions. After processing, the results are stored in a corresponding output file, converted back into an image, and visually verified or cross-checked with a reference Python implementation.</p><p>While this approach enables functional validation, it suffers from several limitations:</p><ul><li><strong>File I/O is slow</strong> and does not reflect real-world FPGA-based image processing.</li><li><strong>No hardware optimizations</strong>, making it unsuitable for real-time applications.</li><li><strong>No pipelining or parallelism</strong>, leading to inefficient processing for large images.</li><li><strong>Mathematical operations</strong> (like square root and trigonometric functions) rely on direct computation rather than optimized hardware-friendly methods.</li></ul><h4 id="proposed-fpga-based-workflow"><strong>Proposed FPGA-Based Workflow</strong></h4><p>The<strong>FPGA implementation</strong> will be designed to replace file-based image processing with a<strong>high-speed AXI-based pipeline</strong> that processes images in real time. Key improvements include:</p><h5 id="cordic-for-mathematical-computation"><strong>CORDIC for Mathematical Computation</strong></h5><p>Operations like<strong>image rotation, edge detection, and geometric transformations</strong> require trigonometric functions (sin, cos) and square root calculations. Instead of using costly multipliers or look-up tables, these will be implemented using<strong>CORDIC (COordinate Rotation DIgital Computer)</strong>, which efficiently computes trigonometric functions, logarithms, and square roots in hardware without requiring floating-point arithmetic.</p><h5 id="memory-optimization-ddr-for-image-storage-bram-for-intermediate-buffers"><strong>Memory Optimization: DDR for Image Storage, BRAM for Intermediate Buffers</strong></h5><ul><li><strong>DDR (Dynamic RAM)</strong> will be used to store the original image and final processed output. This allows handling large images without running into FPGA memory constraints.</li><li><strong>BRAM (Block RAM)</strong> will serve as an intermediate buffer, storing smaller<strong>overlapping regions</strong> of the image during processing.</li><li><strong>AXI4 (Advanced eXtensible Interface)</strong> will manage data transfer between<strong>DDR and the processing modules</strong>, ensuring efficient memory access without bottlenecks.</li></ul><h5 id="axi-stream-for-processing-pipelines"><strong>AXI-Stream for Processing Pipelines</strong></h5><p>Rather than processing an image sequentially,<strong>AXI-Stream will enable a pipeline approach</strong>, where multiple processing stages operate in parallel. This allows continuous data flow, reducing latency and improving throughput.</p><h5 id="parallel-processing-using-image-splitting"><strong>Parallel Processing Using Image Splitting</strong></h5><p>For<strong>operations that do not involve geometric transformations</strong>, the image will be<strong>split into overlapping regions</strong> with necessary padding to avoid edge artifacts. These smaller blocks will be processed<strong>simultaneously</strong> and later recombined. This significantly speeds up computation while ensuring accuracy. For<strong>geometric transformations</strong>, special handling will be required to correctly map pixel positions.</p><h5 id="axi-dma-for-efficient-data-transfer"><strong>AXI DMA for Efficient Data Transfer</strong></h5><p>To avoid CPU intervention in moving image data,<strong>AXI DMA (Direct Memory Access)</strong> will be used to transfer pixel data<strong>directly between DDR and processing units</strong>, allowing continuous streaming of images into the pipeline without stalling.</p><h5 id="vgawireless-display-output-optional-enhancement"><strong>VGA/Wireless Display Output (Optional Enhancement)</strong></h5><p>If real-time visualization of processed images is needed, a<strong>VGA output or a wireless display interface (such as HDMI over Wi-Fi or LVDS panels)</strong> can be integrated. This eliminates the need for software-based file conversions and external host reconstruction, allowing direct, real-time monitoring of image processing results. While not mandatory, this enhancement can significantly improve debugging efficiency and system usability.</p><h5 id="testbenches-for-validation"><strong>Testbenches for Validation</strong></h5><p>To ensure<strong>mathematical accuracy</strong>, the new FPGA implementation will include<strong>systematic testbenches</strong> that validate outputs<strong>pixel-by-pixel</strong> against a Python reference. Unlike the current workflow, which relies on visual verification, this will ensure exact mathematical equivalence.</p><h4 id="expected-outcomes"><strong>Expected Outcomes</strong></h4><p>By implementing this optimized FPGA-based workflow,<strong>ImProVe</strong> will transition from a<strong>simulated Verilog project to a real-time, hardware-accelerated image processing system</strong>. The use of<strong>CORDIC, AXI-based memory architecture, parallel processing, pipelining, and real-time display output</strong> will significantly enhance performance, making the system viable for embedded vision applications in robotics, medical imaging, and autonomous systems.</p><p>I&rsquo;m working on the POC in parallel, and as of now, I have implemented square root using CORDIC, though it still requires some fine-tuning. This is just a proposal and may evolve further based on implementation challenges and optimizations needed along the way. The PoC will serve as a proof of concept for all the modules, ensuring they can be adapted for FPGA implementation. By the end, I aim to demonstrate at least one module as synthesizable and successfully implement it on an FPGA board.</p>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/improve/never/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/improve/never/</guid><description>&lt;![CDATA[<h2 id="never-neural-network-in-veriloghttpsgithubcommummanajagadeeshnever"><a href="https://github.com/Mummanajagadeesh/NeVer" target="_blank">NeVer: NEural NEtwork in VERilog</a></h2><h5 id="do-checkout-main-project-improve-image-processing-using-veriloghttpmummanajagadeeshgithubioprojectsimprove">Do Checkout Main Project:<strong><a href="http://mummanajagadeesh.github.io/projects/improve/" target="_blank">ImProVe: IMage PROcessing using VErilog</a></strong></h5><table><thead><tr><th><strong>Name</strong></th><th>NeVer</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>NeVer implements a neural network in Verilog for better hardware acceleration of image processing tasks</td></tr><tr><td><strong>Start</strong></td><td>28 Feb 2025</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/NeVer" target="_blank">NeVer🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Image Processing, HDL, Computer Vision, Programming, ML</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Perl, TCL, Quartus, Python, NumPy</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Active)</td></tr><tr><td><strong>Progress</strong></td><td>- Implemented detection of MNIST digits (0-9)<br> - Added support for EMNIST, enabling classification of 62 character classes<br> - Integrated real-time inference with a Tkinter-based character drawing interface, achieving sub-5s latency per prediction in simulation</td></tr><tr><td><strong>Next Steps</strong></td><td>- Ensure the top module is synthesizable by eliminating the use of the<code>real</code> data type<br> - Optimize the design for parallel processing, leveraging Multiply-Accumulate (MAC) operations<br> - Enhance floating-point multiplication and division support for improved computational efficiency</td></tr></tbody></table><hr><h4 id="project-overview"><strong>Project Overview</strong></h4><p>This project presents a novel, fully hardware-based neural network inference pipeline in Verilog, targeting the 62-class EMNIST dataset (digits + upper/lowercase letters). The design exclusively uses IEEE 754 floating-point arithmetic, with no fixed-point approximations or external IP cores.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="never-neural-network-in-veriloghttpsgithubcommummanajagadeeshnever"><a href="https://github.com/Mummanajagadeesh/NeVer" target="_blank">NeVer: NEural NEtwork in VERilog</a></h2><h5 id="do-checkout-main-project-improve-image-processing-using-veriloghttpmummanajagadeeshgithubioprojectsimprove">Do Checkout Main Project:<strong><a href="http://mummanajagadeesh.github.io/projects/improve/" target="_blank">ImProVe: IMage PROcessing using VErilog</a></strong></h5><table><thead><tr><th><strong>Name</strong></th><th>NeVer</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>NeVer implements a neural network in Verilog for better hardware acceleration of image processing tasks</td></tr><tr><td><strong>Start</strong></td><td>28 Feb 2025</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/NeVer" target="_blank">NeVer🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Image Processing, HDL, Computer Vision, Programming, ML</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Perl, TCL, Quartus, Python, NumPy</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Active)</td></tr><tr><td><strong>Progress</strong></td><td>- Implemented detection of MNIST digits (0-9)<br> - Added support for EMNIST, enabling classification of 62 character classes<br> - Integrated real-time inference with a Tkinter-based character drawing interface, achieving sub-5s latency per prediction in simulation</td></tr><tr><td><strong>Next Steps</strong></td><td>- Ensure the top module is synthesizable by eliminating the use of the<code>real</code> data type<br> - Optimize the design for parallel processing, leveraging Multiply-Accumulate (MAC) operations<br> - Enhance floating-point multiplication and division support for improved computational efficiency</td></tr></tbody></table><hr><h4 id="project-overview"><strong>Project Overview</strong></h4><p>This project presents a novel, fully hardware-based neural network inference pipeline in Verilog, targeting the 62-class EMNIST dataset (digits + upper/lowercase letters). The design exclusively uses IEEE 754 floating-point arithmetic, with no fixed-point approximations or external IP cores.</p><p>All core operations — matrix multiplication, bias addition, ReLU activation, and argmax — are implemented from scratch in Verilog. Python is used only for generating memory modules, while TCL and Perl scripts automate simulation workflows, memory regeneration, and output logging.</p><img title="" loading="lazy" decoding="async" class="img  " width="400" height="400" src="/images/projects/improve/never/conf-matrix_hu5487398584044323538.webp" alt="conf-mat" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/conf-matrix_hu6037535118215526641.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><p>Focusing more on inference and preprocessing than training, this open-source setup achieves >90% training accuracy (>70% dev acc) and >75% Verilog-level classification accuracy, with average image inference latency ~3.4s.</p><p>This work demonstrates a practical, automation-driven hardware design, enabling reproducible and scalable NN inference on real-world data using only open-source tools.</p><hr><h6 id="note">NOTE:</h6><p>I highly recommend checking out the main project, as this is just a subset. The main project focuses on image processing algorithms, and working on<a href="../">ImProVe (IMage PROcessing using VErilog)</a> has made the learning curve for this project much easier.</p><p>NeVer (Neural Network in Verilog) is one of my favorite subprojects under ImProVe. In this subproject, my goal is to implement a fully functional neural network purely in Verilog and optimize it for efficient hardware acceleration.</p><p>Please note that the names of these projects are not meant to be taken too seriously. The names like ImProVe or NeVer may not fully reflect their functions – ImProVe doesn’t actually improve images, but processes them, and NeVer isn&rsquo;t about something &ldquo;never-implemented&rdquo; – many have done it before. The names just make it easier for me to organize folders and code</p><h4 id="motivation"><strong>Motivation</strong></h4><p>I was inspired by this video:<a href="https://www.youtube.com/watch?v=w8yWXqWQYmU&amp;ab_channel=SamsonZhang" target="_blank">Building a neural network FROM SCRATCH (no TensorFlow/PyTorch, just NumPy &amp; math)</a> by<strong>Samson Zhang</strong>. The video demonstrates a simple 2 layer neural network for recognizing MNIST digits (0-9)</p><p>I expanded on this by:</p><ul><li>Using<strong>two hidden layers</strong> instead of none</li><li>Implementing<strong>Adam optimizer</strong> along with<strong>vanilla SGD</strong>, replacing basic gradient descent</li><li>Extending support for<strong>62 classes</strong> (0-9, A-Z, a-z)</li><li>Using<strong>Verilog</strong> for inference instead of Python</li><li>Incorporating<strong>Tkinter</strong> for manually inputting handwritten characters irl, allowing direct interaction with the trained model</li></ul><h4 id="project-roadmap"><strong>Project Roadmap</strong></h4><ol><li>Train a model using<strong>TensorFlow/PyTorch</strong> for quick validation → Infer in Python</li><li>Train using<strong>NumPy only</strong> → Infer in Python</li><li>Train using<strong>NumPy only</strong> → Infer in Verilog</li><li>Train using<strong>pure Python (no NumPy, user-defined functions)</strong> → Infer in Verilog</li><li>Implement a<strong>single neuron in Verilog</strong> for training</li><li>Train<strong>directly in Verilog</strong> → Infer in Verilog</li><li><strong>Optimize</strong> the implementation using<strong>parallel processing, MAC units, etc.</strong></li><li>Make the<strong>entire Verilog implementation synthesizable</strong></li></ol><hr><h4 id="current-status"><strong>Current Status</strong></h4><ul><li>Successfully performed inference in Verilog using parameters trained in<strong>Python</strong> (Colab) with<strong>NumPy</strong> , achieving<strong>>90% accuracy (>70% dev acc)</strong> on the test dataset</li><li>Implemented inference for both<strong>MNIST (digits 0-9)</strong> and<strong>EMNIST (62 classes: 0-9, A-Z, a-z)</strong></li><li>Training with<strong>2000 iterations</strong>:<ul><li><strong>First 1500 iterations</strong>: Adam optimizer</li><li><strong>Last 500 iterations</strong>: Vanilla SGD (Reason: Adam converges faster initially, but switching to SGD helps refine convergence | Later switched to<strong>&ldquo;SGD with Momentum&rdquo;</strong>)</li></ul></li><li>Using<strong>Tkinter</strong> for drawing input characters, which are then processed and fed into Verilog for inference</li><li>Achieved<strong>&lt;5s inference latency</strong> per prediction in simulation with FSM-driven layer evaluation</li><li>Actively working on<strong>image reconstruction</strong> from NumPy-trained model parameters</li><li>Replacing<code>real</code><strong>(IEEE 754)</strong> in Verilog top module with fixed-point formats like<strong>Q32.32, Q32.16, Q24.8 using sfixed from IEEE 1076.3 (ieee.fixed_pkg)</strong><ul><li>Aiming for better synthesis compatibility, but currently observing<strong>accuracy loss</strong> due to quantization</li><li>Actively tuning<strong>fixed-point precision</strong> to balance accuracy and hardware performance</li><li><strong>Exploring Quantization Aware Training (QAT)</strong> to precondition the model for quantization effects during training and recover lost accuracy</li></ul></li></ul><hr><h4 id="current-workflow"><strong>Current Workflow</strong></h4><ol><li><strong>Image Processing</strong>:<code>draw.py</code> → Converts the Tkinter drawing into<code>drawing.jpg</code></li><li><strong>Grayscale Image Conversion</strong>:<code>img2bin.py</code> → Generates<code>mnist_single_no.txt</code> (integer values from 0-255)</li><li><strong>Vectorization</strong>:<code>arr2row.v</code> → Flattens the<strong>2D 28×28</strong> matrix into<code>input_vector.txt</code> after preprocessing</li><li><strong>Memory Preloading</strong>:<code>memloader_from_inp_vec.py</code> → Converts<code>input_vector.txt</code> into Verilog memory (<code>image_memory.v</code>)</li><li><strong>Weight &amp; Bias Preloading</strong>:<code>wtbs_loader.py</code> → Converts pretrained weight &amp; bias TXT files into Verilog memory (<code>W1_memory.v</code>,<code>b1_memory.v</code>, etc.)</li><li><strong>Inference in Verilog</strong>:<code>emnist_with_tb.v</code> → Top module:<code>emnist.v</code></li></ol><h5 id="folder-structure"><strong>Folder Structure</strong></h5><p>Can be found in the<code>/clean</code> directory under the emnist folders in the repo</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>.</span></span><span style="display:flex;"><span>├───bin/<span style="color:#75715e"># Intermediate image text files</span></span></span><span style="display:flex;"><span>│ └───*.txt</span></span><span style="display:flex;"><span>├───build/<span style="color:#75715e"># Compiled Verilog simulation output</span></span></span><span style="display:flex;"><span>│ └───*.vvp</span></span><span style="display:flex;"><span>├───data/<span style="color:#75715e"># Stores trained model parameters and images</span></span></span><span style="display:flex;"><span>│ ├───biases/<span style="color:#75715e"># Text files containing trained bias values</span></span></span><span style="display:flex;"><span>│ │ └───*.txt</span></span><span style="display:flex;"><span>│ ├───weights/<span style="color:#75715e"># Text files containing trained weight values</span></span></span><span style="display:flex;"><span>│ │ └───*.txt</span></span><span style="display:flex;"><span>│ └───*.png<span style="color:#75715e"># Image files</span></span></span><span style="display:flex;"><span>├───metrics-setup/<span style="color:#75715e"># Evaluation metrics and related resources</span></span></span><span style="display:flex;"><span>│ conf-matrix.png</span></span><span style="display:flex;"><span>│ dataset.py</span></span><span style="display:flex;"><span>│ emnist_byclass_1000.csv</span></span><span style="display:flex;"><span>│ metrics-report.txt</span></span><span style="display:flex;"><span>│ metrics.py</span></span><span style="display:flex;"><span>├───run/<span style="color:#75715e"># Setup and automation scripts for different platforms</span></span></span><span style="display:flex;"><span>│ ├───linux-or-macOs/<span style="color:#75715e"># Setup and automation scripts for Linux or macOS</span></span></span><span style="display:flex;"><span>│ │ └───Makefile<span style="color:#75715e"># Makefile for automating simulation/build steps</span></span></span><span style="display:flex;"><span>│ ├───perl/<span style="color:#75715e"># Scripts for automating simulation and clean-up (Perl)</span></span></span><span style="display:flex;"><span>│ │ └───*.pl</span></span><span style="display:flex;"><span>│ ├───python/<span style="color:#75715e"># Scripts for automating simulation and clean-up (Python)</span></span></span><span style="display:flex;"><span>│ │ └───*.py</span></span><span style="display:flex;"><span>│ ├───tcl/<span style="color:#75715e"># Scripts for automating simulation and clean-up (TCL)</span></span></span><span style="display:flex;"><span>│ │ └───*.tcl</span></span><span style="display:flex;"><span>│ └───windows/<span style="color:#75715e"># Setup and automation scripts for Windows</span></span></span><span style="display:flex;"><span>│ └───*.bat</span></span><span style="display:flex;"><span>├───scripts/<span style="color:#75715e"># Python scripts for image preprocessing</span></span></span><span style="display:flex;"><span>│ └───*.py</span></span><span style="display:flex;"><span>├───sim/<span style="color:#75715e"># Test benches for verifying Verilog modules</span></span></span><span style="display:flex;"><span>│ └───*.v</span></span><span style="display:flex;"><span>└───src/<span style="color:#75715e"># Source Verilog code</span></span></span><span style="display:flex;"><span> ├───image/<span style="color:#75715e"># Image memory modules</span></span></span><span style="display:flex;"><span> │ └───*.v</span></span><span style="display:flex;"><span> ├───params/<span style="color:#75715e"># Memory modules for weights and biases</span></span></span><span style="display:flex;"><span> │ └───*.v</span></span><span style="display:flex;"><span> └───top/<span style="color:#75715e"># Top-level design module and supporting modules</span></span></span><span style="display:flex;"><span> └───*.v</span></span></code></pre></div><table><thead><tr><th><strong>Platform</strong></th><th><strong>Command</strong></th></tr></thead><tbody><tr><td><strong>Windows</strong></td><td><code>cd path-to-clean-dir/</code><br><code>./run/win32/setup.bat</code></td></tr><tr><td><strong>Linux/macOS</strong></td><td><code>cd path-to-clean-dir/run/</code><br><code>make</code></td></tr><tr><td><strong>Perl (Cross-Platform)</strong></td><td><code>cd path-to-clean-dir/</code><br><code>perl ./run/perl/workflow.pl</code></td></tr><tr><td><strong>Tcl (Cross-Platform)</strong></td><td><code>cd path-to-clean-dir/</code><br><code>tclsh ./run/tcl/workflow.tcl</code></td></tr></tbody></table><h5 id="command-workflow">Command Workflow</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd path-to-clean-dir/<span style="color:#75715e"># navigate to your project directory</span></span></span><span style="display:flex;"><span>python ./scripts/draw.py<span style="color:#75715e"># opens a Tkinter interface to draw an image by hand</span></span></span><span style="display:flex;"><span>python ./scripts/img2bin.py<span style="color:#75715e"># converts the drawn image into a text-based binary file</span></span></span><span style="display:flex;"><span>iverilog -o ./build/imgvec.vvp ./src/*.v<span style="color:#75715e"># compiles Verilog code that returns a 1D vector after all preprocessing</span></span></span><span style="display:flex;"><span>vvp ./build/imgvec.vvp<span style="color:#75715e"># runs the compiled imgvec Verilog simulation</span></span></span><span style="display:flex;"><span>python ./scripts/wtbs_loader.py<span style="color:#75715e"># (only needed for first build) generates weight and bias memory Verilog files</span></span></span><span style="display:flex;"><span>python ./scripts/memloader_from_inp_vec.py<span style="color:#75715e"># loads the converted image vector into the image_memory module</span></span></span><span style="display:flex;"><span>iverilog -o build/prediction_test.vvp ./sim/*.v ./src/top/*.v ./src/image/*.v ./src/params/*.v<span style="color:#75715e"># compiles entire prediction design</span></span></span><span style="display:flex;"><span>vvp ./build/prediction_test.vvp<span style="color:#75715e"># runs the compiled prediction simulation</span></span></span></code></pre></div><h5 id="state-diagram-generated-using-graphviz-tool">State Diagram (generated using GraphViz tool)</h5><img title="" loading="lazy" decoding="async" class="img  " width="312" height="800" src="/images/projects/improve/never/fsm_hu15678127029425495858.webp" alt="FSM Mealy" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/fsm_hu16096606119419844844.png'"/><hr><h5 id="memory-initialization">Memory Initialization</h5><ul><li><strong>Structure &amp; Initialization</strong>: A simple<code>reg [WIDTH-1:0] mem [0:DEPTH-1];</code> array whose entries are hard‑coded in an<code>initial</code> block at elaboration time, causing the synthesis tool to bake those constants into the FPGA configuration bitstream citeturn0search6.</li><li><strong>Run‑Time Behavior</strong>: Acts as a pure, read‑only memory (ROM)—you present an address, and on the next clock (or combinationally, depending on inference) you get the stored value. No write ports or file‑I/O occur after configuration citeturn1search1.</li><li><strong>Implementation Styles</strong>:<ul><li><strong>Small arrays</strong> (tens to low hundreds of bits) typically map to<strong>distributed LUT‑RAM</strong>.</li><li><strong>Larger arrays</strong> (kilobits) are inferred as<strong>dedicated block RAM</strong> macros.</li></ul></li><li><strong>Why This Pattern</strong>: Embedding all data directly in RTL avoids reliance on external files and runtime system tasks like<code>$readmemh</code>,<code>$fopen</code> or custom parsers. That makes simulation setups simpler (no file‑path issues), keeps testbenches file‑agnostic, and ensures cross‑tool portability and deterministic initialization.</li></ul><h4 id="technical-details"><strong>Technical Details</strong></h4><ul><li>The<strong>top module</strong> (<code>emnist.v</code>) follows an<strong>FSM-based approach</strong> with minimal to no overlap</li><li><strong>Softmax Approximation</strong>: Using<strong>Taylor series expansion</strong> for exponentiation</li><li><strong>Pipeline Strategy</strong>:<ul><li><strong>Currently</strong>: Using<strong>coarse-grained pipelining</strong>, meaning major computation blocks execute sequentially with some latency</li><li><strong>Next Steps</strong>: Implement<strong>fine-grained pipelining</strong>, where smaller operations are parallelized for higher throughput</li></ul></li></ul><hr><h4 id="to-do"><strong>To-Do</strong></h4><ul><li>Implement<strong>LUTs</strong> for efficient exponential computation in Softmax</li><li>Remove the<strong><code>real</code> datatype</strong> in the top module to ensure full synthesizability</li><li>Extend support for<strong>all ASCII characters</strong> (optional)</li><li>Enable<strong>OCR functionality</strong> to detect any character in a given image</li><li>Optimize for<strong>parallel processing</strong>,<strong>better pipelining</strong>, and<strong>hardware acceleration</strong></li></ul><hr><h4 id="demos"><strong>Demos</strong></h4><p>Here are some demo videos</p><h5 id="mnist-digit-recognition"><strong>Mnist Digit Recognition</strong></h5><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/QtkdWSq25zQ" frameborder="0" allowfullscreen=/></div></div><p><br><br/><ul><li><p>I developed a<strong>fully connected neural network</strong> from scratch in<strong>Google Colab</strong>, avoiding frameworks like<strong>TensorFlow</strong> and<strong>Keras</strong>. Instead, I relied on<strong>NumPy</strong> for numerical operations,<strong>Pandas</strong> for data handling, and<strong>Matplotlib</strong> for visualization. The model was trained on<strong>sample_data/mnist_train_small.csv</strong>, a dataset containing flattened<strong>784-pixel images</strong> of handwritten digits. Data preprocessing included<strong>normalizing pixel values</strong> (dividing by<strong>255</strong>) and splitting the dataset into a<strong>training set</strong> and a<strong>development set</strong>, with the first<strong>1000 samples</strong> reserved for validation. The dataset was shuffled before training to enhance randomness, and labels (digits 0-9) were stored separately</p></li><li><p>The network architecture consists of an<strong>input layer (784 neurons)</strong>, a<strong>hidden layer (128 neurons, ReLU activation)</strong>, and an<strong>output layer (10 neurons, softmax activation)</strong>. Model parameters (weights and biases) were initialized randomly and updated via<strong>gradient descent</strong> over<strong>500 iterations</strong> with a learning rate of<strong>0.1</strong>. Training followed the standard<strong>forward propagation</strong> for computing activations and<strong>backpropagation</strong> for updating parameters. Accuracy was recorded every<strong>10 iterations</strong>. To ensure compatibility with<strong>Verilog</strong>, all weights and biases were<strong>scaled by 10,000</strong> and stored as<strong>integer values</strong> in text files (<code>W1.txt</code>,<code>b1.txt</code>, etc.), eliminating the need for<strong>floating-point operations</strong> in hardware. These trained parameters were later used for inference on new images, verifying accuracy on the<strong>development set</strong> before deployment in Verilog for real-time classification</p></li><li><p>The trained model, based on<strong>sample_data/mnist_train_small.csv</strong>, achieved<strong>over 90% accuracy</strong>. It generates<code>W1</code>,<code>W2</code>,<code>b1</code>, and<code>b2</code> text files containing weight and bias values. These parameters are used in Verilog to predict digits from an<strong>input image</strong> stored in<code>input_vector.txt</code>, formatted as<strong>784 space-separated integers</strong>. The Verilog module reads this data, performs inference, and displays the predicted output using<code>$display</code>. The original CSV file was converted into a<strong>space-separated text format</strong>, where each row contains a digit followed by<strong>784 pixel values (785 total)</strong>. During inference, the first value (label) is discarded, ensuring the model classifies the input image without prior knowledge of its actual label</p></li><li><p>The<strong>Verilog implementation</strong> of the neural network consists of an<strong>input layer (784 neurons)</strong>, a<strong>hidden layer (128 neurons)</strong>, and an<strong>output layer (10 neurons)</strong>. It loads<strong>pre-trained weights and biases</strong> from<code>W1.txt</code>,<code>b1.txt</code>,<code>W2.txt</code>, and<code>b2.txt</code>, along with an<strong>input vector</strong> from<code>input_vector.txt</code>. Input values are<strong>normalized</strong> by dividing by<strong>255.0</strong>, while weights and biases are<strong>scaled by 10,000</strong> for fixed-point arithmetic. The hidden layer applies a<strong>fully connected transformation</strong> (<code>W1 * input + b1</code>) followed by<strong>ReLU activation</strong>, while the output layer computes another weighted sum (<code>W2 * hidden + b2</code>). Instead of applying softmax, the model identifies the predicted class by selecting the index of the<strong>highest output value</strong></p></li><li><p>The module ensures correct file reading before computation begins. Forward propagation is executed sequentially, with an initial delay for<strong>loading weights, biases, and input values</strong>. After processing activations in both layers, the output layer iterates through its neurons to determine the class with the highest activation. The classification result is displayed via<code>$display</code>. This hardware implementation<strong>bypasses complex activation functions</strong> like softmax while maintaining classification accuracy through direct maximum-value selection</p></li><li><p>In the latest iterations,<strong>Python scripts</strong> convert text-based weight and bias files into<strong>synthesizable Verilog memory blocks</strong>. These are stored in<strong>register modules</strong>, which are instantiated in the<strong>top-level module</strong>. The image input is handled in a similar way</p></li><li><p>Currently, the<strong>top module</strong> includes a few non-synthesizable constructs, such as<code>$display</code>,<code>$finish</code>, and the<strong><code>real</code> datatype</strong>. These were relocated to the testbench in later versions to improve synthesizability. Additionally, I am replacing<code>real</code> with a<strong>fixed-point representation (Q24.8)</strong> to make the design fully synthesizable. Future versions will output the classification result to a<strong>seven-segment display</strong> via<strong>case statements</strong>, replacing<code>$display</code></p></li><li><p>Moving forward, I am working on transitioning<strong>training from Python to Verilog</strong>, aiming to implement a fully<strong>synthesizable neural network</strong> for hardware-based learning and inference</p></li></ul><hr><h5 id="emnist-character-recognition"><strong>EMNIST Character Recognition</strong></h5><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/7YccFUtydM0" frameborder="0" allowfullscreen=/></div></div><p><br><br/><p>This model is trained on the<strong>EMNIST ByClass dataset</strong> (<a href="https://greg-cohen.com/datasets/emnist/" target="_blank">source</a>), which includes<strong>62 character classes</strong>—digits (<code>0-9</code>), uppercase letters (<code>A-Z</code>), and lowercase letters (<code>a-z</code>). The dataset undergoes preprocessing, where it is converted into a<strong>CSV format</strong>, normalized, reduced in dimensionality, and shuffled before training to improve generalization</p><h6 id="neural-network-architecture"><strong>Neural Network Architecture</strong></h6><p>The model consists of multiple layers:</p><ul><li><strong>Input Layer</strong>:<strong>784 neurons</strong> (28×28 grayscale pixel values)</li><li><strong>First Hidden Layer</strong>:<strong>256 neurons</strong> (<code>W1: 256×784</code>,<code>b1: 256×1</code>)</li><li><strong>Second Hidden Layer</strong>:<strong>128 neurons</strong> (<code>W2: 128×256</code>,<code>b2: 128×1</code>)</li><li><strong>Output Layer</strong>:<strong>62 neurons</strong> (<code>W3: 62×128</code>,<code>b3: 62×1</code>)</li></ul><h6 id="training-process"><strong>Training Process</strong></h6><p>The network is trained using<strong>forward propagation</strong>, where activations are computed at each layer through<strong>matrix multiplications</strong> and<strong>ReLU activation functions</strong> for hidden layers.<strong>Backpropagation</strong> is used to update weights based on the gradient of the loss function. The dataset is shuffled before each epoch to prevent overfitting. The model is trained over multiple epochs using a combination of<strong>Stochastic Gradient Descent (SGD)</strong> and the<strong>Adam optimizer</strong> to improve convergence</p><p>To ensure compatibility with hardware, weights and biases are<strong>scaled by 10,000</strong> and stored as integers in text files (<code>W1.txt</code>,<code>b1.txt</code>, etc.), since Verilog does not support floating-point arithmetic</p><h6 id="inference-in-verilog"><strong>Inference in Verilog</strong></h6><p>The inference process in Verilog follows a similar structure but accommodates additional layers and character classes. Input images are read from<code>input_vector.txt</code>, normalized, and processed through the neural network using preloaded weights and biases. The computation follows:</p><ul><li><code>hidden1 = ReLU(W1 * input + b1)</code></li><li><code>hidden2 = ReLU(W2 * hidden1 + b2)</code></li><li><code>output = W3 * hidden2 + b3</code></li></ul><p>The<strong>index of the maximum output value</strong> corresponds to the predicted character, which is mapped to<code>"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"</code> and displayed using<code>$display</code></p><hr><h6 id="pipeline-and-data-flow"><strong>Pipeline and Data Flow</strong></h6><p>The following scripts handle image processing, vectorization, and memory loading for Verilog inference:</p><ol><li><strong>Drawing &amp; Image Processing</strong>:<ul><li><code>draw.py</code>: Creates a square canvas in Tkinter for character input</li><li>After drawing, the script<strong>grayscales, inverts, compresses</strong> the image to<strong>28×28 resolution</strong>, and saves it as<code>drawing.jpg</code></li></ul></li><li><strong>Data Conversion &amp; Preprocessing</strong>:<ul><li><code>img2bin.py</code>: Converts<code>drawing.jpg</code> into a<strong>28×28</strong> grayscale pixel matrix (<code>mnist_single_no.txt</code>)</li><li><code>Other Verilog Files</code>: Flattens the<strong>2D array</strong> into a<strong>1D vector (784 values)</strong> and stores it in<code>input_vector.txt</code> after all preprocessing</li></ul></li><li><strong>Memory Module Generation</strong>:<ul><li><code>memloader_from_inp_vec.py</code>: Converts<code>input_vector.txt</code> into a<strong>synthesizable Verilog memory module</strong> (<code>image_memory.v</code>)</li><li><code>wtbs_loader.py</code>: Converts<code>W1</code>,<code>W2</code>,<code>W3</code>,<code>b1</code>,<code>b2</code>,<code>b3</code> into Verilog memory modules (<code>W1_memory.v</code>,<code>b1_memory.v</code>, etc.)</li></ul></li></ol><h6 id="final-hardware-implementation"><strong>Final Hardware Implementation</strong></h6><p>All these components are instantiated in the<strong>top module</strong> (<code>emnist_with_tb.v</code>), along with a<strong>testbench</strong> (<code>emnist_nn_tb.v</code>). The system successfully predicts handwritten characters in real-time</p><p>In the<strong>demo</strong>, I tested the characters<strong>&ldquo;H&rdquo;</strong>,<strong>&ldquo;f&rdquo;</strong>, and<strong>&ldquo;7&rdquo;</strong>, each representing different EMNIST subclasses (uppercase letters, lowercase letters, and numbers)</p><p>Additionally, I implemented a<strong>coarse-grained pipelined</strong> fully connected neural network using a<strong>Finite State Machine (FSM)</strong>, integrating a<strong>Softmax function approximation</strong> via<strong>Taylor series expansion</strong> to improve computational efficiency</p><h4 id="raw-demo-shots-present"><strong>Raw Demo Shots (Present)</strong></h4><table><thead><tr><th><strong>UpperCase Alphabet</strong></th><th><strong>LowerCase Alphabet</strong></th><th><strong>Single Digit Number</strong></th></tr></thead><tbody/></table><table><thead><tr><th><strong>Actual: R</strong></th><th><strong>Prediction: R</strong></th><th><strong>Actual: i</strong></th><th><strong>Prediction: i</strong></th><th><strong>Actual: 9</strong></th><th><strong>Prediction: 9</strong></th></tr></thead><tbody/></table><table><thead><tr><th><img title="" loading="lazy" decoding="async" class="img  " width="300" height="" src="/images/projects/improve/never/R.gif" alt="R" onerror="this.onerror='null';this.src=''"/></th><th><img title="" loading="lazy" decoding="async" class="img  " width="300" height="" src="/images/projects/improve/never/i.gif" alt="i" onerror="this.onerror='null';this.src=''"/></th><th><img title="" loading="lazy" decoding="async" class="img  " width="300" height="" src="/images/projects/improve/never/9.gif" alt="9" onerror="this.onerror='null';this.src=''"/></th></tr></thead><tbody/></table><hr><p><br><br/><h4 id="python-based-pre-processing-workflow-present"><strong>Python Based Pre-processing Workflow (Present)</strong></h4><h6 id="user-is-instructed-to-fill-the-canvas-to-skip-roi-steps">USER is instructed to fill the canvas to skip ROI steps</h6><table><thead><tr><th><strong>Original Drawing</strong></th><th><strong>Grayscale Image</strong></th><th><strong>Inverted Image</strong></th><th><strong>Text Matrix</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/never/drawing_hu7604631846354931858.webp" alt="Org Drawing" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/drawing_hu8736920588309233533.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/never/drawing_gray_hu3511351280517116919.webp" alt="Grayscale Image" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/drawing_gray_hu7715874099881084237.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="300" src="/images/projects/improve/never/drawing_inverted_hu3697581726023509312.webp" alt="Inverted Image" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/drawing_inverted_hu11760880882804386543.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="300" height="299" src="/images/projects/improve/never/drawing_txt_hu17486549095957681256.webp" alt="Text Matrix" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/drawing_txt_hu10590190510516464712.png'"/></td></tr></tbody></table><h4 id="verilog-based-pre-processing-workflow-currently-working-to-refine"><strong>Verilog Based Pre-processing Workflow (Currently Working to Refine)</strong></h4><h6 id="exploring-bus-interconnection-options-for-automated-workflow">Exploring bus interconnection options for automated workflow</h6><table><thead><tr><th><strong>Original</strong></th><th><strong>Downscaled (28×28)</strong></th><th><strong>Grayscale</strong></th><th><strong>Contrasted</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/drawing_hu1515344941628565204.webp" alt="Original" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/drawing_hu16435580804023852138.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/rgb_28_hu14166471280705930250.webp" alt="Downscaled" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/rgb_28_hu6266001371535048932.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/gray_28_hu4992105441641055551.webp" alt="Grayscale" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/gray_28_hu13016660379851694155.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/grayc_28_hu3447728377997936472.webp" alt="Contrasted" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/grayc_28_hu6213978014386972709.png'"/></td></tr></tbody></table><table><thead><tr><th><strong>Edge Detection</strong></th><th><strong>Bounding Box</strong></th><th><strong>Box Overlayed</strong></th><th><strong>Region of Interest</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/sumapp_hu15143006666132997661.webp" alt="Edge Detection" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/sumapp_hu11164070108565330868.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/bound_box_hu6228274439683593736.webp" alt="Bounding Box" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/bound_box_hu178931425381335888.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/box_overlayed_hu11596744056304868555.webp" alt="Box Overlayed" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/box_overlayed_hu15207126818694839310.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/roi_hu3047610927322957338.webp" alt="ROI" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/roi_hu12281553277238620362.png'"/></td></tr></tbody></table><table><thead><tr><th><strong>ROI Zoom to Fit</strong></th><th><strong>ROI Resized 28x28</strong></th><th><strong>ROI Padded</strong></th><th><strong>Inverted</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="186" src="/images/projects/improve/never/ver-preproc/rois_hu7405114600055354267.webp" alt="ROI Zoom" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/rois_hu14035689464999479841.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/roi_28_hu7260640604237741536.webp" alt="ROI Resized" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/roi_28_hu2601496394108596961.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/roip_28_hu9993718221367654718.webp" alt="ROI Padded" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/roip_28_hu3544808776478085537.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/roipi_28_hu7882417018886188009.webp" alt="Inverted" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/roipi_28_hu11662865066759029727.png'"/></td></tr></tbody></table><table><thead><tr><th><strong>Mirrored (Vertical Axis)</strong></th><th><strong>Rotated 90° CCW</strong></th></tr></thead><tbody><tr><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/roipim_28_hu14295889213870398003.webp" alt="Mirrored" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/roipim_28_hu11944874041251940418.png'"/></td><td><img title="" loading="lazy" decoding="async" class="img  " width="200" height="200" src="/images/projects/improve/never/ver-preproc/roipimr_28_hu13912437442492946402.webp" alt="Rotated 90 CCW" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/ver-preproc\/roipimr_28_hu9277075931893855879.png'"/></td></tr></tbody></table><table><thead><tr><th><strong>File</strong></th><th><strong>What it Does</strong></th><th><strong>Why It&rsquo;s Done</strong></th><th><strong>Output</strong></th></tr></thead><tbody><tr><td><code>draw.py</code></td><td>User draws a character</td><td>Generates the initial input</td><td><code>drawing.png</code></td></tr><tr><td><code>img2rgb.py</code></td><td>Splits image into R, G, B channels</td><td>Needed for hardware-friendly memory modules</td><td><code>r_memory.v</code>,<code>g_memory.v</code>,<code>b_memory.v</code></td></tr><tr><td><code>downscale.v</code></td><td>Downscales 600×600 image to 28×28</td><td>Inference work on 28×28 inputs</td><td><code>r_memory_28.v</code>,<code>g_memory_28.v</code>,<code>b_memory_28.v</code></td></tr><tr><td><code>grayscale.v</code></td><td>Converts RGB to grayscale</td><td>Removes color bias, simplifies processing</td><td><code>gray_28.png</code></td></tr><tr><td><code>contrast.v</code></td><td>Enhances contrast</td><td>Makes strokes stand out better</td><td><code>grayc_28.png</code></td></tr><tr><td><code>prewitt.v</code></td><td>Applies Prewitt edge detection</td><td>Finds the outline of the character</td><td><code>sumapp.png</code></td></tr><tr><td><code>bound.v</code></td><td>Detects bounding box from edge outline</td><td>Identifies Region of Interest (ROI)</td><td><code>bound_box.png</code></td></tr><tr><td><code>boxcut.v</code></td><td>Applies bounding box to mask out external pixels</td><td>Isolates the character region</td><td><code>roi.png</code></td></tr><tr><td><code>boxcutF.v</code></td><td>Crops the ROI and zooms to fit the canvas</td><td>Removes zero-padding, centers the content</td><td><code>rois.png</code></td></tr><tr><td><code>resize.v</code></td><td>Resizes cropped ROI to 28×28</td><td>Standardizes input size for neural network</td><td><code>roi_28.png</code></td></tr><tr><td><code>padding.v</code></td><td>Adds 1-pixel padding on all sides, resizes again to 28×28</td><td>Adds margin, keeps stroke intact</td><td><code>roip_28.png</code></td></tr><tr><td><code>mirror.v</code></td><td>Mirrors image about the vertical axis</td><td>Matches EMNIST character orientation</td><td><code>roipim_28.png</code></td></tr><tr><td><code>rotate.v</code></td><td>Rotates image 90° counter-clockwise</td><td>Final transformation to match EMNIST format</td><td><code>roipimr_28.png</code></td></tr><tr><td><code>mat2row.v</code></td><td>Converts 28x28 matrix to 784 length vector</td><td>To vectorise the input</td><td><code>input_vector.txt</code></td></tr></tbody></table><p>UPDATED WORKFLOW</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Step 1: Drawing</span></span><span style="display:flex;"><span> - draw.py → drawing.png</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>Step 2: Image Preprocessing</span></span><span style="display:flex;"><span> - img2rgb.py → r_memory.v, g_memory.v, b_memory.v</span></span><span style="display:flex;"><span> - downscale.v → r_memory_28.v, g_memory_28.v, b_memory_28.v</span></span><span style="display:flex;"><span> - grayscale.v → gray_28.png</span></span><span style="display:flex;"><span> - contrast.v → grayc_28.png</span></span><span style="display:flex;"><span> - prewitt.v → edge outline<span style="color:#f92672">(</span>sumapp.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - bound.v → bounding box<span style="color:#f92672">(</span>bound_box.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - boxcut.v → masked ROI<span style="color:#f92672">(</span>roi.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - boxcutF → cropped, zoomed ROI<span style="color:#f92672">(</span>rois.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - resize.v → resize to 28x28<span style="color:#f92672">(</span>roi_28.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - padding.v → padded and resized 28x28<span style="color:#f92672">(</span>roip_28.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - mirror.v → mirror about vertical axis<span style="color:#f92672">(</span>roipim_28.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - rotate.v → rotate 90° CCW<span style="color:#f92672">(</span>roipimr_28.png<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - mat2row.v → vectorized input<span style="color:#f92672">(</span>input_vector.txt<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>Step 3: Memory Loading</span></span><span style="display:flex;"><span> - memloader_from_inp_vec.py → image_memory.v</span></span><span style="display:flex;"><span> - wtbs_loader.py → W1_memory.v, W2_memory.v, W3_memory.v</span></span><span style="display:flex;"><span> - wtbs_loader.py → b1_memory.v, b2_memory.v, b3_memory.v</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>Step 4: Neural Network Inference<span style="color:#f92672">(</span>Verilog<span style="color:#f92672">)</span></span></span><span style="display:flex;"><span> - emnist_nn.v → Top module</span></span><span style="display:flex;"><span> - Instantiates relu.v, softmax.v</span></span><span style="display:flex;"><span> - Instantiates W1/W2/W3_memory.v and b1/b2/b3_memory.v</span></span><span style="display:flex;"><span> - Instantiates image_memory.v</span></span><span style="display:flex;"><span> - emnist_nn_tb.v → Testbench</span></span><span style="display:flex;"><span> - Loads memories</span></span><span style="display:flex;"><span> - Triggers inference</span></span><span style="display:flex;"><span> - Displays prediction</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>Step 5: Output</span></span><span style="display:flex;"><span> - Final predicted digit/character from Verilog simulation</span></span></code></pre></div><h4 id="image-reconstruction-trials"><strong>Image Reconstruction Trials</strong></h4><p>Image reconstruction works by taking random noise as the initial seed image and passing it through layers formed with trained parameters, iteratively minimizing the loss. This way, we gradually obtain the average image for each digit. Currently, I&rsquo;m working on refining the process in Python with MNIST data, which will eventually be translated into Verilog. The process is taking a significant amount of time per image (even in Python), so you can imagine the challenge in Verilog. I’m still testing the Verilog implementation and aiming to optimize it to achieve better speed performance compared to the Python version.</p><p>I&rsquo;m fully aware that generating images on edge devices—especially using parameters from a trained model (not even GANs)—doesn&rsquo;t quite align with the main objective of this project, mainly due to its limited real-world relevance. Still, I&rsquo;m pursuing it out of curiosity and for experimental purposes. The idea of creating an image using Verilog is highly conceptual, but it&rsquo;s a challenge I&rsquo;m enjoying exploring—just for the sake of it. :)</p><img title="" loading="lazy" decoding="async" class="img  " width="900" height="436" src="/images/projects/improve/never/imgen_hu6647524401982868010.webp" alt="image-recon" onerror="this.onerror='null';this.src='\/images\/projects\/improve\/never\/imgen_hu5513388853605226131.png'"/>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/pidc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/pidc/</guid><description>&lt;![CDATA[<h2 id="pidc---pid-controller-using-opampshttpsgithubcommummanajagadeeshpidc_ctrl"><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDC - PID Controller using OpAmps</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PIDC</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Implemented a PID controller using operational amplifiers to regulate system response and maintain desired performance. The design leverages analog circuitry to achieve precise control over error correction and stability.</td></tr><tr><td><strong>Start</strong></td><td>Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDC🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation , OpAmps</td></tr><tr><td><strong>Tools Used</strong></td><td>LtSpice</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><h4 id="pid-controller-theory-and-hardware-realization-using-op-amps"><strong>PID Controller: Theory and Hardware Realization Using Op-Amps</strong></h4><p>A<strong>PID (Proportional-Integral-Derivative) controller</strong> is a fundamental tool in control systems, widely used in industrial automation, robotics, temperature control, and motor speed regulation. It is designed to<strong>minimize error</strong> and<strong>improve stability</strong> by adjusting a system’s input based on the error between the desired setpoint and the actual output.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="pidc---pid-controller-using-opampshttpsgithubcommummanajagadeeshpidc_ctrl"><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDC - PID Controller using OpAmps</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PIDC</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Implemented a PID controller using operational amplifiers to regulate system response and maintain desired performance. The design leverages analog circuitry to achieve precise control over error correction and stability.</td></tr><tr><td><strong>Start</strong></td><td>Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PIDC_CTRL" target="_blank">PIDC🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Simulation , OpAmps</td></tr><tr><td><strong>Tools Used</strong></td><td>LtSpice</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><h4 id="pid-controller-theory-and-hardware-realization-using-op-amps"><strong>PID Controller: Theory and Hardware Realization Using Op-Amps</strong></h4><p>A<strong>PID (Proportional-Integral-Derivative) controller</strong> is a fundamental tool in control systems, widely used in industrial automation, robotics, temperature control, and motor speed regulation. It is designed to<strong>minimize error</strong> and<strong>improve stability</strong> by adjusting a system’s input based on the error between the desired setpoint and the actual output.</p><h4 id="why-introduce-the-pid-controller"><strong>Why Introduce the PID Controller?</strong></h4><p>Before jumping straight into PID, it&rsquo;s useful to start with simpler controllers and gradually add complexity. This helps in understanding<strong>why</strong> each term (P, I, D) is necessary and how they contribute to system performance.</p><ul><li><strong>Proportional (P) Control</strong> – Reacts to the current error but does not eliminate steady-state error.</li><li><strong>Integral (I) Control</strong> – Eliminates steady-state error by integrating past errors.</li><li><strong>Derivative (D) Control</strong> – Predicts future errors by considering the rate of change.</li></ul><p>This structured approach builds an<strong>intuitive understanding</strong> of why each term is needed before implementing them in hardware.</p><h4 id="mathematical-formulation-of-pid"><strong>Mathematical Formulation of PID</strong></h4><p>The<strong>PID control law</strong> in the time domain is:</p><p>$$
u(t) = K_p e(t) + K_i \int e(t) dt + K_d \frac{d e(t)}{dt}
$$</p><p>where:</p><ul><li>(e(t) = r(t) y(t)) (error between the desired setpoint (r(t)) and actual output (y(t))).</li><li>(K_p) is the<strong>proportional gain</strong> (how much we react to the present error).</li><li>(K_i) is the<strong>integral gain</strong> (how much we consider past errors).</li><li>(K_d) is the<strong>derivative gain</strong> (how much we predict future errors).</li></ul><p>In the<strong>Laplace domain</strong>, the PID transfer function is:</p><p>$$
U(s) = \left( K_p + \frac{K_i}{s} + K_d s \right) E(s)
$$</p><p>which represents the combined effect of<strong>P, I, and D</strong> on the system.</p><h4 id="hardware-realization-of-pid-using-op-amps"><strong>Hardware Realization of PID Using Op-Amps</strong></h4><p>Op-amps are ideal for<strong>analog PID implementation</strong> because they can easily perform<strong>amplification, integration, and differentiation</strong> using simple resistor-capacitor networks.</p><h6 id="proportional-p-controller-using-op-amps"><strong>Proportional (P) Controller Using Op-Amps</strong></h6><p>A proportional controller applies a gain (K_p) to the input error signal. This can be implemented using a<strong>non-inverting op-amp configuration</strong>:</p><p><strong>Circuit:</strong><br>
Use an<strong>op-amp in non-inverting mode</strong> with a feedback resistor (R_f) and input resistor (R_1).</p><p><strong>Gain Equation:</strong><br>
$$
K_p = 1 + \frac{R_f}{R_1}
$$</p><p><strong>Transfer Function:</strong><br>
$$
V_{out}(s) = K_p V_{in}(s)
$$</p><p><strong>Effect:</strong> Improves response speed but does not eliminate steady-state error.</p><h6 id="integral-i-controller-using-op-amps"><strong>Integral (I) Controller Using Op-Amps</strong></h6><p>The integral action sums past error signals over time, eliminating steady-state error. This is implemented using an<strong>op-amp integrator</strong>.</p><p><strong>Circuit:</strong></p><ul><li>Replace the feedback resistor with a<strong>capacitor (C)</strong>.</li><li>A resistor (R) is placed in the input path.</li></ul><p><strong>Transfer Function:</strong><br>
$$
V_{out}(s) = \frac{K_i}{s} V_{in}(s)
$$</p><p>where (K_i = \frac{1}{RC}).</p><p><strong>Effect:</strong> Eliminates steady-state error but may cause slow response or instability.</p><h6 id="derivative-d-controller-using-op-amps"><strong>Derivative (D) Controller Using Op-Amps</strong></h6><p>A differentiator predicts future errors by computing the rate of change of the input signal. This is implemented using an<strong>op-amp differentiator</strong>.</p><p><strong>Circuit:</strong><br>
Use a<strong>capacitor (C) at the input</strong> and a<strong>resistor (R) in the feedback loop</strong>.</p><p><strong>Transfer Function:</strong><br>
$$
V_{out}(s) = K_d s V_{in}(s)
$$</p><p>where (K_d = R C).</p><p><strong>Effect:</strong> Improves stability and damping but is sensitive to noise.</p><h4 id="from-p-to-pi-to-pid-full-implementation"><strong>From P to PI to PID: Full Implementation</strong></h4><h6 id="pi-controller-proportional--integral"><strong>PI Controller (Proportional + Integral)</strong></h6><p>To combine<strong>P and I</strong>, sum the outputs of the proportional and integral circuits. The transfer function becomes:</p><p>$$
U(s) = K_p E(s) + \frac{K_i}{s} E(s)
$$</p><p><strong>Implementation:</strong><br>
Use a<strong>summing amplifier</strong> to combine the outputs of the P and I circuits.</p><h6 id="pid-controller-proportional--integral--derivative"><strong>PID Controller (Proportional + Integral + Derivative)</strong></h6><p>The full<strong>PID transfer function</strong>:</p><p>$$
U(s) = \left( K_p + \frac{K_i}{s} + K_d s \right) E(s)
$$</p><p><strong>Hardware Implementation Steps:</strong></p><ol><li><strong>Sum the outputs</strong> of the P, I, and D circuits using an<strong>op-amp summing amplifier</strong>.</li><li><strong>Adjust gains</strong> (K_p, K_i, K_d) by selecting appropriate resistor and capacitor values.</li><li><strong>Fine-tune</strong> the component values based on system response.</li></ol><h4 id="summary-of-pid-hardware-implementation"><strong>Summary of PID Hardware Implementation</strong></h4><table><thead><tr><th>Controller</th><th>Circuit Type</th><th>Transfer Function</th><th>Key Components</th></tr></thead><tbody><tr><td><strong>P</strong></td><td>Non-inverting amplifier</td><td>(K_p)</td><td>(R_f, R_1)</td></tr><tr><td><strong>I</strong></td><td>Integrator</td><td>(\frac{K_i}{s})</td><td>(R, C)</td></tr><tr><td><strong>D</strong></td><td>Differentiator</td><td>(K_d s)</td><td>(R, C)</td></tr><tr><td><strong>PI</strong></td><td>Summing amplifier of P and I</td><td>(K_p + \frac{K_i}{s})</td><td>Combination of P and I circuits</td></tr><tr><td><strong>PID</strong></td><td>Summing amplifier of P, I, and D</td><td>(K_p + \frac{K_i}{s} + K_d s)</td><td>Combination of P, I, and D circuits</td></tr></tbody></table><h4 id="conclusion-and-next-steps"><strong>Conclusion and Next Steps</strong></h4><p><strong>Why use Op-Amps?</strong></p><ul><li>Fast response time.</li><li>Continuous-time operation.</li><li>Lower power consumption compared to digital implementations.</li></ul><p><strong>Practical Considerations:</strong></p><ul><li>Noise filtering is required for the derivative term (D).</li><li>Proper tuning of (K_p, K_i, K_d) is needed for optimal performance.</li></ul><hr><h3 id="pi-controller-with-square-wave-input">PI Controller with Square Wave Input</h3><h4 id="circuit-diagram">Circuit Diagram</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="518" src="/images/projects/pidc/PIDC_sq_hu8258312176216106087.webp" alt="Circuit Diagram" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/PIDC_sq_hu9638792435271427506.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="setpoint">Setpoint</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="213" src="/images/projects/pidc/sq_setpoint_hu10104047699335501269.webp" alt="Setpoint" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_setpoint_hu7413604800821180335.png'"/><h4 id="output-at-differential-amplifier">Output at Differential Amplifier</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="215" src="/images/projects/pidc/sq_diff_out_hu13366964869359382432.webp" alt="Output at Diff Amp" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_diff_out_hu18019832119747124436.png'"/><h4 id="after-integral">After Integral</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="216" src="/images/projects/pidc/sq_int_hu12355741093204094324.webp" alt="After Integral" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_int_hu14279697933822695612.png'"/><h4 id="final-output">Final Output</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="217" src="/images/projects/pidc/sq_final_hu8113955749164433724.webp" alt="Final Output" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/sq_final_hu15706104938570525425.png'"/><hr><h3 id="pid-controller-transient-analysis">PID Controller Transient Analysis</h3><h4 id="circuit">Circuit</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="497" src="/images/projects/pidc/pidc_full_hu6796135543531041001.webp" alt="Circuit" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/pidc_full_hu3410455324003975788.png'"/><h4 id="response">Response</h4><img title="" loading="lazy" decoding="async" class="img  " width="900" height="216" src="/images/projects/pidc/pidc_tran_hu9152998390288215918.webp" alt="Response" onerror="this.onerror='null';this.src='\/images\/projects\/pidc\/pidc_tran_hu4851804044525527490.png'"/>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/prosarm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/prosarm/</guid><description>&lt;![CDATA[<h2 id="pr057h371c4rmhttpsgithubcommummanajagadeeshpr057h371c4rm"><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PR057H371C4RM</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A simple prosthetic arm that utilizes servo motors to create tension in strings, replicating the function of human tendons to achieve realistic finger motion.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(2018), Implementation(Nov 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Mechanical Design, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Fusion 360, Tinkercad, Wokwi, VS Code, OpenCV, MediaPipe, Python, C++</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Mechanical model complete with updated tolerances.<br> - Finger tracking using MediaPipe is fully functional.<br> - Servo control code is operational.</td></tr><tr><td><strong>Next Steps</strong></td><td>- Analyze weight distribution.<br> - Reevaluate strength and agility for optimization.<br> - 3D print and assemble the prosthetic arm.<br> - Deploy the system on hardware.</td></tr></tbody></table><hr><h4 id="overview"><strong>Overview</strong></h4><p>PR057H371C4RM is a<strong>biomechanical prosthetic arm</strong> designed to replicate the<strong>natural movement and structure of a human hand</strong> as closely as possible. The project focuses on affordability, accessibility, and precision in design, making it a viable option for those who need a functional mechanical replacement for a lost limb.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="pr057h371c4rmhttpsgithubcommummanajagadeeshpr057h371c4rm"><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>PR057H371C4RM</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>A simple prosthetic arm that utilizes servo motors to create tension in strings, replicating the function of human tendons to achieve realistic finger motion.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(2018), Implementation(Nov 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/PR057H371C4RM" target="_blank">PR057H371C4RM🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Mechanical Design, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Fusion 360, Tinkercad, Wokwi, VS Code, OpenCV, MediaPipe, Python, C++</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Mechanical model complete with updated tolerances.<br> - Finger tracking using MediaPipe is fully functional.<br> - Servo control code is operational.</td></tr><tr><td><strong>Next Steps</strong></td><td>- Analyze weight distribution.<br> - Reevaluate strength and agility for optimization.<br> - 3D print and assemble the prosthetic arm.<br> - Deploy the system on hardware.</td></tr></tbody></table><hr><h4 id="overview"><strong>Overview</strong></h4><p>PR057H371C4RM is a<strong>biomechanical prosthetic arm</strong> designed to replicate the<strong>natural movement and structure of a human hand</strong> as closely as possible. The project focuses on affordability, accessibility, and precision in design, making it a viable option for those who need a functional mechanical replacement for a lost limb.</p><p>Each<strong>finger</strong> has been modeled with accurate anatomical proportions to mimic human biomechanics. The design incorporates<strong>tendons (strings), ligaments (rubber cords), and joints (pivot points)</strong> to replicate<strong>natural flexion and extension</strong>. The<strong>rubber cord system</strong> ensures the fingers return to their original position after movement, while<strong>servo motors control flexion</strong>, allowing for precise and lifelike motion.</p><p>This project has been my<strong>dream</strong>, inspired by my passion for<strong>animatronics and robotics</strong>. I discovered<em>Will Cogley&rsquo;s</em> work on YouTube, which motivated me to learn<strong>Fusion 360</strong> to model the entire hand from scratch. Due to budget constraints, I have not yet been able to fully 3D print and assemble the final prototype, but the design and simulation have been extensively tested.</p><hr><h4 id="project-inspiration--resources"><strong>Project Inspiration &amp; Resources</strong></h4><ul><li><strong>3D Printing Service:</strong><a href="https://robu.in/product/3d-printing-service/" target="_blank">Robu</a></li><li><strong>CAD Files:</strong><ul><li><a href="https://grabcad.com/library/sg90-micro-servo-9g-tower-pro-1" target="_blank">SG90 Micro Servo</a></li><li><a href="https://grabcad.com/library/arduino-uno-r3-1" target="_blank">Arduino UNO R3</a></li></ul></li><li><strong>Project Inspiration:</strong><a href="https://www.youtube.com/@WillCogley" target="_blank">Will Cogley</a></li><li><strong>Bulk Export Add-ons:</strong><a href="https://github.com/Mummanajagadeesh/Project-Archiver" target="_blank">Project-Archiver</a></li></ul><hr><h4 id="demo-videos"><strong>Demo Videos</strong></h4><h5 id="latest-prototype"><strong>Latest Prototype</strong></h5><table><thead><tr><th>Motion Study</th><th>Assembly</th></tr></thead><tbody><tr><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/mATUY7Tn4Is" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/IqjxZRdiDbM" frameborder="0" allowfullscreen=/></div></div></td></tr></tbody></table><h5 id="here-are-few-clicks">Here are few clicks</h5><p><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/F-view_hu1401584373448396367.webp" alt="Front View" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/F-view_hu10069619060956966000.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><br><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/full-arm-f_hu8238285960909339441.webp" alt="Full Arm" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/full-arm-f_hu7135783822006069172.png'"/><br><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/full-workspace-all_hu4533822951062469976.webp" alt="Full Workspace" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/full-workspace-all_hu12110544136101094587.png'"/></p><p><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/full-palm_hu15218569622499882049.webp" alt="Full Palm" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/full-palm_hu7486672459591283229.png'"/><img title="" loading="lazy" decoding="async" class="img img-75 " width="1920" height="1080" src="/images/projects/prosarm/finger_hu13804336961041066729.webp" alt="Finger" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/finger_hu4554102789042903001.png'"/></p><hr><h4 id="hand-anatomy--biomechanics-in-the-design"><strong>Hand Anatomy &amp; Biomechanics in the Design</strong></h4><p>The prosthetic hand is designed to closely resemble the<strong>biological structure of a human hand</strong>, including key anatomical components:</p><ol><li><p><strong>Phalanges (Finger Bones)</strong> – Each finger consists of<strong>three segments</strong>:</p><ul><li><strong>Distal Phalanx</strong> (tip of the finger)</li><li><strong>Middle Phalanx</strong></li><li><strong>Proximal Phalanx</strong> (connects to the palm)<br>
The<strong>thumb</strong> has only two phalanges (proximal and distal).</li></ul></li><li><p><strong>Metacarpals (Palm Bones)</strong> – The palm structure is designed to support all fingers and provide stability.</p></li><li><p><strong>Tendons (Strings/Twine)</strong> – Artificial tendons<strong>run through the palm and wrist</strong>, connecting to servo motors in the arm.</p></li><li><p><strong>Ligaments (Rubber Cords)</strong> – The rubber cords<strong>act like ligaments</strong>, maintaining the natural tension of the fingers.</p></li></ol><h5 id="finger-structure--naming-convention"><strong>Finger Structure &amp; Naming Convention</strong></h5><p>Each finger is labeled as follows:</p><p><strong>IX</strong> – Index<br><strong>MX</strong> – Middle<br><strong>RX</strong> – Ring<br><strong>PX</strong> – Pinky<br><strong>TX</strong> – Thumb</p><h6 id="segment-breakdown"><strong>Segment Breakdown</strong></h6><p>Each finger consists of multiple segments:</p><ul><li><strong>IX (Index)</strong> → I1 (Distal), I2 (Middle), I3 (Proximal)</li><li><strong>MX (Middle)</strong> → M1 (Distal), M2 (Middle), M3 (Proximal)</li><li><strong>RX (Ring)</strong> → R1 (Distal), R2 (Middle), R3 (Proximal)</li><li><strong>PX (Pinky)</strong> → P1 (Distal), P2 (Middle), P3 (Proximal)</li><li><strong>TX (Thumb)</strong> → T1 (Distal), T2 (Proximal)</li></ul><p><strong>Segment Definitions:</strong></p><ul><li><strong>Distal (1):</strong> Fingertip section</li><li><strong>Middle (2):</strong> Intermediate joint section</li><li><strong>Proximal (3):</strong> Base section connecting to the palm (except for the thumb, which has only two segments)</li></ul><hr><h4 id="finger-mechanism"><strong>Finger Mechanism</strong></h4><p>Each<strong>finger</strong> consists of<strong>three segments</strong> connected by pivot points, allowing for<strong>natural bending and extension</strong>.</p><ul><li><p><strong>Rubber Cord System:</strong></p><ul><li>A<strong>rubber cord runs twice through each finger</strong>, starting from the<strong>bottom</strong>, looping through the<strong>tip (making a U-turn)</strong>, and returning to the<strong>bottom</strong> again.</li><li>Both ends of the cord are<strong>secured at the back of the palm</strong>, ensuring controlled movement and restoring fingers to a neutral position.</li></ul></li><li><p><strong>String Control System:</strong></p><ul><li>A<strong>string runs through each finger</strong>, with a<strong>knot at the fingertip</strong> to create movement when pulled.</li><li>The<strong>strings pass through the palm, wrist, and arm</strong>, connecting to<strong>servo motors</strong> for actuation.</li></ul></li></ul><h5 id="how-it-works"><strong>How It Works</strong></h5><ol><li><strong>At rest</strong>, the rubber cords keep the fingers straight, aligning all segments.</li><li><strong>When a servo pulls a string</strong>, the corresponding finger bends.</li><li><strong>Once tension is released</strong>, the rubber cord returns the finger to its original position.</li><li><strong>Fingers can only move forward and back, preventing unnatural backward bending.</strong></li></ol><hr><h4 id="thumb-mechanism"><strong>Thumb Mechanism</strong></h4><p>The<strong>thumb</strong> requires two independent servos for realistic movement:</p><ol><li><strong>Palm Servo</strong> – Moves the thumb<strong>up and down</strong> (abduction/adduction).</li><li><strong>Arm Servo</strong> – Controls the<strong>folding motion</strong> (flexion/extension).</li></ol><p>This dual-motor setup allows the thumb to<strong>grip objects naturally</strong> when combined with finger movement.</p><hr><h4 id="palm--string-routing"><strong>Palm &amp; String Routing</strong></h4><ul><li><strong>Holes in the palm</strong> allow rubber cords to be secured at the back, where the fingers intersect.</li><li><strong>Channels through the palm</strong> guide the control strings from the fingertips through the wrist to the servos in the arm.</li></ul><hr><h4 id="servo-control--electronics"><strong>Servo Control &amp; Electronics</strong></h4><p>The system is powered by<strong>six SG90 servo motors</strong> controlled using an<strong>Arduino or similar microcontroller</strong>. The design allows for expansion with<strong>sensor-based or AI-driven control</strong>.</p><h5 id="simulation-links"><strong>Simulation Links</strong></h5><ul><li><p><strong>Tinkercad Circuit Simulation:</strong><a href="https://www.tinkercad.com/things/4HJGXiv97LI-servo-flex-mimic-hand" target="_blank">View Here</a></p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="560" src="/images/projects/prosarm/tinkercad_hu7485008671565594993.webp" alt="Tinkercad Model" onerror="this.onerror='null';this.src='\/images\/projects\/prosarm\/tinkercad_hu987314142999971428.png'"/></li><li><p><strong>Wokwi Simulation:</strong><a href="https://wokwi.com/projects/400010151130264577" target="_blank">View Here</a></p></li></ul><hr><h4 id="future-work--goals"><strong>Future Work &amp; Goals</strong></h4><p>✅<strong>Improve Mechanical &amp; Electronic Design</strong> (70% Complete)<br>
✅<strong>Prototype &amp; Testing Phases</strong> (20% Complete)<br>
🔲<strong>Enhance User Control via Muscle Signals (BCI) or Computer Vision (MediaPipe for Hand Tracking)</strong></p><h5 id="next-steps"><strong>Next Steps</strong></h5><ul><li><strong>Brain-Computer Interface (BCI):</strong> Connect the prosthetic arm to human muscles using electromyography (EMG) sensors.</li><li><strong>Computer Vision Integration:</strong> Use<strong>MediaPipe hand tracking</strong> to detect hand gestures and translate them into servo motor commands.</li><li><strong>Further Refinements in Mechanical Design &amp; 3D Printing.</strong></li></ul><p>This project is constantly evolving, and I welcome feedback, collaboration, and new ideas! 🚀</p><hr>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/protocols/i2c_code/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/protocols/i2c_code/</guid><description>&lt;![CDATA[<h4 id="master">MASTER</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Main module declaration</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">module</span> i2c_master(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> clk,<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rst,<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr,<span style="color:#75715e">// 7-bit I2C slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in,<span style="color:#75715e">// Data to send to slave in write mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> enable,<span style="color:#75715e">// Start signal for I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rw,<span style="color:#75715e">// Read/Write control (0 for write, 1 for read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out,<span style="color:#75715e">// Data received from slave in read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> ready,<span style="color:#75715e">// Indicates when the master is ready for a new transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> i2c_sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_scl<span style="color:#75715e">// I2C clock line (SCL) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Define states for I2C master FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> IDLE<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> START<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> ADDRESS<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> WRITE_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> WRITE_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_ACK2<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> STOP<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> DIVIDE_BY<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;<span style="color:#75715e">// Clock divider to generate I2C clock from system clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state;<span style="color:#75715e">// Current state of the FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] saved_addr;<span style="color:#75715e">// Stores the 7-bit address and RW bit for the current transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] saved_data;<span style="color:#75715e">// Data to be sent in write transactions</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter;<span style="color:#75715e">// Bit counter for data/address transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter2<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Divider counter for generating i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> write_enable;<span style="color:#75715e">// Controls whether the master drives SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_out;<span style="color:#75715e">// Data to output on SDA line when write_enable is 1</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> i2c_scl_enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Controls the state of the i2c_scl line (enabled or high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> i2c_clk<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Internal I2C clock signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Ready signal is high when the master is idle and not in reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> ready<span style="color:#f92672">=</span> ((rst<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (state<span style="color:#f92672">==</span> IDLE))<span style="color:#f92672">?</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// I2C SCL signal: High when i2c_scl_enable is low; otherwise, driven by i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> i2c_scl<span style="color:#f92672">=</span> (i2c_scl_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">?</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> i2c_clk;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// SDA line is driven by sda_out when write_enable is high; otherwise, it's in high-impedance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> i2c_sda<span style="color:#f92672">=</span> (write_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">?</span> sda_out<span style="color:#f92672">:</span> 'bz;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// I2C clock divider: Divides system clock to generate i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter2<span style="color:#f92672">==</span> (DIVIDE_BY<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_clk<span style="color:#f92672">&lt;=</span><span style="color:#f92672">~</span>i2c_clk;<span style="color:#75715e">// Toggle i2c_clk when half period is reached</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter2<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Reset the divider counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter2<span style="color:#f92672">&lt;=</span> counter2<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Increment the divider counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Enable/disable I2C clock based on current state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Disable SCL on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((state<span style="color:#f92672">==</span> IDLE)<span style="color:#f92672">||</span> (state<span style="color:#f92672">==</span> START)<span style="color:#f92672">||</span> (state<span style="color:#f92672">==</span> STOP))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// SCL is disabled in IDLE, START, and STOP states</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SCL in other states</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// State machine for controlling the I2C master operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Reset state to IDLE on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span> (state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> IDLE:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (enable)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> START;<span style="color:#75715e">// Start I2C transaction when enable is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> saved_addr<span style="color:#f92672">&lt;=</span> {addr, rw};<span style="color:#75715e">// Save the 7-bit address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> saved_data<span style="color:#f92672">&lt;=</span> data_in;<span style="color:#75715e">// Save the data to be sent (in write mode)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> START:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Initialize bit counter to 7 for 8-bit transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> state<span style="color:#f92672">&lt;=</span> ADDRESS;<span style="color:#75715e">// Move to ADDRESS state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> ADDRESS:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ACK;<span style="color:#75715e">// Move to ACK check after sending address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Transmit address bits, count down</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (i2c_sda<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span><span style="color:#75715e">// ACK received (SDA pulled low by slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Reset bit counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span> (saved_addr[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>) state<span style="color:#f92672">&lt;=</span> WRITE_DATA;<span style="color:#75715e">// If RW=0, go to write mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> state<span style="color:#f92672">&lt;=</span> READ_DATA;<span style="color:#75715e">// If RW=1, go to read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// NACK received, move to STOP state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ACK2;<span style="color:#75715e">// Move to second ACK check after data transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Transmit data bits, count down</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((i2c_sda<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)) state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Return to IDLE on ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// If NACK received or enable low, go to STOP</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> data_out[counter]<span style="color:#f92672">&lt;=</span> i2c_sda;<span style="color:#75715e">// Capture data bit from SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>) state<span style="color:#f92672">&lt;=</span> WRITE_ACK;<span style="color:#75715e">// After last bit, go to WRITE_ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down for each bit received</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// Go to STOP after sending ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> STOP:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Go back to IDLE after STOP condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// SDA output logic based on the current state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Drive SDA high on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span> (state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> START:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for start condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Pull SDA low for start condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> ADDRESS:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> saved_addr[counter];<span style="color:#75715e">// Send each bit of the address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA to allow slave to drive ACK/NACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for data transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span> saved_data[counter];<span style="color:#75715e">// Output each bit of data to SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for ACK transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Send ACK by pulling SDA low</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA to read data from slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> STOP:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for stop condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Release SDA to indicate stop</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation---">Explanation &ndash;></h5><h5 id="slave">SLAVE</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">module</span> i2c_slave(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr_in,<span style="color:#75715e">// Slave address to respond to (dynamic address input)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> scl<span style="color:#75715e">// I2C clock line (SCL)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Define states for the I2C slave FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> READ_ADDR<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// State for reading the address from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> SEND_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// State for sending ACK after receiving a matching address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> READ_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>;<span style="color:#75715e">// State for reading data from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> WRITE_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>;<span style="color:#75715e">// State for sending data to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> SEND_ACK2<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;<span style="color:#75715e">// State for sending ACK after receiving data from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr;<span style="color:#75715e">// Register to store the address received from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter;<span style="color:#75715e">// Bit counter for data/address transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Current state of the FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Register to store data received from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b11001100</span>;<span style="color:#75715e">// Data to be sent to the master in read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_out<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Data to drive onto SDA when write_enable is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_in<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Register to capture SDA input data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> start<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Flag to indicate the start condition (SDA goes low while SCL is high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> write_enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Controls whether the slave drives the SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Tri-state SDA line: driven by sda_out when write_enable is high, otherwise high-impedance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> sda<span style="color:#f92672">=</span> (write_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">?</span> sda_out<span style="color:#f92672">:</span> 'bz;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Detect start condition on SDA falling edge when SCL is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> sda)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((start<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (scl<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> start<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Set start flag</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Initialize counter to read 8 bits (address or data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Detect stop condition on SDA rising edge when SCL is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> sda)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((start<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">&amp;&amp;</span> (scl<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Go to READ_ADDR state to read the address from master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> start<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Clear start flag</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// State machine for I2C slave behavior, triggered on rising edge of SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> scl)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (start<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span><span style="color:#75715e">// Only proceed if start condition was detected</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">case</span>(state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ADDR:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> addr[counter]<span style="color:#f92672">&lt;=</span> sda;<span style="color:#75715e">// Capture address bit from SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> SEND_ACK;<span style="color:#75715e">// Move to SEND_ACK after receiving full address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down to receive 8 bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Check if received address matches slave address (addr_in)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(addr[<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> addr_in)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Reset bit counter for next data frame</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// Determine next state based on R/W bit (addr[0])</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(addr[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_DATA;<span style="color:#75715e">// If R/W=0, master wants to write, go to READ_DATA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> WRITE_DATA;<span style="color:#75715e">// If R/W=1, master wants to read, go to WRITE_DATA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Address mismatch, go back to READ_ADDR</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> data_in[counter]<span style="color:#f92672">&lt;=</span> sda;<span style="color:#75715e">// Capture data bit from SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> SEND_ACK2;<span style="color:#75715e">// Move to SEND_ACK2 after receiving full byte</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down to receive 8 bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Go back to READ_ADDR to listen for next address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Transmit data_out to master one bit at a time</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// After last bit, go back to READ_ADDR</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down for each bit sent</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Control SDA output behavior on falling edge of SCL, depending on the state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> scl)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span>(state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ADDR:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA while reading address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> (addr[<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> addr_in)<span style="color:#f92672">?</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Send ACK (low) if address matches, else NACK (high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive ACK/NACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA while reading data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> data_out[counter];<span style="color:#75715e">// Send each bit of data_out on SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Send ACK (low) after receiving data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation">Explanation</h5>]]></description><content:encoded>&lt;![CDATA[<h4 id="master">MASTER</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Main module declaration</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">module</span> i2c_master(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> clk,<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rst,<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr,<span style="color:#75715e">// 7-bit I2C slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in,<span style="color:#75715e">// Data to send to slave in write mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> enable,<span style="color:#75715e">// Start signal for I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rw,<span style="color:#75715e">// Read/Write control (0 for write, 1 for read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out,<span style="color:#75715e">// Data received from slave in read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> ready,<span style="color:#75715e">// Indicates when the master is ready for a new transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> i2c_sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_scl<span style="color:#75715e">// I2C clock line (SCL) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Define states for I2C master FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> IDLE<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> START<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> ADDRESS<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> WRITE_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> WRITE_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> READ_ACK2<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> STOP<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">localparam</span> DIVIDE_BY<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;<span style="color:#75715e">// Clock divider to generate I2C clock from system clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state;<span style="color:#75715e">// Current state of the FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] saved_addr;<span style="color:#75715e">// Stores the 7-bit address and RW bit for the current transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] saved_data;<span style="color:#75715e">// Data to be sent in write transactions</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter;<span style="color:#75715e">// Bit counter for data/address transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter2<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Divider counter for generating i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> write_enable;<span style="color:#75715e">// Controls whether the master drives SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_out;<span style="color:#75715e">// Data to output on SDA line when write_enable is 1</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> i2c_scl_enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Controls the state of the i2c_scl line (enabled or high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> i2c_clk<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Internal I2C clock signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Ready signal is high when the master is idle and not in reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> ready<span style="color:#f92672">=</span> ((rst<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (state<span style="color:#f92672">==</span> IDLE))<span style="color:#f92672">?</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// I2C SCL signal: High when i2c_scl_enable is low; otherwise, driven by i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> i2c_scl<span style="color:#f92672">=</span> (i2c_scl_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">?</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> i2c_clk;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// SDA line is driven by sda_out when write_enable is high; otherwise, it's in high-impedance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> i2c_sda<span style="color:#f92672">=</span> (write_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">?</span> sda_out<span style="color:#f92672">:</span> 'bz;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// I2C clock divider: Divides system clock to generate i2c_clk</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter2<span style="color:#f92672">==</span> (DIVIDE_BY<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_clk<span style="color:#f92672">&lt;=</span><span style="color:#f92672">~</span>i2c_clk;<span style="color:#75715e">// Toggle i2c_clk when half period is reached</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter2<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Reset the divider counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter2<span style="color:#f92672">&lt;=</span> counter2<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Increment the divider counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Enable/disable I2C clock based on current state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Disable SCL on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((state<span style="color:#f92672">==</span> IDLE)<span style="color:#f92672">||</span> (state<span style="color:#f92672">==</span> START)<span style="color:#f92672">||</span> (state<span style="color:#f92672">==</span> STOP))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// SCL is disabled in IDLE, START, and STOP states</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> i2c_scl_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SCL in other states</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// State machine for controlling the I2C master operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Reset state to IDLE on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span> (state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> IDLE:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (enable)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> START;<span style="color:#75715e">// Start I2C transaction when enable is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> saved_addr<span style="color:#f92672">&lt;=</span> {addr, rw};<span style="color:#75715e">// Save the 7-bit address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> saved_data<span style="color:#f92672">&lt;=</span> data_in;<span style="color:#75715e">// Save the data to be sent (in write mode)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> START:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Initialize bit counter to 7 for 8-bit transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> state<span style="color:#f92672">&lt;=</span> ADDRESS;<span style="color:#75715e">// Move to ADDRESS state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> ADDRESS:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ACK;<span style="color:#75715e">// Move to ACK check after sending address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Transmit address bits, count down</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (i2c_sda<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span><span style="color:#75715e">// ACK received (SDA pulled low by slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Reset bit counter</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span> (saved_addr[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>) state<span style="color:#f92672">&lt;=</span> WRITE_DATA;<span style="color:#75715e">// If RW=0, go to write mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> state<span style="color:#f92672">&lt;=</span> READ_DATA;<span style="color:#75715e">// If RW=1, go to read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// NACK received, move to STOP state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ACK2;<span style="color:#75715e">// Move to second ACK check after data transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Transmit data bits, count down</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((i2c_sda<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)) state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Return to IDLE on ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// If NACK received or enable low, go to STOP</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> data_out[counter]<span style="color:#f92672">&lt;=</span> i2c_sda;<span style="color:#75715e">// Capture data bit from SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span> (counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>) state<span style="color:#f92672">&lt;=</span> WRITE_ACK;<span style="color:#75715e">// After last bit, go to WRITE_ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">else</span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down for each bit received</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> STOP;<span style="color:#75715e">// Go to STOP after sending ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> STOP:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> IDLE;<span style="color:#75715e">// Go back to IDLE after STOP condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// SDA output logic based on the current state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> i2c_clk<span style="color:#66d9ef">or</span><span style="color:#66d9ef">posedge</span> rst)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (rst<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Drive SDA high on reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span> (state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> START:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for start condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Pull SDA low for start condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> ADDRESS:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> saved_addr[counter];<span style="color:#75715e">// Send each bit of the address and RW bit</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA to allow slave to drive ACK/NACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for data transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span> saved_data[counter];<span style="color:#75715e">// Output each bit of data to SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for ACK transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Send ACK by pulling SDA low</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA to read data from slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> STOP:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA for stop condition</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Release SDA to indicate stop</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation---">Explanation &ndash;></h5><h5 id="slave">SLAVE</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">module</span> i2c_slave(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr_in,<span style="color:#75715e">// Slave address to respond to (dynamic address input)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span> scl<span style="color:#75715e">// I2C clock line (SCL)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Define states for the I2C slave FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> READ_ADDR<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// State for reading the address from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> SEND_ACK<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// State for sending ACK after receiving a matching address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> READ_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>;<span style="color:#75715e">// State for reading data from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> WRITE_DATA<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>;<span style="color:#75715e">// State for sending data to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">localparam</span> SEND_ACK2<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>;<span style="color:#75715e">// State for sending ACK after receiving data from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr;<span style="color:#75715e">// Register to store the address received from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] counter;<span style="color:#75715e">// Bit counter for data/address transmission</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Current state of the FSM</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Register to store data received from the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b11001100</span>;<span style="color:#75715e">// Data to be sent to the master in read mode</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_out<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Data to drive onto SDA when write_enable is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> sda_in<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Register to capture SDA input data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> start<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Flag to indicate the start condition (SDA goes low while SCL is high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> write_enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Controls whether the slave drives the SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Tri-state SDA line: driven by sda_out when write_enable is high, otherwise high-impedance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> sda<span style="color:#f92672">=</span> (write_enable<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">?</span> sda_out<span style="color:#f92672">:</span> 'bz;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Detect start condition on SDA falling edge when SCL is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> sda)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((start<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">&amp;&amp;</span> (scl<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> start<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Set start flag</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Initialize counter to read 8 bits (address or data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Detect stop condition on SDA rising edge when SCL is high</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> sda)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> ((start<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">&amp;&amp;</span> (scl<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>))<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Go to READ_ADDR state to read the address from master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> start<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Clear start flag</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// State machine for I2C slave behavior, triggered on rising edge of SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> scl)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (start<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)<span style="color:#66d9ef">begin</span><span style="color:#75715e">// Only proceed if start condition was detected</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">case</span>(state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ADDR:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> addr[counter]<span style="color:#f92672">&lt;=</span> sda;<span style="color:#75715e">// Capture address bit from SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> SEND_ACK;<span style="color:#75715e">// Move to SEND_ACK after receiving full address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down to receive 8 bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Check if received address matches slave address (addr_in)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(addr[<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> addr_in)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">7</span>;<span style="color:#75715e">// Reset bit counter for next data frame</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// Determine next state based on R/W bit (addr[0])</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(addr[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_DATA;<span style="color:#75715e">// If R/W=0, master wants to write, go to READ_DATA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> WRITE_DATA;<span style="color:#75715e">// If R/W=1, master wants to read, go to WRITE_DATA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Address mismatch, go back to READ_ADDR</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> data_in[counter]<span style="color:#f92672">&lt;=</span> sda;<span style="color:#75715e">// Capture data bit from SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> SEND_ACK2;<span style="color:#75715e">// Move to SEND_ACK2 after receiving full byte</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down to receive 8 bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// Go back to READ_ADDR to listen for next address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Transmit data_out to master one bit at a time</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">if</span>(counter<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> state<span style="color:#f92672">&lt;=</span> READ_ADDR;<span style="color:#75715e">// After last bit, go back to READ_ADDR</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span><span style="color:#66d9ef">else</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> counter<span style="color:#f92672">&lt;=</span> counter<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Count down for each bit sent</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Control SDA output behavior on falling edge of SCL, depending on the state</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">negedge</span> scl)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">case</span>(state)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_ADDR:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA while reading address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> (addr[<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> addr_in)<span style="color:#f92672">?</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Send ACK (low) if address matches, else NACK (high)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive ACK/NACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> READ_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Release SDA while reading data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> WRITE_DATA:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span> data_out[counter];<span style="color:#75715e">// Send each bit of data_out on SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> SEND_ACK2:<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> sda_out<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Send ACK (low) after receiving data</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> write_enable<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Enable SDA to drive ACK</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endcase</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation">Explanation</h5>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/protocols/i2cv/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/protocols/i2cv/</guid><description>&lt;![CDATA[<h2 id="i2c-protocol-verilog-implementation-using-fsmhttpsgithubcommummanajagadeeshi2c-protocol-verilog"><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2C Protocol Verilog Implementation using FSM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>I2C Protocol</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of I2C Protocol using Finite State Machine (FSM) design</td></tr><tr><td><strong>Start</strong></td><td>06 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2CV🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Protocols, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project implements the I2C protocol in Verilog with various versions and configurations. Below is a summary of each version:</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="i2c-protocol-verilog-implementation-using-fsmhttpsgithubcommummanajagadeeshi2c-protocol-verilog"><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2C Protocol Verilog Implementation using FSM</a></h2><table><thead><tr><th><strong>Name</strong></th><th>I2C Protocol</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of I2C Protocol using Finite State Machine (FSM) design</td></tr><tr><td><strong>Start</strong></td><td>06 Nov 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">I2CV🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Protocols, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><p>This project implements the I2C protocol in Verilog with various versions and configurations. Below is a summary of each version:</p><h4 id="v102---simple-master-slave-no-clock-stretching">v1.0.2 - Simple Master-Slave (No Clock Stretching)</h4><ul><li><strong>Description</strong>: This version implements a simple I2C protocol with one master and one slave device. It does not support clock stretching.</li><li><strong>Features</strong>:<ul><li>Basic I2C communication between a single master and slave.</li><li>No handling of clock stretching; both master and slave devices operate with the same clock frequency.</li><li>NACK will be raised indicating that the given address for slave is wrong.</li></ul></li></ul><h4 id="v203---clock-stretching-with-fixed-master-delay">v2.0.3 - Clock Stretching with Fixed Master Delay</h4><ul><li><strong>Description</strong>: This version adds support for clock stretching. The master introduces a fixed delay after sending each data frame, and the SCL line will be held low (clock stretching) while waiting for the slave.</li><li><strong>Features</strong>:<ul><li>Clock stretching is supported for managing communication timing.</li><li>The master introduces a fixed delay to simulate real-world clock stretching scenarios.</li></ul></li></ul><h4 id="v204---clock-stretching-with-configurable-master-delay">v2.0.4 - Clock Stretching with Configurable Master Delay</h4><ul><li><strong>Description</strong>: This version builds on v2.0.3 by adding a configurable delay from the testbench. The delay allows adjusting the time period that the SCL line waits, providing greater flexibility.</li><li><strong>Features</strong>:<ul><li>Configurable master delay, adjustable from the testbench.</li><li>SCL waiting period comparison between the master and slave devices.</li><li>Enhanced clock stretching handling with configurable delays.</li></ul></li></ul><h4 id="v301---multi-slave-single-master-configuration">v3.0.1 - Multi-Slave Single Master Configuration</h4><ul><li><strong>Description</strong>: This version introduces a configuration with a single master and multiple slave devices. The master can communicate with any of the slaves, supporting multi-slave communication.</li><li><strong>Features</strong>:<ul><li>One master can communicate with multiple slaves.</li><li>The master can address and select any slave for communication.</li><li>Basic multi-slave handling without clock stretching.</li></ul></li></ul><h4 id="v311---multi-slave-multi-master-configuration">v3.1.1 - Multi-Slave Multi-Master Configuration</h4><ul><li><strong>Description</strong>: The latest version supports a multi-master, multi-slave configuration, where both the master and slaves can initiate communication. It adds complexity to handle multiple devices that can take control of the bus.</li><li><strong>Features</strong>:<ul><li>Multiple masters can communicate with multiple slaves.</li><li>Advanced bus arbitration is implemented to handle multiple masters trying to access the bus at the same time.</li><li>Suitable for complex systems requiring both multiple masters and multiple slaves.</li></ul></li></ul><p>I2C combines the strengths of both UART and
SPI. It operates using just two wires, like asynchronous serial, yet
supports communication with up to 1,008 peripheral devices. Unlike SPI,
I2C accommodates multi-controller systems, allowing more than one
controller to communicate with all peripheral devices on the bus
(although the controllers must take turns using the bus lines).</p><p>I2C data rates fall between those of asynchronous serial and SPI, with
most devices communicating at 100 kHz or 400 kHz. While there is some
overhead&mdash;requiring one additional acknowledgment (ACK/NACK) bit for
every 8 bits of data transmitted&mdash;I2C remains efficient. Although
implementing I2C requires more complex hardware than SPI, it is still
simpler than asynchronous serial and can be easily realized in software.</p><figure id="fig:i2c_block_diagram"><span class="image placeholder" data-original-image-src="i2c_block_diagram.png" data-original-image-title="" width="80%"/><figcaption>Block Diagram of an I2C System</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="600" src="/images/projects/i2cv/i2c_block_diagram_hu9724975040744162600.webp" alt="Block Diagram of an I2C System" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/i2c_block_diagram_hu8969938300534542992.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="physical-layer">Physical layer</h4><h5 id="two-wire-communication">Two-Wire Communication</h5><p>An I2C system utilizes<strong>two shared communication lines</strong> for all
devices on the bus. These two lines facilitate<strong>bidirectional,
half-duplex communication</strong>. I2C supports multiple controllers and
multiple target devices, making it a flexible choice for various
applications. It is essential to use<strong>pull-up resistors</strong> on both of
these lines to ensure proper operation. Fig<a href="#fig:i2c_implementation">2.4</a>{reference-type=&ldquo;ref&rdquo;
reference=&ldquo;fig:i2c_implementation&rdquo;} shows a typical implementation of
the I2C physical layer.</p><figure id="fig:i2c_implementation"><span class="image placeholder" data-original-image-src="i2c_physical_layer.png" data-original-image-title="" width="80%"/><figcaption>Typical I2C Implementation</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="377" src="/images/projects/i2cv/i2c_physical_layer_hu5001890849971727351.webp" alt="Typical I2C Implementation" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/i2c_physical_layer_hu5413651912767855860.png'"/><p>One of the main reasons that I2C is a widely adopted protocol is due to
its requirement of only<strong>two lines</strong> for communication. The first line,<strong>SCL</strong>, is the serial clock line, primarily controlled by the
controller device. SCL is responsible for synchronously clocking data in
or out of the target device. The second line,<strong>SDA</strong>, is the serial
data line, used to transmit data to or from the target devices. For
instance, a controller device can send configuration data and output
codes to a target<strong>digital-to-analog converter (DAC)</strong>, or a target<strong>analog-to-digital converter (ADC)</strong> can send conversion data back to
the controller device.</p><p>I2C operates as a<strong>half-duplex communication</strong> protocol, meaning that
only one controller or target device can send data on the bus at any
given time. In contrast, the<strong>Serial Peripheral Interface (SPI)</strong> is a<strong>full-duplex protocol</strong> that allows data to be sent and received
simultaneously, requiring four lines for communication: two data lines
for sending and receiving data, along with a serial clock and a unique
SPI chip select line to select the device for communication.</p><p>An I2C controller device initiates and terminates communication, which
eliminates potential issues related to<strong>bus contention</strong>. Communication
with a target device is established through a<strong>unique address</strong> on the
bus, allowing multiple controllers and multiple target devices to
coexist on the I2C bus.</p><p>The SDA and SCL lines have an<strong>open-drain connection</strong> to all devices
on the bus, necessitating a pull-up resistor connected to a common
voltage supply.</p><h5 id="open-drain-connection">Open-Drain Connection</h5><p>The<strong>open-drain connections</strong> are employed on both the SDA and SCL
lines and are linked to an NMOS transistor. This open-drain
configuration manages the I2C communication line by either pulling the
line low or allowing it to rise to a high state. The term "open-drain"
refers to the NMOS bus connection when the NMOS is turned<strong>OFF</strong>.
Figure<a href="#fig:open_drain_connection">2.5</a>{reference-type=&ldquo;ref&rdquo;
reference=&ldquo;fig:open_drain_connection&rdquo;} illustrates the open-drain
connection when the NMOS is turned<strong>ON</strong>.</p><figure id="fig:open_drain_connection"><span class="image placeholder" data-original-image-src="open_drain_connection.png" data-original-image-title="" width="80%"/><figcaption>Open-Drain Connection Pulls Line Low When NMOS is Turned
On</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="408" src="/images/projects/i2cv/open_drain_connection_hu11847467768529842632.webp" alt="Open-Drain Connection Pulls Line Low When NMOS is Turned On" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/open_drain_connection_hu6074012038034762589.png'"/><p>To establish the voltage level of the SDA or SCL line, the NMOS
transistor is either switched<strong>ON</strong> or<strong>OFF</strong>. When the NMOS is<strong>ON</strong>, it allows current to flow through the resistor to ground,
effectively pulling the open-drain line low. This transition from high
to low is typically rapid, as the NMOS quickly discharges any
capacitance on the SDA or SCL lines.</p><p>When the NMOS turns<strong>OFF</strong>, the device ceases to pull current, and the
pull-up resistor subsequently raises the SDA or SCL line back to<strong>VDD</strong>. Figure<a href="#fig:open_drain_off">2.6</a>{reference-type=&ldquo;ref&rdquo;
reference=&ldquo;fig:open_drain_off&rdquo;} shows the open-drain line when the NMOS
is turned<strong>OFF</strong>, illustrating how the pull-up resistor brings the line
high.</p><figure id="fig:open_drain_off"><span class="image placeholder" data-original-image-src="open_drain_off.png" data-original-image-title="" width="80%"/><figcaption>Open-Drain Line with NMOS Turned Off</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="469" src="/images/projects/i2cv/open_drain_off_hu4560108909222930383.webp" alt="Open-Drain Line with NMOS Turned Off" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/open_drain_off_hu5878766402834574374.png'"/><p>The transition of the open-drain line to a high state is slower because
the line is pulled up against the bus capacitance, rather than being
actively driven high.</p><h4 id="i2c-protocol">I2C Protocol</h4><p>Communication over<strong>I2C</strong> requires a specific signaling protocol to
ensure that devices on the bus recognize valid I2C transmissions. While
this process is more intricate than<strong>UART</strong> or<strong>SPI</strong>, most
I2C-compatible devices handle the finer protocol details internally,
allowing developers to focus primarily on data exchange.</p><p><strong>SDA and SCL Lines:</strong> The I2C bus operates with two main lines:<strong>SDA</strong>
(Serial Data Line) and<strong>SCL</strong> (Serial Clock Line). Data is transmitted
over the<strong>SDA</strong> line in sync with clock pulses on the<strong>SCL</strong> line.
Generally, data is placed on<strong>SDA</strong> when<strong>SCL</strong> is low, and devices
sample this data when<strong>SCL</strong> goes high. If needed, multiple internal<strong>registers</strong> may control data handling, especially in complex devices.</p><p><strong>Protocol Components:</strong></p><p>1.<strong>Start Condition:</strong> To initiate communication, the controller sets<strong>SCL</strong> high and then pulls<strong>SDA</strong> low. This signals all peripheral
devices on the bus that a transmission is starting. In cases where
multiple controllers attempt to start communication simultaneously, the
first device to pull<strong>SDA</strong> low gains control. If necessary, the
controller can issue repeated start conditions to maintain bus control
without releasing it.</p><p>2.<strong>Address Frame:</strong> Every I2C transmission begins with an<strong>address
frame</strong> to specify the target peripheral. This frame consists of a 7-bit
address, sent<strong>MSB</strong> (most significant bit) first, followed by a<strong>R/W
bit</strong> indicating the operation type (read or write).</p><p>After this, the 9th bit, known as the<strong>ACK/NACK bit</strong>, is used by the
receiving device to confirm reception. If the device pulls<strong>SDA</strong> low
before the 9th clock pulse (<strong>ACK</strong>), communication continues. If not
(<strong>NACK</strong>), it indicates either unrecognized data or an issue in
reception, prompting the controller to decide the next steps.</p><p>3.<strong>Data Frames:</strong> Following the address frame, one or more<strong>data
frames</strong> are sent over the<strong>SDA</strong> line. Each data frame is 8 bits, and
data is transferred from the controller to the peripheral or vice versa,
based on the<strong>R/W bit</strong> in the address frame.</p><p>Many peripheral devices have auto-incrementing<strong>internal registers</strong>,
enabling data to continue from consecutive registers without the need to
re-specify the register address.</p><p>4.<strong>Stop Condition:</strong> The controller ends communication by generating
a<strong>stop condition</strong>. This is done by transitioning<strong>SDA</strong> from low to
high after a high-to-low transition on<strong>SCL</strong>, with<strong>SCL</strong> held high
during the stop sequence. To avoid false stop conditions, the value on<strong>SDA</strong> should not change while<strong>SCL</strong> is high during regular data
transmission.</p><p>The<strong>I2C protocol</strong> divides communication into structured<strong>frames</strong>.
Each communication sequence begins with a<strong>START</strong> condition, initiated
by the controller, followed by an<strong>address frame</strong> and then one or more<strong>data frames</strong>. Every frame also includes an acknowledgment (ACK) bit,
signaling that the frame has been received successfully by the intended
device.<strong>Figure 3-3</strong> illustrates the structure of two I2C
communication frames, showing both address and data frames in detail.</p><figure id="fig:i2c_frames"><span class="image placeholder" data-original-image-src="i2c_frames.png" data-original-image-title="" width="80%"/><figcaption>I2C Address and Data Frames</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="214" src="/images/projects/i2cv/i2c_frames_hu8079952379911720152.webp" alt="I2C Address and Data Frames" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/i2c_frames_hu17776359726810003991.png'"/><p>In an I2C transaction, the controller first sends a<strong>START condition</strong>
by pulling the<strong>SDA</strong> line low, followed by the<strong>SCL</strong> line. This
sequence asserts control over the bus, preventing other devices from
interfering. Each target device on the I2C bus has a unique<strong>7-bit
address</strong>, allowing the controller to specify which target device it
intends to communicate with.</p><p>Once the address is set on<strong>SDA</strong> while<strong>SCL</strong> acts as the clock, the<strong>8th bit</strong> (R/W bit) indicates the intended operation type:<strong>read
(1)</strong> or<strong>write (0)</strong>. This initial address and R/W bit are followed by
an<strong>ACK bit</strong>, sent by the target device to confirm receipt. If the
target device receives the address successfully, it pulls<strong>SDA</strong> low
during the next<strong>SCL</strong> pulse, signaling an ACK. If no device
acknowledges, the line remains high, signaling a<strong>NACK</strong>.</p><p>After the address frame, one or more<strong>data frames</strong> follow. Each data
frame contains 8 bits of data, which are acknowledged (ACK) in the 9th
bit. If the data frame is a<strong>write</strong> operation, the target device pulls<strong>SDA</strong> low to confirm data receipt. For<strong>read</strong> operations, the
controller pulls<strong>SDA</strong> low to acknowledge receipt of the data. The
presence or absence of the ACK is essential for troubleshooting, as a
missing ACK may indicate an addressing error or transmission failure.</p><p>Finally, the communication ends with a<strong>STOP condition</strong>, where the
controller releases<strong>SCL</strong> first, followed by<strong>SDA</strong>. This action
releases the I2C bus for other devices to use, completing the
communication cycle.</p><p>This structured protocol allows for the transmission of multiple bytes
within one communication sequence. In cases where a target device has
multiple internal<strong>registers</strong>, a write operation can specify the
register to read or write data to, enhancing flexibility and enabling
complex data transactions.</p><h1 id="module-specifications">Module Specifications</h1><h4 id="master-module">MASTER MODULE</h4><h5 id="code">CODE</h5><p>This module enables communication with I2C-compatible devices through
the I2C protocol by implementing the necessary operations to generate
I2C signals and manage data transfer. Let&rsquo;s break down each section of
the code:</p><h6 id="module-declaration">Module Declaration</h6><p>The code begins with the module declaration:</p><blockquote><pre><code>module i2c_master(
input wire clk, // System clock
input wire rst, // Synchronous reset
input wire [6:0] addr, // 7-bit I2C address
input wire [7:0] data_in, // Data to be transmitted
input wire enable, // Enable signal to start I2C transaction
input wire rw, // Read/Write control (0 = Write, 1 = Read)
output reg [7:0] data_out, // Data received from I2C
output wire ready, // Ready signal when module is idle
inout i2c_sda, // I2C data line (SDA)
inout wire i2c_scl // I2C clock line (SCL)
);</code></pre></blockquote><p>This module contains inputs for the system clock (<code>clk</code>), reset (<code>rst</code>),
I2C address (<code>addr</code>), data to be sent (<code>data_in</code>), an enable signal
(<code>enable</code>), and a Read/Write control (<code>rw</code>). It also provides outputs
for data received (<code>data_out</code>), a ready status signal (<code>ready</code>), and
bidirectional I2C lines,<code>i2c_sda</code> and<code>i2c_scl</code>.</p><h6 id="state-machine-definition">State Machine Definition</h6><p>The code defines several states representing stages in the I2C
transaction:</p><blockquote><pre><code>localparam IDLE = 0;
localparam START = 1;
localparam ADDRESS = 2;
localparam READ_ACK = 3;
localparam WRITE_DATA = 4;
localparam WRITE_ACK = 5;
localparam READ_DATA = 6;
localparam READ_ACK2 = 7;
localparam STOP = 8;</code></pre></blockquote><p>Each<code>localparam</code> corresponds to a state in the Finite State Machine
(FSM), controlling the I2C protocol flow, including start, address
transmission, acknowledgment (ACK) reception, data transfer, and stop
condition generation.</p><h6 id="clock-divider">Clock Divider</h6><p>To generate a slower clock for the I2C operations, a clock divider is
implemented:</p><blockquote><pre><code>always @(posedge clk) begin
if (counter2 == (DIVIDE_BY / 2) - 1) begin
i2c_clk &lt;= ~i2c_clk;
counter2 &lt;= 0;
end else counter2 &lt;= counter2 + 1;
end</code></pre></blockquote><p>This block toggles<code>i2c_clk</code> at a lower frequency than the system clock,<code>clk</code>, using a counter<code>counter2</code> with a division factor defined by<code>DIVIDE_BY</code>.</p><h6 id="sda-and-scl-control">SDA and SCL Control</h6><p>To control the<code>i2c_sda</code> and<code>i2c_scl</code> lines based on the module&rsquo;s
state:</p><blockquote><pre><code>assign ready = ((rst == 0) &amp;&amp; (state == IDLE)) ? 1 : 0;
assign i2c_scl = (i2c_scl_enable == 0) ? 1 : i2c_clk;
assign i2c_sda = (write_enable == 1) ? sda_out : 'bz;</code></pre></blockquote><ul><li><p><code>ready</code> is high when the reset is inactive and the state is<code>IDLE</code>.</p></li><li><p><code>i2c_scl</code> is either high (idle state) or follows the divided<code>i2c_clk</code> signal.</p></li><li><p><code>i2c_sda</code> outputs the value of<code>sda_out</code> when<code>write_enable</code> is
active. When<code>write_enable</code> is inactive,<code>i2c_sda</code> goes to
high-impedance (<code>’bz</code>) for reading data.</p></li></ul><h6 id="finite-state-machine-fsm">Finite State Machine (FSM)</h6><p>The FSM controls the I2C communication process, progressing through
states based on the I2C protocol requirements:</p><blockquote><pre><code>always @(posedge i2c_clk or posedge rst) begin
if (rst == 1) begin
state &lt;= IDLE;
end else begin
case (state)
IDLE: begin
if (enable) begin
state &lt;= START;
saved_addr &lt;= {addr, rw};
saved_data &lt;= data_in;
end
end
START: begin
counter &lt;= 7;
state &lt;= ADDRESS;
end
...
STOP: begin
state &lt;= IDLE;
end
endcase
end
end</code></pre></blockquote><p>Each state corresponds to an I2C operation:</p><ul><li><p><code>IDLE</code>: Waits for<code>enable</code> signal to initiate communication.</p></li><li><p><code>START</code>: Prepares a start condition by asserting<code>sda_out</code> low.</p></li><li><p><code>ADDRESS</code>: Sends the address and R/W bit.</p></li><li><p><code>READ_ACK</code> and<code>READ_ACK2</code>: Verifies acknowledgment (ACK) from the
slave.</p></li><li><p><code>WRITE_DATA</code> and<code>WRITE_ACK</code>: Transfers data to the slave and waits
for ACK.</p></li><li><p><code>READ_DATA</code>: Receives data from the slave.</p></li><li><p><code>STOP</code>: Generates a stop condition and returns to<code>IDLE</code>.</p></li></ul><h6 id="sda-output-logic">SDA Output Logic</h6><p>The logic for controlling the<code>i2c_sda</code> line, depending on the FSM
state, is implemented as follows:</p><blockquote><pre><code>always @(negedge i2c_clk or posedge rst) begin
if (rst == 1) begin
write_enable &lt;= 1;
sda_out &lt;= 1;
end else begin
case (state)
START: begin
write_enable &lt;= 1;
sda_out &lt;= 0;
end
ADDRESS: begin
sda_out &lt;= saved_addr[counter];
end
...
STOP: begin
write_enable &lt;= 1;
sda_out &lt;= 1;
end
endcase
end
end</code></pre></blockquote><ul><li><p>In the<code>START</code> state,<code>sda_out</code> goes low to generate a start
condition.</p></li><li><p>In the<code>ADDRESS</code> and<code>WRITE_DATA</code> states,<code>sda_out</code> sends the bits
of<code>saved_addr</code> or<code>saved_data</code>.</p></li><li><p>In<code>STOP</code>,<code>sda_out</code> goes high to signify the end of the
transmission.</p></li></ul><p>This Verilog module effectively implements an I2C Master communication
sequence by controlling the<code>i2c_sda</code> and<code>i2c_scl</code> lines according to
the I2C protocol.</p><h4 id="slave-module">SLAVE MODULE</h4><h5 id="code-1">CODE</h5><p>I2C Slave Module implements
the core logic for an I2C slave device capable of receiving and
transmitting data over the I2C protocol. Let&rsquo;s break down the components
of the code and their functionality:</p><h6 id="module-declaration-1">Module Declaration</h6><p>The module begins with the declaration of inputs and outputs:</p><blockquote><pre><code>module i2c_slave(
input [6:0] addr_in, // Dynamic address input for I2C slave
inout sda, // I2C data line (SDA)
inout scl // I2C clock line (SCL)
);</code></pre></blockquote><p>The inputs include a 7-bit address (<code>addr_in</code>) for the slave device,
along with the bidirectional<code>sda</code> and<code>scl</code> lines for data and clock
signals respectively.</p><h6 id="state-machine-definition-1">State Machine Definition</h6><p>The I2C protocol relies on a finite state machine (FSM) to control the
data transfer sequence. The FSM is represented by five states:</p><blockquote><pre><code>localparam READ_ADDR = 0;
localparam SEND_ACK = 1;
localparam READ_DATA = 2;
localparam WRITE_DATA = 3;
localparam SEND_ACK2 = 4;</code></pre></blockquote><p>Each state corresponds to a particular phase of the I2C communication: -<code>READ_ADDR</code>: Reads the I2C address and R/W bit. -<code>SEND_ACK</code>: Sends
acknowledgment (ACK) if the address matches. -<code>READ_DATA</code>: Receives
data from the master. -<code>WRITE_DATA</code>: Sends data to the master. -<code>SEND_ACK2</code>: Sends a second ACK after data reception.</p><h6 id="internal-registers-and-signals">Internal Registers and Signals</h6><p>Several internal registers and signals are declared to support the
functionality of the I2C slave: -<code>addr</code> holds the slave address and R/W
bit. -<code>counter</code> is used to count bits during transmission. -<code>state</code>
holds the current FSM state. -<code>data_in</code> and<code>data_out</code> store the
incoming and outgoing data, respectively. -<code>sda_out</code> and<code>sda_in</code>
control the data line (SDA). -<code>start</code> flags the detection of the I2C
start condition. -<code>write_enable</code> controls whether the slave can drive
the SDA line.</p><h6 id="sda-line-control">SDA Line Control</h6><p>The assignment of the<code>sda</code> line is conditional on the<code>write_enable</code>
signal:</p><blockquote><pre><code>assign sda = (write_enable == 1) ? sda_out : 'bz;</code></pre></blockquote><p>This means that the slave drives the<code>sda</code> line when<code>write_enable</code> is
active, otherwise, the line is in high-impedance state (&lsquo;bz).</p><h6 id="start-and-stop-condition-detection">Start and Stop Condition Detection</h6><p>The start condition is detected when there is a falling edge on the<code>sda</code> line while the<code>scl</code> line is high, and the stop condition is
detected when there is a rising edge on the<code>sda</code> line while<code>scl</code> is
high. These conditions trigger transitions in the FSM.</p><blockquote><pre><code>always @(negedge sda) begin
if ((start == 0) &amp;&amp; (scl == 1)) begin
start &lt;= 1; // Set start flag
counter &lt;= 7; // Initialize bit counter
end
end
always @(posedge sda) begin
if ((start == 1) &amp;&amp; (scl == 1)) begin
state &lt;= READ_ADDR; // Transition to READ_ADDR state
start &lt;= 0; // Reset start flag
write_enable &lt;= 0; // Disable write
end
end</code></pre></blockquote><p>These blocks capture the start and stop conditions and manage the FSM
transitions accordingly.</p><h6 id="fsm-logic-for-data-transfer">FSM Logic for Data Transfer</h6><p>The FSM operates on the rising edge of the<code>scl</code> signal, progressing
through various states based on the detected conditions:</p><blockquote><pre><code>always @(posedge scl) begin
if (start == 1) begin
case(state)
READ_ADDR: begin
addr[counter] &lt;= sda;
if(counter == 0) state &lt;= SEND_ACK;
else counter &lt;= counter - 1;
end
SEND_ACK: begin
if(addr[7:1] == addr_in) begin
counter &lt;= 7;
if(addr[0] == 0) begin
state &lt;= READ_DATA; // If write mode, move to READ_DATA
end else state &lt;= WRITE_DATA; // Else move to WRITE_DATA
end else state &lt;= READ_ADDR;
end
...
endcase
end
end</code></pre></blockquote><p>The state transitions depend on whether the address matches, the R/W
bit, and whether data is being read or written. The<code>SEND_ACK</code> state
sends an acknowledgment if the address is correct, while the<code>READ_DATA</code>
and<code>WRITE_DATA</code> states handle data reception and transmission
respectively.</p><h6 id="sda-output-logic-1">SDA Output Logic</h6><p>The logic for controlling the<code>sda</code> output during the FSM states is
defined in the following block:</p><blockquote><pre><code>always @(negedge scl) begin
case(state)
READ_ADDR: begin
write_enable &lt;= 0; // Disable writing during address read
end
SEND_ACK: begin
sda_out &lt;= (addr[7:1] == addr_in) ? 0 : 1; // Send ACK (0) or NACK (1)
write_enable &lt;= 1;
end
READ_DATA: begin
write_enable &lt;= 0; // Disable writing during data read
end
WRITE_DATA: begin
sda_out &lt;= data_out[counter]; // Output data bit by bit
write_enable &lt;= 1;
end
SEND_ACK2: begin
sda_out &lt;= 0; // Send ACK (0) after data reception
write_enable &lt;= 1;
end
endcase
end</code></pre></blockquote><p>Each state manipulates the<code>sda_out</code> signal to either send an
acknowledgment (ACK) or transmit the data bit by bit. The<code>SEND_ACK</code>
state checks the address match and sends either an ACK or NACK. The<code>WRITE_DATA</code> state sends the data, while the<code>SEND_ACK2</code> state sends an
ACK after data reception.</p><h6 id="summary">Summary</h6><p>This Verilog code implements a simple I2C Slave module that can handle
basic I2C communication. It includes start/stop condition detection,
address matching, data reception, and data transmission using an FSM.
The module can receive data from the I2C master, send data to it, and
properly acknowledge the master at each step in the communication
process.</p><h4 id="top-level-module">TOP-LEVEL MODULE</h4><h5 id="code-2">CODE</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Top module to integrate i2c_master and i2c_slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Top module to integrate i2c_master and i2c_slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">module</span> top(</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> clk,<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rst,<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr,<span style="color:#75715e">// 7-bit I2C address for the master to communicate with</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in,<span style="color:#75715e">// Data to be sent from the master to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> enable,<span style="color:#75715e">// Enable signal to initiate I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span><span style="color:#66d9ef">wire</span> rw,<span style="color:#75715e">// Read/Write signal (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out,<span style="color:#75715e">// Data received by the master from the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span><span style="color:#66d9ef">wire</span> ready,<span style="color:#75715e">// Signal indicating the master is ready for a new operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_sda,<span style="color:#75715e">// I2C data line (SDA) - bidirectional</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">inout</span><span style="color:#66d9ef">wire</span> i2c_scl<span style="color:#75715e">// I2C clock line (SCL)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>);</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Internal register to store the address the slave will respond to.</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// This is the fixed address of the slave in this example.</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] slave_address<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0101010</span>;<span style="color:#75715e">// Example default slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the I2C slave module</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> i2c_slave slave_inst (</span></span><span style="display:flex;"><span> .addr_in(slave_address),<span style="color:#75715e">// Provide the fixed slave address to the slave instance</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .sda(i2c_sda),<span style="color:#75715e">// Connect the slave's SDA line to the top-level SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .scl(i2c_scl)<span style="color:#75715e">// Connect the slave's SCL line to the top-level SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> );</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the I2C master module</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> i2c_master master_inst (</span></span><span style="display:flex;"><span> .clk(clk),<span style="color:#75715e">// Connect the system clock to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rst(rst),<span style="color:#75715e">// Connect the reset signal to the master</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .addr(addr),<span style="color:#75715e">// Provide the I2C address the master should communicate with</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_in(data_in),<span style="color:#75715e">// Data to be sent to the slave (if writing)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .enable(enable),<span style="color:#75715e">// Enable signal to start the I2C transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rw(rw),<span style="color:#75715e">// Read/Write signal (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_out(data_out),<span style="color:#75715e">// Data received from the slave (if reading)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .ready(ready),<span style="color:#75715e">// Master ready signal indicating it's idle or ready for a new transaction</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_sda(i2c_sda),<span style="color:#75715e">// Connect the master's SDA line to the top-level SDA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_scl(i2c_scl)<span style="color:#75715e">// Connect the master's SCL line to the top-level SCL</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> );</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation">Explanation</h5><ul><li><p>The<code>top</code> module connects an I2C master and slave module on shared<code>i2c_sda</code> and<code>i2c_scl</code> lines.</p></li><li><p>The<code>slave_address</code> register holds a predefined address used by the
slave.</p></li><li><p>The<code>i2c_slave</code> and<code>i2c_master</code> modules are instantiated and
connected to share the I2C lines and control signals.</p></li></ul><h4 id="testbench-module">TESTBENCH MODULE</h4><h5 id="code-3">CODE</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ps</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">module</span> i2c_controller_tb();</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Inputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> clk;<span style="color:#75715e">// System clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> rst;<span style="color:#75715e">// Reset signal</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] addr;<span style="color:#75715e">// Address for the master to communicate with</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_in;<span style="color:#75715e">// Data to be sent from the master to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> enable;<span style="color:#75715e">// Enable signal to start communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> rw;<span style="color:#75715e">// Read/Write control (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Outputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">7</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] data_out;<span style="color:#75715e">// Data received by the master from the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> ready;<span style="color:#75715e">// Ready signal indicating the master is ready for a new operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Bidirectional wires</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> i2c_sda;<span style="color:#75715e">// I2C data line (SDA) - shared between master and slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> i2c_scl;<span style="color:#75715e">// I2C clock line (SCL) - shared between master and slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the Top Module (Device Under Test - DUT)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> top uut (</span></span><span style="display:flex;"><span> .clk(clk),<span style="color:#75715e">// Connect system clock to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rst(rst),<span style="color:#75715e">// Connect reset signal to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .addr(addr),<span style="color:#75715e">// Connect address input to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_in(data_in),<span style="color:#75715e">// Connect data to be sent by master to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .enable(enable),<span style="color:#75715e">// Connect enable signal to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .rw(rw),<span style="color:#75715e">// Connect read/write control to DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .data_out(data_out),<span style="color:#75715e">// Receive data read by master from DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .ready(ready),<span style="color:#75715e">// Receive ready signal from DUT</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_sda(i2c_sda),<span style="color:#75715e">// Connect bidirectional SDA line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> .i2c_scl(i2c_scl)<span style="color:#75715e">// Connect bidirectional SCL line</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> );</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Clock generation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">initial</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> clk<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">forever</span> #<span style="color:#ae81ff">1</span> clk<span style="color:#f92672">=</span><span style="color:#f92672">~</span>clk;<span style="color:#75715e">// Toggle clock every 1 ns to generate a 2 ns period clock (500 MHz)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Test sequence to simulate I2C operations</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">initial</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Set up VCD file for waveform dumping</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> $dumpfile(<span style="color:#e6db74">"i2c_controller_tb.vcd"</span>);<span style="color:#75715e">// Name of the VCD file for waveform output</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> $dumpvars(<span style="color:#ae81ff">0</span>, i2c_controller_tb);<span style="color:#75715e">// Dump all variables in this module for waveform analysis</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Initialize Inputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rst<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert reset to initialize the system</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Initially disable communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0000000</span>;<span style="color:#75715e">// Set an initial address (not used immediately)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b0</span>;<span style="color:#75715e">// Set initial data (not used immediately)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Set initial operation to write (0 = Write, 1 = Read)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait for reset to complete</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">10</span>;</span></span><span style="display:flex;"><span> rst<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert reset after 10 ns to start normal operation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Test Case 1: Write operation with matching address (Expect ACK from slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0101010</span>;<span style="color:#75715e">// Set address to match the slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b10101010</span>;<span style="color:#75715e">// Data to be sent to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Set operation to write</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert enable to start the I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">20</span> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert enable after 20 ns to complete the command</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait and observe response (slave should ACK the address and receive data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">100</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Test Case 2: Write operation with non-matching address (Expect NACK from slave)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b1111111</span>;<span style="color:#75715e">// Set address to a non-matching address for the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> data_in<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#ae81ff">'b11001100</span>;<span style="color:#75715e">// Different data to be sent to the slave</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Set operation to write</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert enable to start the I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">20</span> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert enable after 20 ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait and observe response (slave should NACK the address since it does not match)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">100</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#75715e">// Test Case 3: Read operation with matching address (Expect ACK from slave and read data)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> addr<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span><span style="color:#ae81ff">'b0101010</span>;<span style="color:#75715e">// Set address to match the slave address</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> rw<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Set operation to read</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;<span style="color:#75715e">// Assert enable to start the I2C communication</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">20</span> enable<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;<span style="color:#75715e">// Deassert enable after 20 ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/></span></span><span style="display:flex;"><span><span style="color:#75715e">// Wait and observe response (slave should ACK the address and send data to master)</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> #<span style="color:#ae81ff">100</span>;</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span> #<span style="color:#ae81ff">200</span></span></span><span style="display:flex;"><span> $finish;<span style="color:#75715e">// End the simulation after 200 ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="explanation-1">Explanation</h5><ul><li><p><code>i2c_controller_tb</code>: Testbench module for the<code>top</code> module
integrating the master-slave I2C communication.</p></li><li><p>A clock signal is generated using a continuous<code>initial</code> block.</p></li><li><p>Test cases:</p><ul><li><p><strong>Test Case 1</strong>: Matches the slave address, expecting an ACK.</p></li><li><p><strong>Test Case 2</strong>: Uses a non-matching address, expecting a NACK.</p></li><li><p><strong>Test Case 3</strong>: Matches the address and tests a read operation.</p></li></ul></li><li><p>At the end of the test cases, the simulation finishes with<code>$finish</code>.</p></li></ul><h1 id="results">Results</h1><h4 id="test-case-1-address-match-with-write-operation">Test Case 1: Address Match with Write Operation</h4><figure><span class="image placeholder" data-original-image-src="TEST-CASE-1.jpg" data-original-image-title="" width="\textwidth"/><figcaption>Test Case 1</figcaption></figure><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/i2cv/TEST-CASE-2_hu6405931946634379952.webp" alt="Test Case 2" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/TEST-CASE-2_hu12279029995292422776.jpg'"/><p>The waveform in this test shows the master sending an address 7&rsquo;b0101010, which matches the slave’s configured address. Since the address matches, the slave acknowledges the communication by sending an ACK (acknowledgment) signal. After receiving the ACK, the master initiates a write operation, transmitting the data 8&rsquo;b10101010 to the slave. The enable signal is set to initiate communication and deasserted after a delay, allowing the transmission to complete. The presence of the ACK in this waveform confirms that the address was successfully matched, allowing data transfer.</p><figure><span class="image placeholder" data-original-image-src="TEST-CASE-2.jpg" data-original-image-title="" width="\textwidth"/><figcaption>Test Case 2</figcaption></figure><h4 id="test-case-2-address-mismatch-with-write-operation-expect-nack">Test Case 2: Address Mismatch with Write Operation (Expect NACK)</h4><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/i2cv/TEST-CASE-2_hu6405931946634379952.webp" alt="Test Case 3" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/TEST-CASE-2_hu12279029995292422776.jpg'"/><p>In this test case, the master sends a non-matching address 7&rsquo;b1111111, which does not correspond to the slave’s preset address. The waveform shows the absence of an acknowledgment signal (NACK) from the slave, indicating that the address verification failed and the data transfer cannot proceed. This NACK response is expected behavior when the slave does not recognize the transmitted address. The enable signal initiates the communication, but with no matching address and no ACK received, data transfer is not established.</p><figure><span class="image placeholder" data-original-image-src="TEST-CASE-3.jpg" data-original-image-title="" width="\textwidth"/><figcaption>Test Case 3</figcaption></figure><h4 id="test-case-3-address-match-with-read-operation">Test Case 3: Address Match with Read Operation</h4><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/i2cv/TEST-CASE-3_hu5097597462133817533.webp" alt="Test Case 3" onerror="this.onerror='null';this.src='\/images\/projects\/i2cv\/TEST-CASE-3_hu16799201968338071699.jpg'"/><p>The final waveform demonstrates a read operation with the master sending a matching address 7&rsquo;b0101010. Upon recognizing the address, the slave responds with an ACK signal, confirming the communication link. Following the acknowledgment, the master initiates a read operation, and the slave provides the preloaded data 8&rsquo;b11001100 to the master. The enable signal triggers the start of communication and is deasserted after a delay, allowing the master to read the data. This successful transmission and receipt of data verify correct read functionality with an address match.</p><h3 id="challenges-and-risk-analysis">Challenges and Risk Analysis</h3><h4 id="potential-issues-and-solutions">Potential Issues and Solutions</h4><p>In the development of the I2C communication project, I encountered several challenges, starting with the design of basic Verilog modules for both master and slave entities capable of fundamental read and write operations. After an initial review of the I2C protocol from various online resources and Verilog syntax, I designed a preliminary testbench module to simulate and validate the basic functionality.</p><p>As the project progressed, I introduced additional functionality, including ACK and NACK flags, to handle incorrect slave addresses and refined the finite state machine (FSM) logic for more reliable state transitions. To make the slave module independent of global configurations, I designed a top-level module that instantiated both the master and slave modules and added an extra layer of address validation.</p><p>For synchronization, I implemented clock stretching between address and data frames. This addition worked effectively during address transmission but revealed timing issues during data frame read operations. After extensive troubleshooting, I identified limitations in the initial approach and modified the design accordingly.</p><p>I also explored a multi-master, multi-slave configuration, assigning slave addresses in the format<code>10101XY</code> (with<code>XY</code> values as 00, 01, 10, and 11 for slaves 1 through 4) and a master select line in the testbench to choose the active master. Preloaded data in each slave was structured as<code>110011XY</code> to streamline read operations. However, unresolved synchronization issues in the multi-master setup led me to scale back to a single-master, single-slave model, excluding clock stretching and multiple nodes. The final design focuses on single-point communication, with code attempts for the multi-master setup included in the project appendix on GitHub.</p><h4 id="risk-management">Risk Management</h4><p>Several potential risks emerged during the design and integration phases:</p><ul><li><p><strong>Design Complexity</strong>: The complexity of the I2C protocol and multi-node configuration posed unforeseen design challenges. A modular testing approach mitigated these risks by allowing iterative refinements.</p></li><li><p><strong>Timing Issues</strong>: Timing mismatches, particularly in multi-master configurations, impacted protocol accuracy. While resolved in the single-master model, this remains an area for future improvement.</p></li><li><p><strong>FSM Complexity</strong>: Introducing ACK/NACK handling increased the complexity of the FSM, raising the potential for state transition errors. Comprehensive simulation and debugging minimized these risks.</p></li></ul><p>In this project, I implemented the clock stretching functionality and addressed timing issues in data frame read operations. Starting with basic I2C modules, I managed the synchronization aspect by incorporating clock stretching between address and data frames, a mechanism crucial for addressing timing issues in the protocol. Despite progress, some discrepancies remain in the data frame during read operations, which are planned for future enhancements.</p><p>Additionally, I expanded the basic modules by introducing acknowledgment (ACK) and negative acknowledgment (NACK) flags to handle erroneous addresses. I refined the FSM logic to improve state transitions, address handling, and protocol management complexities. While the initial goal was a multi-master configuration with selectable slave nodes, unresolved timing issues led to a focus on a single-master, single-slave model, effectively capturing the core aspects of I2C communication in the final implementation.</p><h3 id="future-work-and-improvements">Future Work and Improvements</h3><h4 id="suggested-enhancements">Suggested Enhancements</h4><p>Future enhancements to this project could include adding more registers
to each slave, allowing for more sophisticated data handling. Additional
registers would enable more extensive data storage and retrieval options
in each slave device, making the project closer to real-world I2C
applications.</p><h4 id="alternative-designs">Alternative Designs</h4><p>Exploring alternative FSM architectures could improve the efficiency and
stability of the I2C protocol, especially for multi-master
configurations. Further, advanced data synchronization techniques,
possibly through modified clock stretching or data frame timing
adjustments, could address the current timing issues. Replacing the
current point-to-point master-slave setup with a robust multi-node
configuration, if resolved, could significantly enhance the protocol&rsquo;s
scalability.</p><h3 id="appendices">Appendices</h3><h4 id="verilog-code-listings">Verilog Code Listings</h4><p>The complete Verilog code for the I2C Master module, including support
for multi-master/slave configuration and clock stretching, is available
in the following GitHub repository:</p><p><strong>Repository:</strong><a href="https://github.com/Mummanajagadeesh/I2C-protocol-verilog" target="_blank">https://github.com/Mummanajagadeesh/I2C-protocol-verilog</a></p><h4 id="references">References</h4><ol><li><p>Texas Instruments,<em>A Basic Guide to I2C</em>, Available at:<a href="https://www.ti.com/lit/pdf/sbaa565" target="_blank">https://www.ti.com/lit/pdf/sbaa565</a></p></li><li><p>Prodigy Technoinnovations,<em>I2C Protocol</em>, Available at:<a href="https://www.prodigytechno.com/i2c-protocol" target="_blank">https://www.prodigytechno.com/i2c-protocol</a></p></li><li><p>SparkFun,<em>I2C Tutorial</em>, Available at:<a href="https://learn.sparkfun.com/tutorials/i2c/all" target="_blank">https://learn.sparkfun.com/tutorials/i2c/all</a></p></li><li><p>Class Lectures,<em>Verilog Code Syntax</em></p></li></ol><blockquote><p>Most images in this document are adapted from the above
resources. All images are copyrighted by their respective owners; no
ownership rights are claimed.</p></blockquote>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/rubec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/rubec/</guid><description>&lt;![CDATA[<h2 id="ru83c-rubiks-cube-solving-robothttpsgithubcommummanajagadeeshru83c"><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83C: Rubik&rsquo;s Cube Solving Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>RU83C</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Rubik&rsquo;s Cube-solving robot using Kociemba algorithm, featuring computer vision for state detection, mechanical design for cube manipulation, and electronics for execution.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(July 2023), Implementation(Aug 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83C🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Algorithms, Programming, Game Dev</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Unity3D, Python, C#, VS Code, OpenCV, Fusion 360, ArduinoIDE</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Unity3D implementation is done.<br> - Mechanical Design is started in Fusion 360<br> - CV part code is ready, color ranges yet to be tuned</td></tr><tr><td><strong>Next Steps</strong></td><td>- CV (Computer Vision): Responsible for recognizing the scrambled state of the cube via a camera.<br> - Mechanical Design: Focused on the creation of the holder and gripping mechanisms to manipulate the cube.<br> - Electronics: Controls and coordinates the robot’s movements based on the computed solution.</td></tr></tbody></table><hr><h4 id="overview">Overview</h4><p>RU83C is a Rubik&rsquo;s Cube-solving robot that leverages computer vision (CV), mechanical design, and electronics to solve a scrambled Rubik&rsquo;s Cube using the Kociemba algorithm. The robot features a camera that captures the current state of the scrambled cube, processes the image using CV, and calculates the solution. A mechanical holder grips the cube securely, and the robot executes the necessary moves to solve it.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="ru83c-rubiks-cube-solving-robothttpsgithubcommummanajagadeeshru83c"><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83C: Rubik&rsquo;s Cube Solving Robot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>RU83C</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Rubik&rsquo;s Cube-solving robot using Kociemba algorithm, featuring computer vision for state detection, mechanical design for cube manipulation, and electronics for execution.</td></tr><tr><td><strong>Start</strong></td><td>Ideation(July 2023), Implementation(Aug 2023)</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/RU83C/" target="_blank">RU83C🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Algorithms, Programming, Game Dev</td></tr><tr><td><strong>Tools Used</strong></td><td>Blender, Unity3D, Python, C#, VS Code, OpenCV, Fusion 360, ArduinoIDE</td></tr><tr><td><strong>Current Status</strong></td><td>Ongoing (Passive)</td></tr><tr><td><strong>Progress</strong></td><td>- Unity3D implementation is done.<br> - Mechanical Design is started in Fusion 360<br> - CV part code is ready, color ranges yet to be tuned</td></tr><tr><td><strong>Next Steps</strong></td><td>- CV (Computer Vision): Responsible for recognizing the scrambled state of the cube via a camera.<br> - Mechanical Design: Focused on the creation of the holder and gripping mechanisms to manipulate the cube.<br> - Electronics: Controls and coordinates the robot’s movements based on the computed solution.</td></tr></tbody></table><hr><h4 id="overview">Overview</h4><p>RU83C is a Rubik&rsquo;s Cube-solving robot that leverages computer vision (CV), mechanical design, and electronics to solve a scrambled Rubik&rsquo;s Cube using the Kociemba algorithm. The robot features a camera that captures the current state of the scrambled cube, processes the image using CV, and calculates the solution. A mechanical holder grips the cube securely, and the robot executes the necessary moves to solve it.</p><h4 id="features">Features</h4><p><strong>Computer Vision</strong>: A camera-based system to detect the current state of the Rubik&rsquo;s Cube, using image processing techniques to translate the visual input into a digital cube representation.</p><p><strong>Mechanical Design</strong>: A custom-built holder with an efficient gripping system to securely hold and rotate the cube while executing the solution.</p><p><strong>Kociemba Algorithm</strong>: The Kociemba algorithm is employed to calculate the optimal solution for the scrambled state.</p><p><strong>Electronics</strong>: The system uses electronics to control the motors and mechanical components, translating the calculated moves into physical actions.</p><h4 id="structure">Structure</h4><p>The project is divided into several key parts:</p><ol><li><p>CV (Computer Vision): Responsible for recognizing the scrambled state of the cube via a camera.</p></li><li><p>Mechanical Design: Focused on the creation of the holder and gripping mechanisms to manipulate the cube.</p></li><li><p>Algorithm: Implementation of the Kociemba algorithm to calculate the solution to any scrambled state.</p></li><li><p>Electronics: Controls and coordinates the robot’s movements based on the computed solution.</p></li></ol><h4 id="base-version">Base Version</h4><p>A base version of this project was previously developed in simulation, where users could manually or automatically scramble a virtual cube in Unity. The solution for the scrambled cube was calculated and displayed in the virtual environment. This was an intermediate step, and the current version represents the full hardware implementation of the Rubik&rsquo;s Cube-solving robot.</p><p>BASE VERSION:<a href="https://github.com/Mummanajagadeesh/V-RU81K5CU83" target="_blank">here</a> &ndash;implemented in simulation using Unity3D(C#)</p><h2 id="base-version-1">BASE VERSION</h2><h3 id="v-ru81k5cu83---virtual-rubiks-cube-using-kociemba-solverhttpsgithubcommummanajagadeeshv-ru81k5cu83"><a href="https://github.com/Mummanajagadeesh/V-RU81K5CU83" target="_blank">V-RU81K5CU83 - Virtual Rubik&rsquo;s Cube Using Kociemba Solver</a></h3><p>A virtual Rubik&rsquo;s Cube implemented using the<strong>Kociemba algorithm</strong> for solving scrambled states. This project offers an interactive 3D simulation of a Rubik&rsquo;s Cube that you can scramble, manipulate manually, and solve. The solution is computed using the Kociemba two-phase algorithm, widely known for its efficiency in solving Rubik&rsquo;s cubes with minimal moves.</p><p>Deployment: This project is deployed using a WebGL server with Node.js alongside GitHub Pages for hosting the live demo.</p><p><strong>INSPIRATION:</strong><a href="https://www.megalomobile.com/" target="_blank">@Megalomobile</a></p><p><strong><a href="https://mummanajagadeesh.github.io/v-cube-host/" target="_blank">Click here for the Live Demo</a> |<a href="https://v-cube-host.vercel.app/" target="_blank">Vercel</a></strong></p><h4 id="features-1">Features</h4><ul><li><strong>Interactive 3D Cube</strong>: Manipulate the cube by dragging and rotating different layers in 3D space.</li><li><strong>Scramble &amp; Solve</strong>: Automatically scramble the cube or solve any configuration using the Kociemba algorithm.</li><li><strong>Unity/Blender Simulation</strong>: Visual simulations and demos showcasing the solution steps.</li></ul><h4 id="demo-videos">Demo Videos</h4><table><thead><tr><th>Unity 3D Demo</th><th>Blender Solution Demo</th></tr></thead><tbody><tr><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/L4s2YYyi-70" frameborder="0" allowfullscreen=/></div></div></td><td><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/pQN5wu2dtTQ" frameborder="0" allowfullscreen=/></div></div></td></tr></tbody></table><h4 id="project-overview">Project Overview</h4><p>This project leverages the pre-existing<strong>Kociemba two-phase algorithm</strong> for Rubik&rsquo;s Cube solving, and our main contribution has been the seamless integration of this algorithm into a Unity-based simulation. The role of the solver is crucial, as it computes the solution when a scrambled cube is presented.</p><p>We designed the system to fetch cube states directly from the user interface, where users can scramble or manipulate the cube. Upon clicking the &ldquo;Solve&rdquo; button, the Kociemba algorithm works under the hood to generate an optimal solution, which is then passed to the Unity engine. The Unity environment simulates this solution visually, step by step, allowing users to see the cube&rsquo;s transformation in real-time.</p><p>The<strong>Blender solution demo</strong> featured here is purely a visual mockup, simulating how the cube might appear when following a solved sequence. It serves as a demonstration for visual feedback but has no direct involvement in the solving process or algorithm implementation. This is an intermediate step showcasing the solution process and will be further integrated into Unity for enhanced user interaction.</p><h2 id="kociembas-algorithm-for-solving-a-rubiks-cube"><strong>Kociemba’s Algorithm for Solving a Rubik’s Cube</strong></h2><p>Kociemba’s Algorithm is a two-phase algorithm used to efficiently solve a 3×3 Rubik’s Cube in a minimal number of moves. It is an advanced method that improves upon simpler approaches, such as layer-by-layer (LBL) solving, by reducing the number of moves required to solve the cube.</p><p>Kociemba’s Algorithm is often used in optimal cube solvers, and it serves as the basis for algorithms like Herbert Kociemba’s Cube Explorer and the well-known<strong>Two-Phase Algorithm</strong>.</p><hr><h4 id="overview-of-the-algorithm"><strong>Overview of the Algorithm</strong></h4><p>The algorithm consists of two main phases:</p><ol><li><strong>Phase 1</strong>: Reducing the cube to a subset of solvable states known as the<strong>&ldquo;G1 group&rdquo;</strong>.</li><li><strong>Phase 2</strong>: Solving the cube optimally from this subset.</li></ol><p>By breaking the problem into these two phases, Kociemba’s Algorithm achieves solutions that typically require around 20 moves (or fewer), which is significantly shorter than beginner methods.</p><hr><h4 id="mathematical-background"><strong>Mathematical Background</strong></h4><p>The algorithm relies on<strong>group theory</strong>, particularly the concept of<strong>cosets</strong> and<strong>group reductions</strong>. In simple terms, it works by reducing the number of legal states the cube can be in while maintaining solvability.</p><p>The Rubik’s Cube has a<strong>state space</strong> of<strong>43,252,003,274,489,856,000 (43 quintillion) possible arrangements</strong>. Finding an optimal solution in this space is extremely complex, but by using the concept of<strong>group reduction</strong>, the problem is split into two more manageable parts.</p><hr><h4 id="phase-1-reduction-to-g1-group"><strong>PHASE 1: Reduction to G1 Group</strong></h4><p>In this phase, the cube is transformed into a<strong>restricted subset</strong> of states where:</p><ul><li>All edge orientations are correct (edges are in the correct flipped orientation).</li><li>All corner orientations are correct.</li><li>The positioning of the U/D (Up/Down) face edges falls into a specific allowed pattern.</li></ul><p>This phase<strong>does not solve</strong> the cube completely but simplifies it to a structured form that is easier to solve in the second phase.</p><h6 id="mathematical-properties-of-g1-group"><strong>Mathematical Properties of G1 Group</strong></h6><p>The group G1 is a subset of all possible cube states that satisfies the following conditions:</p><ol><li><strong>Edge Orientation is Solved</strong>: Each edge must be in its correct orientation.</li><li><strong>Corner Orientation is Solved</strong>: Each corner must be in its correct orientation.</li><li><strong>UD-Slice Edges Must Stay in the UD-Slice</strong>: The four edges belonging to the U (Up) and D (Down) face centers must remain within that slice.</li></ol><p>The key insight is that reducing the cube to this state significantly reduces the number of possible positions, making the final solving phase much easier.</p><h6 id="how-this-phase-works"><strong>How This Phase Works</strong></h6><ul><li>Kociemba’s algorithm uses a<strong>pruning table</strong> that precomputes the minimum number of moves required to reach the G1 state from any given configuration.</li><li>Using<strong>bidirectional search</strong>, the algorithm efficiently finds the shortest path to reach G1.</li><li>Typically, this phase takes<strong>at most 12 moves</strong>.</li></ul><hr><h4 id="phase-2-solving-the-cube-from-g1"><strong>PHASE 2: Solving the Cube from G1</strong></h4><p>Once the cube is in the<strong>G1 subset</strong>, the next step is to solve it completely while maintaining the constraints of G1.</p><h6 id="mathematical-properties-of-phase-2"><strong>Mathematical Properties of Phase 2</strong></h6><p>In this phase, we solve the cube while ensuring:</p><ol><li><strong>The E-Slice (Middle Layer Edges) is Correct</strong>: The four middle layer edges must be correctly positioned.</li><li><strong>Corner Permutation is Correct</strong>: The corners must be arranged correctly.</li><li><strong>Edge Permutation is Correct</strong>: All edges must be positioned correctly.</li></ol><p>At this point, the cube is already simplified, so a<strong>brute-force or optimized search</strong> (using a<strong>pruning table</strong>) is performed to find the shortest solution sequence.</p><ul><li>This phase usually takes around<strong>10 moves</strong> in most cases.</li><li>Since the cube is already in a reduced state,<strong>only a limited number of moves are needed</strong> to reach the solved state.</li></ul><hr><h4 id="key-techniques-used-in-kociembas-algorithm"><strong>Key Techniques Used in Kociemba’s Algorithm</strong></h4><h6 id="pruning-tables"><strong>Pruning Tables</strong></h6><ul><li>The algorithm precomputes<strong>lookup tables</strong> that store the shortest paths for solving different cube states.</li><li>These tables help the algorithm efficiently determine the best next move without unnecessary computations.</li></ul><h6 id="heuristic-search"><strong>Heuristic Search</strong></h6><ul><li>Kociemba’s Algorithm uses<em><em>A</em> search</em>* (or similar algorithms) to minimize the number of moves required to reach a solved state.</li><li>It evaluates different move sequences and picks the shortest one.</li></ul><h6 id="group-theory-based-reduction"><strong>Group Theory-Based Reduction</strong></h6><ul><li>The algorithm does not directly solve the cube but instead<strong>reduces it</strong> step by step to smaller solvable subsets.</li><li>By using<strong>cosets</strong> and<strong>subgroups</strong>, the problem is broken down into manageable parts.</li></ul><h6 id="move-pruning--bidirectional-search"><strong>Move Pruning &amp; Bidirectional Search</strong></h6><ul><li>The algorithm avoids unnecessary moves by pruning branches that lead to longer solutions.</li><li>It uses<strong>bidirectional search</strong> (searching both forward and backward) to quickly find the optimal solution.</li></ul><hr><h4 id="why-is-kociembas-algorithm-efficient"><strong>Why is Kociemba’s Algorithm Efficient?</strong></h4><p><strong>It significantly reduces the search space</strong>: Instead of searching through 43 quintillion possible states, it first reduces the cube to G1, making the search much easier.<strong>It finds near-optimal solutions</strong>: While not always the absolute shortest solution, Kociemba’s Algorithm typically finds solutions within 20 moves, close to the<strong>God’s Number</strong> (20 moves).<strong>It is practical for human and computer solvers</strong>: Many advanced cube solvers and speedcubing programs use this approach for efficient solving.</p><hr><h4 id="comparison-to-other-solving-methods"><strong>Comparison to Other Solving Methods</strong></h4><table><thead><tr><th>Algorithm</th><th>Average Move Count</th><th>Approach</th></tr></thead><tbody><tr><td>Layer-by-Layer (Beginner Method)</td><td>100+ moves</td><td>Step-by-step solving</td></tr><tr><td>CFOP (Fridrich Method)</td><td>50-60 moves</td><td>Speedcubing method</td></tr><tr><td>Kociemba’s Algorithm</td><td>~20 moves</td><td>Two-phase optimal solving</td></tr><tr><td>Thistlethwaite’s Algorithm</td><td>40-50 moves</td><td>Four-phase group theory approach</td></tr><tr><td>God’s Algorithm</td><td>20 moves (optimal)</td><td>Brute-force minimum solution</td></tr></tbody></table><p>Kociemba’s Algorithm is<strong>not always optimal</strong>, but it is extremely<strong>efficient</strong> and can be computed<strong>very quickly</strong> compared to brute-force approaches.</p><hr><h4 id="applications-of-kociembas-algorithm"><strong>Applications of Kociemba’s Algorithm</strong></h4><ul><li><strong>Speedcubing</strong>: Used in optimal cube-solving software.</li><li><strong>Computer Solvers</strong>: Implemented in AI-based solvers and robotic Rubik’s Cube solvers.</li><li><strong>Mathematical Research</strong>: Used to study<strong>group theory and combinatorial optimization</strong>.</li><li><strong>God’s Number Research</strong>: Helps find efficient solutions near the<strong>20-move optimal bound</strong>.</li></ul><hr><h4 id="controls">Controls</h4><ul><li><strong>Right Click + Drag</strong>: Rotate the entire cube in 3D space.</li><li><strong>Left Click + Drag on Layers</strong>: Rotate specific layers of the Rubik&rsquo;s Cube.</li></ul><h4 id="buttons">Buttons</h4><ul><li><strong>SCRAMBLE</strong>: Randomly scrambles the Rubik&rsquo;s Cube.</li><li><strong>SOLVE</strong>: Solves the scrambled cube using the Kociemba solver. (Note: Initial solve may take some time to compute.)</li></ul><h5 style="text-align: center;">Layout</h5><img title="" loading="lazy" decoding="async" class="img  " width="1201" height="802" src="/images/projects/rubec/layout_hu14405346715368994746.webp" alt="Unity Layout" onerror="this.onerror='null';this.src='\/images\/projects\/rubec\/layout_hu8176224447079097799.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><h4 id="installation--setup">Installation &amp; Setup</h4><p>To run the project locally, follow these steps:</p><ol><li><p>Clone the repository:</p><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Mummanajagadeesh/v-rubiks-cube.git</span></span><span style="display:flex;"><span>cd v-rubiks-cube</span></span></code></pre></div></li><li><p>Open the project in your preferred IDE or deploy it on a web hosting service.</p></li><li><p>To modify or extend the project, ensure you have:</p><ul><li>A working knowledge of 3D engines such as Unity or Blender.</li><li>Familiarity with the Kociemba algorithm and basic Rubik’s Cube concepts.</li></ul></li></ol><h4 id="how-the-solver-works">How the Solver Works</h4><p>This project uses the<strong>Kociemba two-phase algorithm</strong>, which is an optimized approach for solving the Rubik&rsquo;s Cube in under 20 moves. The first phase reduces the problem to a manageable subset of configurations, and the second phase finds an optimal solution from that subset.</p><h4 id="performance-notes">Performance Notes</h4><ul><li>The first time you run the solver, it may take longer due to the initial calculation of move tables.</li><li>Subsequent solves will be faster as the tables are cached.</li></ul><h4 id="future-goals">Future Goals</h4><p>We have exciting plans for the future of this project:</p><ul><li><strong>Hardware Integration</strong>: The next step is to bring this solution into the physical world. Using computer vision (CV) techniques, we aim to read the Rubik&rsquo;s Cube faces via a camera and translate the detected state into a solvable format.</li><li><strong>3D Design</strong>: We are currently working on the 3D design of the hardware, which is under construction. This will involve a mechanism where gripper-like structures hold and manipulate the cube for solving.</li><li><strong>Optimization</strong>: Another goal is to reduce the time required for solving, making the process as fast and efficient as possible.</li><li><strong>Physical Cube Solving</strong>: Ultimately, the project will be able to solve a real Rubik&rsquo;s Cube using robotic structures that simulate the virtual environment.</li></ul><p>We are open to contributions from anyone interested in participating in this exciting journey. If you&rsquo;d like to help us push the project forward, feel free to reach out!</p><p>Enjoy solving the cube! 🎲</p>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/shopping-cart-bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/shopping-cart-bot/</guid><description>&lt;![CDATA[<h2 id="shopping-cart-bothttpsgithubcommummanajagadeeshshopping-cart-bot-rig"><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Bot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Shopping Cart Bot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The Shopping Cart Bot is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</td></tr><tr><td><strong>Start</strong></td><td>30 Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Bot🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, ROS2, GeminiAPI, PyQt, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><p>The<strong>Shopping Cart Bot</strong> is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="shopping-cart-bothttpsgithubcommummanajagadeeshshopping-cart-bot-rig"><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Bot</a></h2><table><thead><tr><th><strong>Name</strong></th><th>Shopping Cart Bot</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>The Shopping Cart Bot is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</td></tr><tr><td><strong>Start</strong></td><td>30 Sep 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/shopping-cart-bot-rig" target="_blank">Shopping Cart Bot🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>Computer Vision, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Webots, ROS2, GeminiAPI, PyQt, Python, OpenCV</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><p>The<strong>Shopping Cart Bot</strong> is a robotics project designed to automate the shopping experience by utilizing computer vision and autonomous navigation. The bot follows a person, detects and classifies items placed in the cart, and categorizes them based on predefined labels such as food, electronics, and clothing. Additionally, it integrates barcode recognition, label detection, and a payment system to streamline the checkout process.</p><h4 id="problem-statement">Problem Statement</h4><p>The project aims to address the following challenges:</p><ul><li><strong>Object Detection and Classification:</strong> Implement computer vision techniques to identify and categorize products.</li><li><strong>Person Following:</strong> Develop a system that enables the bot to follow a shopper autonomously.</li><li><strong>Barcode and Label Recognition:</strong> Use image processing and OCR to extract information from labels and barcodes.</li><li><strong>Discount Application and Payment System:</strong> Calculate the final bill with category-wise discounts and generate a QR code for payment.</li></ul><h4 id="motivation">Motivation</h4><p>This project was developed as part of the<strong>Round 3 induction project for my college robotics club</strong>. The objective was to explore the integration of robotics and computer vision in real-world applications, enhancing the retail shopping experience.</p><h4 id="hardware-design">Hardware Design</h4><ul><li><strong>Frame:</strong> Designed using aluminum extrusion in<strong>Fusion 360</strong>.</li><li><strong>Wheels:</strong> Mecanum wheels were chosen due to the<strong>restricted motion in malls</strong> (tight spaces, high foot traffic, and the need for omnidirectional movement).</li></ul><h4 id="person-following-implementation">Person Following Implementation</h4><h5 id="simulation-environment"><strong>Simulation Environment</strong></h5><ul><li>Implemented in<strong>Webots</strong> simulation.</li><li>The world was divided into separate tracks for the person to walk and collect items.</li><li>The cart was equipped with a<strong>camera and GPS</strong>, mounted on a mecanum-wheeled base.</li><li>The person was equipped with a<strong>GPS sensor</strong> embedded in their body slot, transmitting signals via a dedicated channel.</li><li>The bot’s camera continuously monitored the person, following them wherever they moved.</li><li>The<strong>GPS signal</strong> served as an additional reference for tracking the person’s location.</li></ul><style>
.youtube-container {
width: 100%;
}
.youtube-container .youtube-embed {
position: relative;
width: 100%;
padding-bottom: 56.25%;
height: 0;
}
.youtube-container .youtube-embed iframe {
position: absolute;
width: 100%;
height: 100%;
top: 0;
left: 0;
}
table {
width: 100%;
table-layout: fixed;
}
td {
padding: 10px;
vertical-align: top;
}</style><div class="youtube-container"><div class="youtube-embed"><iframe src="https://www.youtube.com/embed/7x07H0RtYMg" frameborder="0" allowfullscreen=/></div></div><h5 id="unimplemented-features-due-to-time-constraints"><strong>Unimplemented Features Due to Time Constraints</strong></h5><ul><li>Handling the scenario where the person moves out of the camera frame, using GPS as a fallback.</li><li>Detecting when the bot is stuck without any input stimulus.</li></ul><h4 id="object-detection-and-classification">Object Detection and Classification</h4><ul><li><p><strong>YOLOv5 Model:</strong> Trained using a<strong>Roboflow dataset</strong> to detect and categorize shopping items.</p></li><li><p><strong>Label Detection Pipeline:</strong></p><ul><li>Convert the image from<strong>RGB to grayscale</strong>.</li><li>Apply<strong>Canny edge detection</strong>.</li><li>Identify the<strong>largest contour</strong> and create a<strong>bounding box</strong> around the label.</li><li>Extract the<strong>bounded region</strong> from the original image.</li><li>Perform<strong>OCR (Optical Character Recognition)</strong> using an API to extract text.</li><li>Utilize<strong>Gemini API</strong> for text correction and cost retrieval.</li></ul><video width="1000" autoplay= loop= muted= controls= class="embed-responsive "><source src="/images/projects/scbot/shpbotrecog.mp4" type="video/mp4"/>
Your browser does not support the video tag.</video></li></ul><blockquote><p>Implemented a ROS2 node to enable communication between mecanum base motors and code via a UDP server.</p></blockquote><h4 id="payment-system">Payment System</h4><ul><li><p>The total cost is calculated based on item quantity, category-wise discounts, and final pricing.</p></li><li><p>A<strong>UPI URL</strong> is used to generate a<strong>QR code</strong>.</p></li><li><p>Scanning the QR code prompts the user to pay the exact calculated amount.</p><video width="500" autoplay= loop= muted= controls= class="embed-responsive "><source src="/images/projects/scbot/upiqr.mp4" type="video/mp4"/>
Your browser does not support the video tag.</video></li></ul><p>The<strong>Shopping Cart Bot</strong> successfully integrates multiple robotics and computer vision techniques to automate the shopping experience. Despite some unimplemented features due to time constraints, the project demonstrates a proof of concept for autonomous retail assistance.</p><hr><h5 id="future-improvements">Future Improvements</h5><ul><li>Implement fallback mechanisms for lost person tracking.</li><li>Enhance navigation strategies for obstacle avoidance.</li><li>Develop a fully integrated hardware prototype for real-world testing.</li></ul>
]]></content:encoded></item><item><title/><link>https://mummanajagadeesh.github.io/projects/tlcv/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/tlcv/</guid><description>&lt;![CDATA[<h2 id="traffic-light-controller-httpsgithubcommummanajagadeeshtrafficlightcontroller-verilog"><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TRAFFIC LIGHT CONTROLLER 🚦</a></h2><table><thead><tr><th><strong>Name</strong></th><th>TLC using Verilog</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of Traffic Light Controller</td></tr><tr><td><strong>Start</strong></td><td>05 Apr 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TLCV🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><blockquote><p>The original version, which utilizes FSM, is currently on hold. Here is the base version, which does not use FSM and instead relies directly on Boolean logic expressions. Below is the explanation for the base version.</p>]]></description><content:encoded>&lt;![CDATA[<h2 id="traffic-light-controller-httpsgithubcommummanajagadeeshtrafficlightcontroller-verilog"><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TRAFFIC LIGHT CONTROLLER 🚦</a></h2><table><thead><tr><th><strong>Name</strong></th><th>TLC using Verilog</th></tr></thead><tbody><tr><td><strong>Description</strong></td><td>Verilog Implementation of Traffic Light Controller</td></tr><tr><td><strong>Start</strong></td><td>05 Apr 2024</td></tr><tr><td><strong>Repository</strong></td><td><a href="https://github.com/Mummanajagadeesh/TrafficLightController-verilog" target="_blank">TLCV🔗</a></td></tr><tr><td><strong>Type</strong></td><td>Individual</td></tr><tr><td><strong>Level</strong></td><td>Beginner</td></tr><tr><td><strong>Skills</strong></td><td>HDL, Programming</td></tr><tr><td><strong>Tools Used</strong></td><td>Verilog, Icarus, Xilinx</td></tr><tr><td><strong>Current Status</strong></td><td>On Hold</td></tr></tbody></table><hr><blockquote><p>The original version, which utilizes FSM, is currently on hold. Here is the base version, which does not use FSM and instead relies directly on Boolean logic expressions. Below is the explanation for the base version.</p></blockquote><h2 id="base-version">BASE VERSION</h2><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="737" src="/images/projects/tlc/lane-picture_hu4146720103007524920.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/lane-picture_hu7639973906903205819.png'"/><script>
window.addEventListener("load", (e) => {
const lightbox = GLightbox();
});</script><p>Consider the problem of controlling a traffic light at the intersection of two equally busy streets, A Street and B Street. Our traffic light controller takes two inputs – CarA (which is high when there is a car just before the intersection on A Street – in either direction), and CarB (which is high when there is a car just before the intersection on B street). The controller needs to generate six outputs – RedA, YellowA, GreenA, RedB, YellowB, and GreenB – which drive the respective traffic lights for A Street and B Street. In the figure above, CarA will be high, since there is a car (the rectangle) on A Street, and CarB will be low, since there is no car on B Street. Also in the Figure RedA is high since A Street has a red light, and GreenB is high since B Street has a green light. All other outputs are low. We can think of the traffic light controller as a black box that takes two inputs (and a clock) and generates six outputs as shown below.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="689" src="/images/projects/tlc/tlcblock_hu9325997977067735153.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/tlcblock_hu904393213427707066.png'"/><ol><li>When the light is green on A Street and a car is waiting on B Street, give A Street a yellow light for one clock cycle and then give A Street a red light and B Street a green light for at least two cycles.</li><li>When the light is green on A Street and there is no car on B Street, leave the light green on A Street.</li><li>When the is green on B Street (and we’ve finished the two cycles from step 1) and a car is waiting on A Street, give B Street a yellow light for one clock cycle and then give B Street a red light and A Street a green light for at least two cycles.</li><li>When the light is green on B Street and there is no car on A Street, leave the light green on B Street.</li><li>When you press the reset switch, after no more than six cycles, the light should be initially green on A Street and red on B Street and the controller should be ready for operation.</li></ol><h4 id="working">WORKING:</h4><p>We can translate these five rules into the following state diagram. For clarity, we omit the transitions that take all states to state AG2 (A Green 2nd cycle) when reset is true.</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="817" src="/images/projects/tlc/state-diagram_hu7133944902976557533.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/state-diagram_hu3948849623443658779.png'"/><p>Each circle in the state diagram represents a state. The name of the state is in the circle and the state of the six output lines (in the order listed above) is shown below that state. The transitions between the states are labeled with the signals that make these transitions occur. Most of the edges have no label which indicates that the transition always occurs (unless reset is asserted).
When our finite-state machine (FSM) is in state AG2, A Street has a green light and B Street has a red light. The transition from AG2 back to itself indicates that as long as there is no car on B Street we keep the A Street light green. The transition to AY (for A Yellow) indicates that if there is a car on B Street, we make the A Street light yellow on the next cycle. AY always transitions to BG1 (for B Green 1st cycle) where the A Street light becomes red and the B Street light becomes green. BG1 always transitions to BG2 where the FSM waits for a car on A Street before sequencing through BY and AG1 back to AG2.</p><p>From this state diagram we can write the following state table:</p><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="563" src="/images/projects/tlc/state-table_hu3048702135184146678.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/state-table_hu15547272149258596845.png'"/><table><tr><th>State</th><th colspan="3">Inputs</th><th>nextState</th><th colspan="2">Outputs</th></tr><tr><th/><th>reset</th><th>CarA</th><th>CarB</th><th/><th>A lights</th><th>B lights</th></tr><tr><td>*</td><td>1</td><td>*</td><td>*</td><td>AG2</td><td>Green</td><td>Red</td></tr><tr><td>AG2</td><td>0</td><td>0</td><td>*</td><td>AG2</td><td>Green</td><td>Red</td></tr><tr><td>AG2</td><td>0</td><td>*</td><td>1</td><td>AY</td><td>Green</td><td>Red</td></tr><tr><td>AY</td><td>0</td><td>*</td><td>*</td><td>BG1</td><td>Yellow</td><td>Red</td></tr><tr><td>BG1</td><td>0</td><td>*</td><td>*</td><td>BG2</td><td>Red</td><td>Green</td></tr><tr><td>BG2</td><td>0</td><td>*</td><td>1</td><td>BY</td><td>Red</td><td>Green</td></tr><tr><td>BG2</td><td>0</td><td>0</td><td>1</td><td>BY</td><td>Red</td><td>Green</td></tr><tr><td>BY</td><td>0</td><td>*</td><td>*</td><td>AG1</td><td>Red</td><td>Yellow</td></tr><tr><td>AG1</td><td>0</td><td>*</td><td>*</td><td>AG2</td><td>Green</td><td>Red</td></tr></table><h4 id="circuit-diagram-implemented">CIRCUIT DIAGRAM IMPLEMENTED:</h4><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="372" src="/images/projects/tlc/circuit-diagram_hu4954760165853522568.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/circuit-diagram_hu2516666750173183316.jpg'"/><h5 id="inputs-for-d-flip-flops">INPUTS FOR D FLIP FLOPS:</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span>D1<span style="color:#f92672">=</span> Q3<span style="color:#f92672">+</span> (<span style="color:#f92672">~</span>CB)<span style="color:#960050;background-color:#1e0010">•</span>(Q1)<span style="color:#f92672">+</span> reset</span></span><span style="display:flex;"><span>D2<span style="color:#f92672">=</span> Q1<span style="color:#960050;background-color:#1e0010">•</span>CB</span></span><span style="display:flex;"><span>D3<span style="color:#f92672">=</span> Q5</span></span><span style="display:flex;"><span>D4<span style="color:#f92672">=</span> (Q6<span style="color:#f92672">+</span> (Q4<span style="color:#960050;background-color:#1e0010">•</span>(<span style="color:#f92672">~</span>CA))<span style="color:#f92672">+</span> reset</span></span><span style="display:flex;"><span>D5<span style="color:#f92672">=</span> Q4<span style="color:#960050;background-color:#1e0010">•</span>CB</span></span><span style="display:flex;"><span>D6<span style="color:#f92672">=</span> Q2</span></span></code></pre></div><h5 id="overall-ouputs">OVERALL OUPUTS:</h5><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span>RedA<span style="color:#f92672">=</span> Q5<span style="color:#f92672">+</span> reset<span style="color:#f92672">+</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">•</span>(Q4<span style="color:#f92672">+</span> Q6)</span></span><span style="display:flex;"><span>YellowA<span style="color:#f92672">=</span> Q2<span style="color:#960050;background-color:#1e0010">•</span> (<span style="color:#f92672">~</span>reset)</span></span><span style="display:flex;"><span>GreenA<span style="color:#f92672">=</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">•</span>(Q1<span style="color:#f92672">+</span> Q3)</span></span><span style="display:flex;"><span/></span><span style="display:flex;"><span>RedB<span style="color:#f92672">=</span> Q2<span style="color:#f92672">+</span> reset<span style="color:#f92672">+</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">•</span>(Q1<span style="color:#f92672">+</span> Q3)</span></span><span style="display:flex;"><span>YellowB<span style="color:#f92672">=</span> Q5<span style="color:#960050;background-color:#1e0010">•</span>(<span style="color:#f92672">~</span>reset)</span></span><span style="display:flex;"><span>GreenB<span style="color:#f92672">=</span> (<span style="color:#f92672">~</span>reset)<span style="color:#960050;background-color:#1e0010">•</span>(Q5<span style="color:#f92672">+</span> Q6)</span></span></code></pre></div><h4 id="design-code">DESIGN CODE:</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">module</span> TLC(clk, reset, carA, carB, lightsA, lightsB) ;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">input</span> clk ;<span style="color:#75715e">// clock</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span> reset ;<span style="color:#75715e">// reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span> carA ;<span style="color:#75715e">// a car is waiting on A Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">input</span> carB ;<span style="color:#75715e">// a car is waiting on B Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span>[<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsA ;<span style="color:#75715e">// Red, Yellow, Green lights for A Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">output</span>[<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsB ;<span style="color:#75715e">// Red, Yellow, Green lights for B Street</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> ag2, ay, ag1, bg2, by, bg1 ;<span style="color:#75715e">// state bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> nag2, nay, nag1, nbg2, nby, nbg1 ;<span style="color:#75715e">// next state bits</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span>[<span style="color:#ae81ff">5</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state ;<span style="color:#75715e">// for observation only</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> state<span style="color:#f92672">=</span> {ag2, ay, ag1, bg2, by, bg1} ;</span></span><span style="display:flex;"><span><span style="color:#75715e">// state equations</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span></span></span><span style="display:flex;"><span>nag2<span style="color:#f92672">=</span> ag1<span style="color:#f92672">|</span>(ag2<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>carB)<span style="color:#f92672">|</span>reset ,<span style="color:#75715e">// D1 = Q3 + (~CB)•(Q1) + reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nay<span style="color:#f92672">=</span> ag2<span style="color:#f92672">&amp;</span> carB ,<span style="color:#75715e">// D2 = Q1•CB</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nbg1<span style="color:#f92672">=</span> ay ,<span style="color:#75715e">// D3 = Q5</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nbg2<span style="color:#f92672">=</span> (bg1<span style="color:#f92672">|</span>(bg2<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>carA))<span style="color:#f92672">&amp;~</span>reset,<span style="color:#75715e">// D4 = (Q6 + (Q4•(~CA)) + reset</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nby<span style="color:#f92672">=</span> bg2<span style="color:#f92672">&amp;</span> carA ,<span style="color:#75715e">// D5 = Q4•CA</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>nag1<span style="color:#f92672">=</span> by ;<span style="color:#75715e">// D6 = Q2</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// flip flops</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)</span></span><span style="display:flex;"><span>{ag2, ay, ag1, bg2, by, bg1}<span style="color:#f92672">=</span> {nag2, nay, nag1, nbg2, nby, nbg1} ;</span></span><span style="display:flex;"><span><span style="color:#75715e">// output equations</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span></span></span><span style="display:flex;"><span>lightsA[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">=</span> by<span style="color:#f92672">|</span> lightsB[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">|</span> reset ,<span style="color:#75715e">// red</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsA[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">=</span> ay<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset ,<span style="color:#75715e">// yellow</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsA[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">=</span> (ag1<span style="color:#f92672">|</span> ag2)<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset,<span style="color:#75715e">// green</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsB[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">=</span> ay<span style="color:#f92672">|</span> lightsA[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">|</span> reset,<span style="color:#75715e">// red</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsB[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">=</span> by<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset,<span style="color:#75715e">// yellow</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>lightsB[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">=</span> (bg1<span style="color:#f92672">|</span> bg2)<span style="color:#f92672">&amp;</span><span style="color:#f92672">~</span>reset ;<span style="color:#75715e">// green</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h4 id="testbench-code">TESTBENCH CODE:</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span><span style="color:#66d9ef">`timescale</span><span style="color:#ae81ff">1</span>ns<span style="color:#f92672">/</span><span style="color:#ae81ff">1</span>ns</span></span><span style="display:flex;"><span><span style="color:#66d9ef">module</span> TLC_tb;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Parameters</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">parameter</span> CLK_PERIOD<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>;<span style="color:#75715e">// Clock period in ns</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Inputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">reg</span> clk;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> reset;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> carA;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">reg</span> carB;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Outputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsA;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">2</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] lightsB;</span></span><span style="display:flex;"><span><span style="color:#66d9ef">wire</span> [<span style="color:#ae81ff">5</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0</span>] state;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Instantiate the TLC module</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/>TLC uut (</span></span><span style="display:flex;"><span> .clk(clk),</span></span><span style="display:flex;"><span> .reset(reset),</span></span><span style="display:flex;"><span> .carA(carA),</span></span><span style="display:flex;"><span> .carB(carB),</span></span><span style="display:flex;"><span> .lightsA(lightsA),</span></span><span style="display:flex;"><span> .lightsB(lightsB)</span></span><span style="display:flex;"><span>);</span></span><span style="display:flex;"><span><span style="color:#75715e">// Connect the state output of TLC to state wire in testbench</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">assign</span> state<span style="color:#f92672">=</span> uut.state;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Clock generation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> #((CLK_PERIOD)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>) clk<span style="color:#f92672">=</span><span style="color:#f92672">~</span>clk;</span></span><span style="display:flex;"><span><span style="color:#75715e">// Initial values</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">initial</span><span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> clk<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>;</span></span><span style="display:flex;"><span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;</span></span><span style="display:flex;"><span> #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// Wait for a few cycles</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#75715e">// Test cases</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 1</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 2</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 3</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 4</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 5</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 6</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 7</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 8</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 9</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 10</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 11</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; #<span style="color:#ae81ff">10</span>;<span style="color:#75715e">// 12</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/> $finish;<span style="color:#75715e">// End simulation</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Display outputs</span></span></span><span style="display:flex;"><span><span style="color:#75715e"/><span style="color:#66d9ef">always</span> @(<span style="color:#66d9ef">posedge</span> clk)<span style="color:#66d9ef">begin</span></span></span><span style="display:flex;"><span> $display(<span style="color:#e6db74">"reset = %b carA = %b carB = %b : lightsA = %b lightsB = %b state =%b%b%b%b%b%b"</span>,</span></span><span style="display:flex;"><span> reset, carA, carB, lightsA, lightsB, state[<span style="color:#ae81ff">5</span>], state[<span style="color:#ae81ff">4</span>], state[<span style="color:#ae81ff">3</span>], state[<span style="color:#ae81ff">2</span>], state[<span style="color:#ae81ff">1</span>], state[<span style="color:#ae81ff">0</span>]);</span></span><span style="display:flex;"><span><span style="color:#66d9ef">end</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">endmodule</span></span></span></code></pre></div><h5 id="code-explanation">CODE EXPLANATION:</h5><h6 id="design-code-1">DESIGN CODE:</h6><p>Functionality:
The Verilog module TLC defines a traffic light controller with inputs for clock (clk), reset (reset), and car presence on streets A and B (carA, carB). It generates outputs (lightsA, lightsB) to control the traffic lights and uses registers (ag2, ay, ag1, bg2, by, bg1) and wires (nag2, nay, nag1, nbg2, nby, nbg1) to manage internal state transitions and next state calculations (state).</p><p>Operation:
The module updates its internal state (ag2, ay, ag1, bg2, by, bg1) based on clock edges and input conditions, calculates next state bits (nag2, nay, nag1, nbg2, nby, nbg1) using state equations, and determines the output state of traffic lights (lightsA, lightsB) based on the current state and reset conditions using output equations.</p><h6 id="testbench-code-1">TESTBENCH CODE:</h6><p>Purpose:
This Verilog testbench (TLC_tb) is designed to simulate the behavior of the TLC module by providing input stimuli (clk, reset, carA, carB) and observing the corresponding outputs (lightsA, lightsB) and internal state (state). It helps validate the functionality and correctness of the TLC module under various test cases.</p><p>Operation:
The testbench initializes the inputs, generates a clock signal (clk), applies test cases with different input combinations, and displays the resulting outputs and state changes using $display. The testbench also connects the state wire to observe the internal state of the TLC module during simulation.</p><h4 id="ouput">OUPUT:</h4><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-verilog" data-lang="verilog"><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">100000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">100000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">010</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000010</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">001000</span></span></span><span style="display:flex;"><span>reset<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> carA<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> carB<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span> lightsA<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span> lightsB<span style="color:#f92672">=</span><span style="color:#ae81ff">001</span> state<span style="color:#f92672">=</span><span style="color:#ae81ff">000001</span></span></span></code></pre></div><img title="" loading="lazy" decoding="async" class="img  " width="1000" height="112" src="/images/projects/tlc/waveform_hu14643348579372039064.webp" alt="Original Image 1" onerror="this.onerror='null';this.src='\/images\/projects\/tlc\/waveform_hu2771881731006117160.png'"/><p><strong>Output Columns Explanation</strong>:</p><ol><li><code>reset</code>: Indicates whether the controller is in reset mode (<code>1</code> = reset active,<code>0</code> = normal operation).</li><li><code>carA</code>: Indicates whether there is a car waiting on Street A (<code>1</code> = car present,<code>0</code> = no car).</li><li><code>carB</code>: Indicates whether there is a car waiting on Street B (<code>1</code> = car present,<code>0</code> = no car).</li><li><code>lightsA</code> and<code>lightsB</code>: 3-bit outputs indicating the light status for streets A and B, respectively:<ul><li><code>100</code>: Red</li><li><code>010</code>: Yellow</li><li><code>001</code>: Green</li></ul></li><li><code>state</code>: 6-bit internal state of the controller, where each bit corresponds to one of the states (<code>ag2</code>,<code>ay</code>,<code>ag1</code>,<code>bg2</code>,<code>by</code>,<code>bg1</code>).</li></ol><p><strong>Key Observations from the Output</strong>:</p><ol><li><p><strong>Reset Behavior</strong>:</p><ul><li>When<code>reset = 1</code>, the controller initializes to the default state (<code>AG2</code>), where Street A has a green light (<code>lightsA = 100</code>) and Street B has a red light (<code>lightsB = 100</code>).</li></ul></li><li><p><strong>State Transitions</strong>:</p><ul><li><strong>Initial State</strong> (<code>AG2</code>): Street A has a green light, and Street B has a red light. The controller remains in this state as long as<code>carB = 0</code>.</li><li><strong>Transition to AY</strong>: When<code>carB = 1</code>, the controller transitions to<code>AY</code> (A Yellow), giving Street A a yellow light while preparing to switch to B Street.</li><li><strong>Transition to BG1/BG2</strong>: After<code>AY</code>, the controller transitions to<code>BG1</code> and<code>BG2</code>, giving Street B the green light and Street A the red light. The controller waits for at least two cycles on Street B (<code>BG1</code> and<code>BG2</code>) before checking for<code>carA</code>.</li><li><strong>Transition to BY</strong>: When<code>carA = 1</code>, the controller transitions to<code>BY</code> (B Yellow), switching from Street B back to Street A.</li></ul></li><li><p><strong>Input-Driven State Changes</strong>:</p><ul><li>The controller responds dynamically to<code>carA</code> and<code>carB</code>, switching states and light colors based on the presence of cars. For example:<ul><li><code>carA = 0, carB = 1</code>: Street B gets priority (transition from<code>AG2</code> →<code>AY</code> →<code>BG1</code>).</li><li><code>carA = 1, carB = 0</code>: Street A gets priority (transition from<code>BG2</code> →<code>BY</code> →<code>AG1</code>).</li></ul></li></ul></li><li><p><strong>Output Consistency</strong>:</p><ul><li>The outputs (<code>lightsA</code> and<code>lightsB</code>) match the expected light status for each state in the state table:<ul><li><code>lightsA = 100</code> (Red for A) corresponds to<code>BG1</code>/<code>BG2</code> states.</li><li><code>lightsB = 001</code> (Green for B) corresponds to<code>BG1</code>/<code>BG2</code> states.</li><li><code>lightsA = 001</code> (Green for A) corresponds to<code>AG1</code>/<code>AG2</code> states.</li></ul></li></ul></li></ol><p><strong>Waveform Analysis</strong>:
The waveform visualizes the same transitions observed in the output table. Key points:</p><ul><li>The state bits change in accordance with the state transitions defined by the FSM.</li><li>The<code>lightsA</code> and<code>lightsB</code> signals follow the expected traffic light rules.</li><li><code>Reset</code> enforces the initial state (<code>AG2</code>), confirming the correctness of initialization.</li></ul>
]]></content:encoded></item><item><title>:~$ whoami</title><link>https://mummanajagadeesh.github.io/about_1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about_1/</guid><description>&lt;![CDATA[<p>I’m from Visakhapatnam, Andhra Pradesh, and currently a<strong>sophomore at NIT Calicut</strong>, studying<strong>Electronics and Communication Engineering</strong>.</p>]]></description><content:encoded>&lt;![CDATA[<p>I’m from Visakhapatnam, Andhra Pradesh, and currently a<strong>sophomore at NIT Calicut</strong>, studying<strong>Electronics and Communication Engineering</strong>.</p><p>As an electronics student, I have a strong interest in digital and mixed-signal VLSI design, as well as hardware optimization. I also enjoy working with microcontrollers and coding for various electronics projects in my personal time. My broader interests include robotics, AI, and the hardware that powers these systems.</p><p>I am actively seeking internship opportunities in electronics design roles. To enhance my skills, I am continuously revising course material, gaining hands-on experience with design tools and technologies, and familiarizing myself with full design flows and simulation processes.</p><p>Currently, I am focused on electronics design and systems development for real-world applications at my college&rsquo;s Mechatronics Lab.</p><h5 id="my-blog">My Blog</h5><p><a href="https://mummanajagadeesh.github.io/blog/hello-world/" target="_blank">Do checkout the introduction post :)</a></p><p>This blog was initiated as a platform to systematically document my technical projects. It functions both as a personal archive and as a means to share insights with others who may be exploring related areas.</p><p>Within this space, I chronicle my progress, challenges encountered, and the underlying technical aspects of my work. Whether it involves deconstructing complex problems, presenting completed projects, or reflecting on the development process, the blog serves as a tool to organize my thoughts and contribute meaningfully to collective learning.</p><p>Through careful documentation, I aim to reinforce my own understanding while offering resources that may prove helpful to others pursuing similar interests.</p><p>// The photo is to be updated on the left-hand side, which is currently empty //</p>
]]></content:encoded></item><item><title>About ME</title><link>https://mummanajagadeesh.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/</guid><description>&lt;![CDATA[<p>I’m from Visakhapatnam, Andhra Pradesh, and currently a<strong>sophomore at NIT Calicut</strong>, studying<strong>Electronics and Communication Engineering</strong>.</p>]]></description><content:encoded>&lt;![CDATA[<p>I’m from Visakhapatnam, Andhra Pradesh, and currently a<strong>sophomore at NIT Calicut</strong>, studying<strong>Electronics and Communication Engineering</strong>.</p><p>As an electronics student, I have a strong interest in digital and mixed-signal VLSI design, as well as hardware architecture and optimization. I also enjoy working with microcontrollers and coding for various electronics projects in my personal time. My broader interests include robotics, AI, and the hardware that powers these systems.</p><p>I am actively seeking internship opportunities in electronics design roles. To enhance my skills, I am continuously revising course material, gaining hands-on experience with design tools and technologies, and familiarizing myself with full design flows and simulation processes.</p><p>Currently, I am focused on electronics design and systems development for real-world applications at my college&rsquo;s Mechatronics Lab.</p><h5 id="my-blog">My Blog</h5><p><a href="https://mummanajagadeesh.github.io/blog/hello-world/" target="_blank">Do checkout the introduction post :)</a></p><p>This blog was initiated as a platform to systematically document my technical projects. It functions both as a personal archive and as a means to share insights with others who may be exploring related areas.</p><p>Within this space, I chronicle my progress, challenges encountered, and the underlying technical aspects of my work. Whether it involves deconstructing complex problems, presenting completed projects, or reflecting on the development process, the blog serves as a tool to organize my thoughts and contribute meaningfully to collective learning.</p><p>Through careful documentation, I aim to reinforce my own understanding while offering resources that may prove helpful to others pursuing similar interests.</p><p>// The photo is to be updated on the left-hand side, which is currently empty //</p>
]]></content:encoded></item><item><title>Contact</title><link>https://mummanajagadeesh.github.io/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/contact/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item><item><title>Courses</title><link>https://mummanajagadeesh.github.io/about/courses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/courses/</guid><description>&lt;![CDATA[<h6 id="edx"><strong>EDX</strong></h6><ul><li><strong>CS50P 2022</strong> Harvard | Jan'24</li><li><strong>CS50X 2024</strong> Harvard | Sep'24</li></ul><h6 id="coursera"><strong>Coursera</strong></h6><ul><li><strong>Build a Modern Computer from First Principles: From Nand to Tetris (Project-Centered Course)</strong> Hebrew University</li><li><strong>Robotics Specialisation</strong> University of Pennsylvania</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="edx"><strong>EDX</strong></h6><ul><li><strong>CS50P 2022</strong> Harvard | Jan'24</li><li><strong>CS50X 2024</strong> Harvard | Sep'24</li></ul><h6 id="coursera"><strong>Coursera</strong></h6><ul><li><strong>Build a Modern Computer from First Principles: From Nand to Tetris (Project-Centered Course)</strong> Hebrew University</li><li><strong>Robotics Specialisation</strong> University of Pennsylvania</li></ul>
]]></content:encoded></item><item><title>GPBOT Sub Projects</title><link>https://mummanajagadeesh.github.io/projects/gpbot/subprojects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/gpbot/subprojects/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item><item><title>ImProVe Sub Projects</title><link>https://mummanajagadeesh.github.io/projects/improve/subprojects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/improve/subprojects/</guid><description>&lt;![CDATA[<h5 id="verilog-hdl-toolkit-for-image-processing-and-pattern-recognition">Verilog HDL Toolkit for Image Processing and Pattern Recognition</h5><p><strong>Duration:</strong> Individual, Ongoing<br><strong>Tools:</strong> Verilog (Icarus Verilog, Xilinx Vivado) | Python (OpenCV, NumPy, Tkinter) | Scripting (TCL. Perl)</p>]]></description><content:encoded>&lt;![CDATA[<h5 id="verilog-hdl-toolkit-for-image-processing-and-pattern-recognition">Verilog HDL Toolkit for Image Processing and Pattern Recognition</h5><p><strong>Duration:</strong> Individual, Ongoing<br><strong>Tools:</strong> Verilog (Icarus Verilog, Xilinx Vivado) | Python (OpenCV, NumPy, Tkinter) | Scripting (TCL. Perl)</p><ul><li><strong>Designed image processing algorithms (e.g., edge detection, geometric &amp; color transforms, noise reduction) in Verilog, utilizing hardware optimized math techniques to maximize computational efficiency; fine-tuned for low-latency preprocessing in embedded vision SoCs</strong></li><li><strong>Implemented 3-layer MLP (784-256-128-62) for Extended-MNIST Character Recognition (62 classes, ∼124k samples) using FSM-controlled neural network in Verilog; achieved >90% training accuracy with &lt;3.5s inference latency (in simulation); developed full end-to-end preprocessing and inference workflow</strong></li><li><strong>Automated model inference and performance metric evaluation via Tcl/Perl scripts (py &amp; iverilog commands execution); real-time Tkinter GUI for test user input</strong></li><li><strong>Working on real life applications including label detection, document scanning, stereo depth map generation, and neural network inference for MNIST/EMNIST datasets</strong></li></ul><p><br><br><br/><hr><ul><li><p>I highly recommend checking out the main project, as this is just a subset. The main project focuses on image processing algorithms, and working on<a href="../">ImProVe (IMage PROcessing using VErilog)</a> has made the learning curve for this project much easier.</p></li><li><p><a href="../never">NeVer (Neural Network in Verilog)</a> is one of my favorite subprojects under ImProVe. In this subproject, my goal is to implement a fully functional neural network purely in Verilog and optimize it for efficient hardware acceleration.</p></li></ul><blockquote><p>Please note that the names of these projects are not meant to be taken too seriously. The names like ImProVe or NeVer may not fully reflect their functions – ImProVe doesn’t actually improve images, but processes them, and NeVer isn&rsquo;t about something &ldquo;never-implemented&rdquo; – many have done it before. The names just make it easier for me to organize folders and code</p></blockquote><p><br><br><br/><hr><h5 id="tabular-summary-of-all-technical-details--nn-inference-workflow-">Tabular Summary of all technical details ( NN Inference Workflow )</h5><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Value / Detail</strong></th><th><strong>Technical Highlights</strong></th></tr></thead><tbody><tr><td><strong>Accuracy</strong></td><td>>90% training acc (>70% dev acc)</td><td>High classification precision on both MNIST (10 classes) and EMNIST (62 classes).</td></tr><tr><td><strong>Verilog Simulation Accuracy</strong></td><td>>75% (tested on 1000 random samples)</td><td>Accuracy observed when predicting directly using Verilog simulation with fixed-point arithmetic.</td></tr><tr><td><strong>Inference Latency</strong></td><td>&lt;3.5 sec per prediction (tested on 1000 random samples)</td><td>Achieved via a tightly controlled FSM-driven sequential evaluation in simulation.</td></tr><tr><td><strong>Pipelining</strong></td><td>Coarse-grained</td><td>Finite State Machine (FSM) orchestrates layer-by-layer processing without fine-grained, parallel overlap.</td></tr><tr><td><strong>Data Type</strong></td><td>IEEE 754<code>real</code></td><td>Simulation relies on IEEE 754 floating-point (non-synthesizable) for high-precision computation during development.</td></tr><tr><td><strong>Python Libraries</strong></td><td>NumPy exclusively</td><td>Utilizes NumPy for all training routines and parameter extraction, without relying on higher-level ML frameworks.</td></tr><tr><td><strong>Dataset</strong></td><td>EMNIST ByClass ≈124k (≈2K per class, 62 classes); MNIST – TSD (Google Colab)</td><td>Separate datasets: EMNIST ByClass, with 62 classes (digits and both uppercase and lowercase letters), and MNIST (handwritten digits 0-9), trained independently for alphanumeric character recognition tasks.</td></tr><tr><td><strong>Training Optimizers</strong></td><td>Adam (1500 iterations) + SGD with Momentum (500 iterations)</td><td>Hybrid optimization: Adam for rapid convergence initially, then SGD with Momentum for fine-tuning and refinement.</td></tr><tr><td><strong>Neural Architecture (MNIST)</strong></td><td>784 (input) – 128 (hidden) – 10 (output)</td><td>A compact feed-forward architecture optimized for digit recognition.</td></tr><tr><td><strong>Neural Architecture (EMNIST)</strong></td><td>784 (input) – 256 (hidden) – 128 (hidden) – 62 (output)</td><td>Expanded design to support 62 classes (digits, uppercase, lowercase) within the same inference infrastructure.</td></tr><tr><td><strong>Weight &amp; Bias Scaling</strong></td><td>×10,000</td><td>Parameters are scaled to simulate fixed-point arithmetic, ensuring compatibility during inference in Verilog.</td></tr><tr><td><strong>Input Image Format</strong></td><td>28×28 grayscale</td><td>Images are captured via a Tkinter drawing interface, then saved as 600x600 rgb image.</td></tr><tr><td><strong>Preprocessing Pipeline</strong></td><td>Custom Python scripts for initial image conversion + Verilog modules</td><td>Workflow includes image conversion (<code>img2bin.py</code>), image processing (resize, contrast, gray, roi, padding, invert, rotate, flip, flatten), and file preparation for memory module generation.</td></tr><tr><td><strong>Memory Module Generation</strong></td><td>Python scripts (wtbs_loader.py, memloader_from_inp_vec.py)</td><td>Automated conversion of weight, bias, and image vector files into synthesizable Verilog memory modules.</td></tr><tr><td><strong>Simulation Environment</strong></td><td>Icarus Verilog</td><td>Compilation and simulation are conducted using Icarus Verilog with dedicated testbenches for module validation.</td></tr><tr><td><strong>Automation &amp; Workflow</strong></td><td>Fully automated, cross-platform</td><td>Integration via Makefiles (Linux/macOS), batch scripts (Windows), plus Perl and TCL scripts to streamline build, test, and simulation phases.</td></tr><tr><td><strong>Verification &amp; Testbenches</strong></td><td>Implemented</td><td>Robust testbenches facilitate both unit-level and end-to-end verification of the Verilog inference modules.</td></tr><tr><td><strong>System Integration</strong></td><td>End-to-End pipeline</td><td>Seamless integration connects Python for image input/output with Verilog for core logic simulation, creating a unified hardware prototyping workflow</td></tr><tr><td><strong>Test User Interaction</strong></td><td>Tkinter-based interface</td><td>Direct interactive drawing capability allows real-time testing of handwritten inputs through the complete conversion and inference flow.</td></tr></tbody></table>
]]></content:encoded></item><item><title>Other Achievements [Secondary School]</title><link>https://mummanajagadeesh.github.io/about/achievements/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/achievements/</guid><description>&lt;![CDATA[<h6 id="karate-black-belt-dan--holder"><strong>Karate Black Belt [DAN Ⅰ] Holder</strong></h6><ul><li>Achieved a<strong>Black Belt (DAN Ⅰ)</strong> in Karate</li></ul><h6 id="gold-medalist--district-level-karate-tournament"><strong>Gold Medalist – District Level Karate Tournament</strong></h6><ul><li>Secured<strong>1st place</strong> in a district-level Karate tournament</li></ul><h6 id="sports-kid-of-the-year-2018-19"><strong>Sports Kid of the Year [2018-19]</strong></h6><ul><li>Honored as the<strong>Sports Kid of the Year 2018</strong></li></ul><h6 id="gold-medalist--essay-writing"><strong>Gold Medalist – Essay Writing</strong></h6><ul><li>Won<strong>1st place</strong> in an<strong>essay writing competition</strong></li></ul><h6 id="silver-medalist--vedic-math"><strong>Silver Medalist – Vedic Math</strong></h6><ul><li>Achieved<strong>2nd place</strong> in a<strong>Vedic Mathematics competition</strong></li></ul>
]]></description><content:encoded>&lt;![CDATA[<h6 id="karate-black-belt-dan--holder"><strong>Karate Black Belt [DAN Ⅰ] Holder</strong></h6><ul><li>Achieved a<strong>Black Belt (DAN Ⅰ)</strong> in Karate</li></ul><h6 id="gold-medalist--district-level-karate-tournament"><strong>Gold Medalist – District Level Karate Tournament</strong></h6><ul><li>Secured<strong>1st place</strong> in a district-level Karate tournament</li></ul><h6 id="sports-kid-of-the-year-2018-19"><strong>Sports Kid of the Year [2018-19]</strong></h6><ul><li>Honored as the<strong>Sports Kid of the Year 2018</strong></li></ul><h6 id="gold-medalist--essay-writing"><strong>Gold Medalist – Essay Writing</strong></h6><ul><li>Won<strong>1st place</strong> in an<strong>essay writing competition</strong></li></ul><h6 id="silver-medalist--vedic-math"><strong>Silver Medalist – Vedic Math</strong></h6><ul><li>Achieved<strong>2nd place</strong> in a<strong>Vedic Mathematics competition</strong></li></ul>
]]></content:encoded></item><item><title>Personal Accomplishments and Competitions</title><link>https://mummanajagadeesh.github.io/about/accomplishments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/accomplishments/</guid><description>&lt;![CDATA[<h6 id="india-semiconductor-workforce-development-program-fellowship--grade-i-awardee-individual-may-25"><strong>India Semiconductor Workforce Development Program Fellowship – Grade I Awardee</strong><em>(Individual, May &lsquo;25)</em></h6><ul><li>Selected among the<strong>top candidates out of 2,800+ applicants</strong> for the<strong>ISWDP Fellowship (Grade I)</strong>, hosted by<strong>IISc, Synopsys, and Samsung</strong></li></ul><h6 id="isro-iroc-u-robotics-challenge--round-1-qualified-team-dec-24"><strong>ISRO IROC-U Robotics Challenge – Round 1 Qualified</strong><em>(Team, Dec &lsquo;24)</em></h6><ul><li>Designing an<strong>autonomous drone</strong> for<strong>Martian surface</strong> exploration, enabling autonomous operation in<strong>GNSS-denied</strong> environments</li><li>Successfully<strong>qualified for Elimination Round</strong>;<strong>Round 3 is ongoing</strong></li></ul><h6 id="circuit-conclave--nitc-tathva--1st-place-team-oct-24"><strong>Circuit Conclave | NITC Tathva – 1st Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Secured<strong>1st place</strong> in<strong>Circuit Conclave</strong>, an electronics design competition focused on innovative circuit solutions</li></ul><h6 id="disarmamine--nitc-tathva--3rd-place-team-oct-24"><strong>Disarmamine | NITC Tathva – 3rd Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Achieved<strong>3rd place</strong> in<strong>Disarmamine</strong>, showcasing expertise in electronics and problem-solving</li></ul><h6 id="robotrix24--nit-surathkal--1st-round-qualified-individual-dec-24"><strong>Robotrix'24 | NIT Surathkal – 1st Round Qualified</strong><em>(Individual, Dec &lsquo;24)</em></h6><ul><li>Successfully cleared<strong>Round 1</strong> of<strong>Robotrix'24</strong> and participated in the<strong>24-hour robotics simulation hackathon (Round 2)</strong> using<strong>CoppeliaSim</strong></li></ul><h6 id="digital-circuit-design-challenge--nit-trichy--1st-round-qualified-team-feb-25"><strong>Digital Circuit Design Challenge | NIT Trichy – 1st Round Qualified</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Cleared<strong>Round 1</strong> in<strong>Digital Circuit Design Challenge</strong>, a challenge focusing on digital electronics and logic design</li></ul><h6 id="flipkart-grid-robotics-challenge--1st-round-qualified-individual-aug-24"><strong>Flipkart GRID Robotics Challenge – 1st Round Qualified</strong><em>(Individual, Aug &lsquo;24)</em></h6><ul><li>Advanced past<strong>Round 1</strong> in the<strong>Flipkart GRID Robotics Challenge</strong>, an AI-driven robotics competition</li></ul><hr><hr><h6 id="aws-aiml-nano-degree-scholarship--udacity--amazon-mar-24"><strong>AWS AI/ML Nano Degree Scholarship | Udacity &amp; Amazon</strong><em>(Mar &lsquo;24)</em></h6><ul><li>Completed<strong>two AI/ML courses</strong> and cleared<strong>evaluation test</strong> as part of the<strong>AWS AI/ML Scholarship Program</strong></li><li>Trained an<strong>autonomous racing car</strong> using<strong>reinforcement learning (RL)</strong> to compete against a lap, making it to the<strong>leaderboards</strong></li><li>Became<strong>eligible to apply</strong> for the<strong>AWS AI/ML Nano Degree Scholarship</strong></li></ul><hr><hr><h6 id="c2s-chip-to-startup-digital-hackathon--participated-team-feb-25"><strong>C2S Chip to Startup &ldquo;Digital Hackathon&rdquo; – Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Competed in<strong>Digital Hackathon</strong> with a focus on<strong>digital electronics</strong>, organized under<strong>C2S Chip to Startup</strong> by<strong>Ministry of Electronics &amp; Information Technology (MeitY)</strong></li></ul><h6 id="nokia-fpga-hackathon-team-mar-25"><strong>Nokia FPGA Hackathon</strong><em>(Team, Mar &lsquo;25)</em></h6><ul><li>Participated in<strong>FPGA Based Quiz</strong> as part of the<strong>Round 1</strong> of the competition</li></ul><h6 id="bajaj-auto-ohm-challenge--participated-team-feb-25"><strong>Bajaj Auto Ohm Challenge – Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Took part in the<strong>Bajaj Auto Ohm Challenge</strong>, an engineering competition emphasizing<strong>electrical and electronic innovations</strong></li></ul><h6 id="bharatiya-antariksh-hackathon-bah-24--participated-team-july-24"><strong>Bharatiya Antariksh Hackathon (BAH &lsquo;24) – Participated</strong><em>(Team, July &lsquo;24)</em></h6><ul><li>Developed an<strong>AI/ML-based system</strong> for<strong>automatic detection of craters and boulders</strong> from<strong>Orbiter High-Resolution Camera (OHRC) images</strong></li><li>Focused on<strong>enhancing planetary exploration</strong> through automation and computer vision</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="india-semiconductor-workforce-development-program-fellowship--grade-i-awardee-individual-may-25"><strong>India Semiconductor Workforce Development Program Fellowship – Grade I Awardee</strong><em>(Individual, May &lsquo;25)</em></h6><ul><li>Selected among the<strong>top candidates out of 2,800+ applicants</strong> for the<strong>ISWDP Fellowship (Grade I)</strong>, hosted by<strong>IISc, Synopsys, and Samsung</strong></li></ul><h6 id="isro-iroc-u-robotics-challenge--round-1-qualified-team-dec-24"><strong>ISRO IROC-U Robotics Challenge – Round 1 Qualified</strong><em>(Team, Dec &lsquo;24)</em></h6><ul><li>Designing an<strong>autonomous drone</strong> for<strong>Martian surface</strong> exploration, enabling autonomous operation in<strong>GNSS-denied</strong> environments</li><li>Successfully<strong>qualified for Elimination Round</strong>;<strong>Round 3 is ongoing</strong></li></ul><h6 id="circuit-conclave--nitc-tathva--1st-place-team-oct-24"><strong>Circuit Conclave | NITC Tathva – 1st Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Secured<strong>1st place</strong> in<strong>Circuit Conclave</strong>, an electronics design competition focused on innovative circuit solutions</li></ul><h6 id="disarmamine--nitc-tathva--3rd-place-team-oct-24"><strong>Disarmamine | NITC Tathva – 3rd Place</strong><em>(Team, Oct &lsquo;24)</em></h6><ul><li>Achieved<strong>3rd place</strong> in<strong>Disarmamine</strong>, showcasing expertise in electronics and problem-solving</li></ul><h6 id="robotrix24--nit-surathkal--1st-round-qualified-individual-dec-24"><strong>Robotrix'24 | NIT Surathkal – 1st Round Qualified</strong><em>(Individual, Dec &lsquo;24)</em></h6><ul><li>Successfully cleared<strong>Round 1</strong> of<strong>Robotrix'24</strong> and participated in the<strong>24-hour robotics simulation hackathon (Round 2)</strong> using<strong>CoppeliaSim</strong></li></ul><h6 id="digital-circuit-design-challenge--nit-trichy--1st-round-qualified-team-feb-25"><strong>Digital Circuit Design Challenge | NIT Trichy – 1st Round Qualified</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Cleared<strong>Round 1</strong> in<strong>Digital Circuit Design Challenge</strong>, a challenge focusing on digital electronics and logic design</li></ul><h6 id="flipkart-grid-robotics-challenge--1st-round-qualified-individual-aug-24"><strong>Flipkart GRID Robotics Challenge – 1st Round Qualified</strong><em>(Individual, Aug &lsquo;24)</em></h6><ul><li>Advanced past<strong>Round 1</strong> in the<strong>Flipkart GRID Robotics Challenge</strong>, an AI-driven robotics competition</li></ul><hr><hr><h6 id="aws-aiml-nano-degree-scholarship--udacity--amazon-mar-24"><strong>AWS AI/ML Nano Degree Scholarship | Udacity &amp; Amazon</strong><em>(Mar &lsquo;24)</em></h6><ul><li>Completed<strong>two AI/ML courses</strong> and cleared<strong>evaluation test</strong> as part of the<strong>AWS AI/ML Scholarship Program</strong></li><li>Trained an<strong>autonomous racing car</strong> using<strong>reinforcement learning (RL)</strong> to compete against a lap, making it to the<strong>leaderboards</strong></li><li>Became<strong>eligible to apply</strong> for the<strong>AWS AI/ML Nano Degree Scholarship</strong></li></ul><hr><hr><h6 id="c2s-chip-to-startup-digital-hackathon--participated-team-feb-25"><strong>C2S Chip to Startup &ldquo;Digital Hackathon&rdquo; – Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Competed in<strong>Digital Hackathon</strong> with a focus on<strong>digital electronics</strong>, organized under<strong>C2S Chip to Startup</strong> by<strong>Ministry of Electronics &amp; Information Technology (MeitY)</strong></li></ul><h6 id="nokia-fpga-hackathon-team-mar-25"><strong>Nokia FPGA Hackathon</strong><em>(Team, Mar &lsquo;25)</em></h6><ul><li>Participated in<strong>FPGA Based Quiz</strong> as part of the<strong>Round 1</strong> of the competition</li></ul><h6 id="bajaj-auto-ohm-challenge--participated-team-feb-25"><strong>Bajaj Auto Ohm Challenge – Participated</strong><em>(Team, Feb &lsquo;25)</em></h6><ul><li>Took part in the<strong>Bajaj Auto Ohm Challenge</strong>, an engineering competition emphasizing<strong>electrical and electronic innovations</strong></li></ul><h6 id="bharatiya-antariksh-hackathon-bah-24--participated-team-july-24"><strong>Bharatiya Antariksh Hackathon (BAH &lsquo;24) – Participated</strong><em>(Team, July &lsquo;24)</em></h6><ul><li>Developed an<strong>AI/ML-based system</strong> for<strong>automatic detection of craters and boulders</strong> from<strong>Orbiter High-Resolution Camera (OHRC) images</strong></li><li>Focused on<strong>enhancing planetary exploration</strong> through automation and computer vision</li></ul>
]]></content:encoded></item><item><title>Positions of Responsibility &amp;amp; Volunteer Work</title><link>https://mummanajagadeesh.github.io/about/positions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/positions/</guid><description>&lt;![CDATA[<h6 id="rignitc-tech-member--nov24---forever"><strong>RIGNITC Tech Member | Nov'24 - Forever</strong></h6><ul><li><strong>RIGNITC - Robotics Interest Group @ NITC</strong></li><li>Worked on several real-world interdisciplinary projects as part of robotics enthusiast teams</li><li>Assisted in explaining lab visits to students from various schools</li><li>Helped in organizing Origo'25, the annual tech workshop by team RIG</li></ul><hr><hr><h6 id="ecea-executive-assistant--event-management--techincal-team--oct24---present"><strong>ECEA Executive Assistant | Event Management | Techincal Team , Oct'24 - Present</strong></h6><ul><li><strong>ECEA - Electronics And Communication Engineering Association @ NITC</strong></li><li>Arranged workshops and seminars in ECE department blocks</li><li>Helped freshers connect with faculty</li><li>Built relations with alumni and learned a lot during the process</li></ul><h6 id="tathva24-junior-executive--tech-conclave-committee-oct24"><strong>Tathva'24 Junior Executive | Tech Conclave Committee, Oct'24</strong></h6><ul><li><strong>Tathva - South India&rsquo;s Largest Techno-management Fest @ NITC</strong></li><li>Reaching out to YouTubers and influencers via cold emails to invite them to the event; successfully secured one guest attendee</li><li>Contributed to content writing and poster ideation for event promotion</li><li>Managed crowd coordination and logistics on the event day</li></ul><hr><hr><h6 id="scientific-volunteer--sep23"><strong>Scientific Volunteer | Sep'23</strong></h6><ul><li><strong>Institute for Plasma Research (IPR × NITC) | Plasma Exhibition</strong></li><li>Trained to explain plasma science, its applications, and nuclear fusion to exhibition visitors</li><li>Demonstrated and provided in-depth explanations of<strong>5+ plasma exhibits</strong> to over<strong>100 students</strong>, detailing their functions and construction while addressing queries</li></ul><h6 id="asteroid-hunter--may-24---aug-24"><strong>Asteroid Hunter | May &lsquo;24 - Aug &lsquo;24</strong></h6><ul><li><strong>International Astronomical Search Collaboration (IASC × NASA × Saptarshi India | STAC)</strong></li><li>Trained in using<strong>Astrometrica</strong> software to analyze astronomical data for asteroid detection</li><li>Identified<strong>10+ potential asteroid</strong> signatures as part of<strong>NASA’s Citizen Science</strong> initiative</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="rignitc-tech-member--nov24---forever"><strong>RIGNITC Tech Member | Nov'24 - Forever</strong></h6><ul><li><strong>RIGNITC - Robotics Interest Group @ NITC</strong></li><li>Worked on several real-world interdisciplinary projects as part of robotics enthusiast teams</li><li>Assisted in explaining lab visits to students from various schools</li><li>Helped in organizing Origo'25, the annual tech workshop by team RIG</li></ul><hr><hr><h6 id="ecea-executive-assistant--event-management--techincal-team--oct24---present"><strong>ECEA Executive Assistant | Event Management | Techincal Team , Oct'24 - Present</strong></h6><ul><li><strong>ECEA - Electronics And Communication Engineering Association @ NITC</strong></li><li>Arranged workshops and seminars in ECE department blocks</li><li>Helped freshers connect with faculty</li><li>Built relations with alumni and learned a lot during the process</li></ul><h6 id="tathva24-junior-executive--tech-conclave-committee-oct24"><strong>Tathva'24 Junior Executive | Tech Conclave Committee, Oct'24</strong></h6><ul><li><strong>Tathva - South India&rsquo;s Largest Techno-management Fest @ NITC</strong></li><li>Reaching out to YouTubers and influencers via cold emails to invite them to the event; successfully secured one guest attendee</li><li>Contributed to content writing and poster ideation for event promotion</li><li>Managed crowd coordination and logistics on the event day</li></ul><hr><hr><h6 id="scientific-volunteer--sep23"><strong>Scientific Volunteer | Sep'23</strong></h6><ul><li><strong>Institute for Plasma Research (IPR × NITC) | Plasma Exhibition</strong></li><li>Trained to explain plasma science, its applications, and nuclear fusion to exhibition visitors</li><li>Demonstrated and provided in-depth explanations of<strong>5+ plasma exhibits</strong> to over<strong>100 students</strong>, detailing their functions and construction while addressing queries</li></ul><h6 id="asteroid-hunter--may-24---aug-24"><strong>Asteroid Hunter | May &lsquo;24 - Aug &lsquo;24</strong></h6><ul><li><strong>International Astronomical Search Collaboration (IASC × NASA × Saptarshi India | STAC)</strong></li><li>Trained in using<strong>Astrometrica</strong> software to analyze astronomical data for asteroid detection</li><li>Identified<strong>10+ potential asteroid</strong> signatures as part of<strong>NASA’s Citizen Science</strong> initiative</li></ul>
]]></content:encoded></item><item><title>Privacy Policy</title><link>https://mummanajagadeesh.github.io/privacy-policy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/privacy-policy/</guid><description>&lt;![CDATA[<h3 id="wait-why-is-this-even-here">Wait… Why Is This Even Here?</h3><p>No one will ever notice this privacy policy. I don’t even know why it exists. Except for someone like me. And now you. If you’re reading this, you found it. Regret it now.</p>]]></description><content:encoded>&lt;![CDATA[<h3 id="wait-why-is-this-even-here">Wait… Why Is This Even Here?</h3><p>No one will ever notice this privacy policy. I don’t even know why it exists. Except for someone like me. And now you. If you’re reading this, you found it. Regret it now.</p><h4 id="we-need-your-email-to-send-you-stuff">We Need Your Email (To Send You Stuff)</h4><p>By signing up, you give me your email. But don’t forget—once I have it, it could be used in ways you might not expect. Stay subscribed if you want to stay in the loop.</p><h4 id="your-info-is-safe-but-not-forever">Your Info Is Safe (But Not Forever)</h4><p>I keep your email secure, but once it’s in my system, it might end up in unexpected places. I won’t share it with random strangers, but I’ll use it to its full potential.</p><h4 id="cookies-are-just-for-the-website-and-we-track-you">Cookies Are Just for the Website (And We Track You)</h4><p>I use cookies to improve your experience on my site, and yes, I track you. It’s not personal—it’s business. You’re here, and I’m going to make sure you keep coming back.</p><h4 id="unsubscribe-yeah-you-can-but-seriously">Unsubscribe? Yeah, You Can. But Seriously…</h4><p>You can unsubscribe at any time, but you’ll miss out on all the cool stuff. Think hard before you hit that button. Once you’re gone, you might not come back.</p><h4 id="accidentally-ended-up-here">Accidentally Ended Up Here?</h4><p>If you clicked on this by mistake, too bad. You’re in it now. Might as well stick around and see what happens.</p><h4 id="questions-better-ask-quickly">Questions? Better Ask Quickly.</h4><p>Got questions? Reach out, but remember—I don’t do apologies. I do business.</p><hr><h3 id="tldr-yes-i-sell-your-email-ids-deal-with-it">TL;DR: Yes, I Sell Your Email IDs. Deal With It.</h3><p>Here’s the hard truth about your email. When you sign up, I collect your email address to send you updates. And guess what? I might share it with others. So if you want to keep getting my emails, you better stick around.</p>
]]></content:encoded></item><item><title>Projects</title><link>https://mummanajagadeesh.github.io/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/projects/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item><item><title>Scholarships Received</title><link>https://mummanajagadeesh.github.io/about/scholarships/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/about/scholarships/</guid><description>&lt;![CDATA[<h6 id="india-semiconductor-workforce-development-program-iswdp-fellowship"><strong>India Semiconductor Workforce Development Program (ISWDP) Fellowship</strong></h6><ul><li><strong>Issued by:</strong> IISc Bangalore, Synopsys, and Samsung ·<em>May 2025</em></li><li><strong>Description:</strong> Secured a prestigious fellowship under the Grade I category, awarded to top-performing candidates out of over 2,800 applicants.</li><li><strong>Selection:</strong> Based on academic excellence and demonstrated skills in semiconductor technologies.</li><li><strong>Benefits:</strong> Includes 100% waiver on training sessions, 75% waiver on lab sessions, and exclusive access to semiconductor-focused workshops and lab infrastructure.</li></ul><h6 id="crec-sjet-scholarship"><strong>CREC-SJET Scholarship</strong></h6><ul><li><strong>Issued by:</strong> CREC Silver Jubilee Endowment Trust ·<em>Apr 2024</em></li><li><strong>Associated with:</strong> National Institute of Technology Calicut</li><li>Awarded in recognition of academic merit and financial need, enabling me to pursue my education and overcome financial barriers.</li></ul><h6 id="reliance-foundation-scholarship"><strong>Reliance Foundation Scholarship</strong></h6><ul><li><strong>Issued by:</strong> Reliance Foundation ·<em>Feb 2024</em></li><li><strong>Description:</strong> Recipient of a prestigious scholarship supporting meritorious first-year undergraduate students nationwide.</li><li><strong>Selection:</strong> Awarded on a merit-cum-means basis, with up to 5,000 scholars selected.</li><li><strong>Benefits:</strong> Besides financial aid, it also connects students to a strong alumni network.</li></ul><h6 id="fiitjee-tuition-fee-waiver"><strong>FIITJEE Tuition Fee Waiver</strong></h6><ul><li><strong>Issued by:</strong> FIITJEE ·<em>Mar 2021</em></li><li><strong>Associated with:</strong> FIITJEE</li><li><strong>Selection:</strong> Through performance in the FIITJEE Admission Test</li><li><strong>Award:</strong> Received 100% tuition fee waiver for excelling in the admission test</li></ul>]]></description><content:encoded>&lt;![CDATA[<h6 id="india-semiconductor-workforce-development-program-iswdp-fellowship"><strong>India Semiconductor Workforce Development Program (ISWDP) Fellowship</strong></h6><ul><li><strong>Issued by:</strong> IISc Bangalore, Synopsys, and Samsung ·<em>May 2025</em></li><li><strong>Description:</strong> Secured a prestigious fellowship under the Grade I category, awarded to top-performing candidates out of over 2,800 applicants.</li><li><strong>Selection:</strong> Based on academic excellence and demonstrated skills in semiconductor technologies.</li><li><strong>Benefits:</strong> Includes 100% waiver on training sessions, 75% waiver on lab sessions, and exclusive access to semiconductor-focused workshops and lab infrastructure.</li></ul><h6 id="crec-sjet-scholarship"><strong>CREC-SJET Scholarship</strong></h6><ul><li><strong>Issued by:</strong> CREC Silver Jubilee Endowment Trust ·<em>Apr 2024</em></li><li><strong>Associated with:</strong> National Institute of Technology Calicut</li><li>Awarded in recognition of academic merit and financial need, enabling me to pursue my education and overcome financial barriers.</li></ul><h6 id="reliance-foundation-scholarship"><strong>Reliance Foundation Scholarship</strong></h6><ul><li><strong>Issued by:</strong> Reliance Foundation ·<em>Feb 2024</em></li><li><strong>Description:</strong> Recipient of a prestigious scholarship supporting meritorious first-year undergraduate students nationwide.</li><li><strong>Selection:</strong> Awarded on a merit-cum-means basis, with up to 5,000 scholars selected.</li><li><strong>Benefits:</strong> Besides financial aid, it also connects students to a strong alumni network.</li></ul><h6 id="fiitjee-tuition-fee-waiver"><strong>FIITJEE Tuition Fee Waiver</strong></h6><ul><li><strong>Issued by:</strong> FIITJEE ·<em>Mar 2021</em></li><li><strong>Associated with:</strong> FIITJEE</li><li><strong>Selection:</strong> Through performance in the FIITJEE Admission Test</li><li><strong>Award:</strong> Received 100% tuition fee waiver for excelling in the admission test</li></ul>
]]></content:encoded></item><item><title>Search Result</title><link>https://mummanajagadeesh.github.io/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 UTC</pubDate><guid>https://mummanajagadeesh.github.io/search/</guid><description>&lt;![CDATA[]]></description><content:encoded>&lt;![CDATA[]]></content:encoded></item></channel></rss>